--- 
knitr: "bookdown::render_book"
title: "Computational Thinking for Social Scientists"
author: ["[Jae Yeon Kim](https://jaeyk.github.io/)"]
date: "2021-12-13"
site: bookdown::bookdown_site
github-repo: jaeyk/PS239T
twitter-handle: JaeJaeykim2
output: bookdown::gitbook
documentclass: book
bibliography:
  - book.bib
  - packages.bib
biblio-style: apalike
link-citations: yes
colorlinks: yes 
description: "Computational Thinking for Social Scientists. Online textbook for Teaching Computational Tools and Techniques for Social Scientists."
---

# Hello World 


```r
print("Hello, World!")
```

```
## [1] "Hello, World!"
```

> Make simple things simple, and complex things possible. - [Alan Kay](https://www.quora.com/What-is-the-story-behind-Alan-Kay-s-adage-Simple-things-should-be-simple-complex-things-should-be-possible)

This is the website for *Computational Thinking for Social Scientists*. This book intends to help social scientists think computationally and develop proficiency with computational tools and techniques to research computational social science. Mastering these tools and techniques not only enables social scientists to collect, wrangle, analyze, and interpret data with less pain and more fun, but it also let them work on research projects that would previously seem impossible.

The book is not intended to be a comprehensive guide for computational social science or any particular programming language, computational tool, or technique. For a general introduction to computational social science, I recommend [Matthew Salganik](http://www.princeton.edu/~mjs3/)'s [Bit By Bit (2017)](https://www.bitbybitbook.com/). 

The book is currently divided into two main subjects (fundamentals and applications) and eight main sessions.

## Part I Fundamentals

1. [Why computational thinking](#motivation)

2. [Best practices in data and code management using Git and Bash](#git_bash)

3. [How to wrangle, model, and visualize data easier and faster](#tidy_data) 

4. [How to use functional programming to automate repeated things](#functional_programming) 

5. [How to develop data products (e.g., packages and apps)](#products) 

## Part II Applications

6. [How to collect and parse semi-structured data at scale (e.g., using APIs and web scraping)](#semi_structured_data) 

7. [How to analyze high-dimensional data (e.g., text, image) using machine learning](#machine_learning) 

8. [How to access, query, and manage big data using SQL and Spark](#big_data) 

The book teaches how to do all of these, mostly in [**R**](https://www.r-project.org/about.html), and sometimes in [**bash**](https://www.gnu.org/software/bash/) and [**Python**](https://www.python.org/about/).

  - Why R? R is free, easy to learn (thanks to [`tidyverse`](https://www.tidyverse.org/) and [RStudio](https://rstudio.com/)), fast (thanks to [`Rcpp`](https://cran.r-project.org/web/packages/Rcpp/index.html)), runs everywhere, **open** (16,000+ packages; counting only ones [available at CRAN](https://cran.r-project.org/web/packages/)), and has a growing massive and inclusive community ([`#rstats`](https://twitter.com/search?q=%23rstats&src=typed_query)).
  
  - Why R + Python + bash?

       >> "For R and Python, Python is first and foremost a programming language. And that has a lot of good features, but it tends to mean, that if you are going to do data science in Python, you have to first learn how to program in Python. Whereas I think you are going to get up and running faster with R, than with Python because there's just a bunch more stuff built in and you don't have to learn as many programming concepts. You can focus on being a great political scientist or whatever you do and learning enough R that you don't have to become an expert programmer as well to get stuff done." - Hadley Wickham
  
      - However, this feature of the R community also raises a challenge. 
      
      >> Compared to other programming languages, the R community tends to be more focused on results instead of processes. Knowledge of software engineering best practices is patchy: for instance, not enough R programmers use source code control or automated testing. Inconsistency is rife across contributed packages, even within base R. You are confronted with over 20 years of evolution every time you use R. R is not a particularly fast programming language, and poorly written R code can be terribly slow. R is also a profligate user of memory. - Hadley Wickham
  
      - RStudio, especially the tidyverse team, has made heroic efforts to amend the problems listed above. Readers will learn these recent advances in the R ecosystem and complement R with Python and Bash.
      
      - If you're serious about programming, I strongly recommend learning Python. Learning Python also helps you fill gaps in the software engineering knowledge useful to be highly proficient in R.
      
## Special thanks 

This book is collected as much as it is authored. It is a remix version of [PS239T](https://github.com/rochelleterman/PS239T), a graduate-level computational methods course at UC Berkeley, developed initially by [Rochelle Terman](http://rochelleterman.com/) then revised by [Rachel Bernhard](http://rachelbernhard.com/). I have taught PS239T three times (twice as an instructor and once as a teaching assistant). Other teaching materials draw from the workshops I have created for [D-Lab](https://dlab.berkeley.edu/) (Summer-Fall 2020) and [Data Science Discovery Program](https://data.berkeley.edu/research/discovery-program-home) (Spring 2020) at UC Berkeley. I also have cited all the other references whenever I am aware of related books, articles, slides, blog posts, or YouTube video clips. 

## Suggestions, questions, or comments 

Please feel free to [create issues](https://github.com/jaeyk/PS239T/issues) if you find typos, errors, missing citations, please report them via the GitHub repository associated with this book. 

## License 

![](https://licensebuttons.net/l/by/4.0/88x31.png) This work is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).

<!--chapter:end:index.Rmd-->

# Computational thinking {#motivation}



## Why computational thinking

-   If social scientists want to know how to work smart and not just hard, they need to take full advantage of the power of modern programming languages, and that power is **automation**.

-   Let's think about the following two cases (these examples come from [the column](https://dlab.berkeley.edu/blog/why-teaching-social-scientists-how-code-professional-important) I contributed to the D-Lab website).

    -   Case 1: Suppose a social scientist needs to collect data on civic organizations in the United States from websites, Internal Revenue Service reports, and social media posts. As the number of these organizations is large, the researcher could not collect a large volume of data from diverse sources, so they would hire undergraduates and distribute tasks. This is a typical data collection plan in social science research, and it is labor-intensive. Automation is not part of the game plan. Yet, it is critical for so many reasons. Because the process is costly, no one is likely to either replicate or update the data collection effort. Put differently, without making the process efficient, it is difficult for it to be reproducible and scalable.

    -   Case 2: An alternative is to write computer programs that collect such data automatically, parse them, and store them in interconnected databases. Additionally, someone may need to maintain and validate the quality of the data infrastructure. Nevertheless, this approach lowers the cost of the data collection process, thereby substantially increasing the **reproducibility** and **scalability**. Furthermore, the researcher can document their code and publicly share it using their GitHub repository or even gather some of the functions they used and distribute them as open-source libraries.

-   Programming is as valuable a skill as writing in social science research. The extent to which a researcher can automate the research process can determine its efficiency, reproducibility, and scalability.

> Every modern statistical and data analysis problem needs code to solve it. You shouldn't learn just the basics of programming, spend some time gaining mastery. Improving your programming skills pays off because code is a **force multiplier**: once you've solved a problem once, code allows you to solve it much faster in the future. As your programming skill increases, the generality of your solutions improves: you solve not just the precise problem you encountered, but a wider class of related problems (in this way programming skill is very much like mathematical skill). Finally, sharing your code with others allows them to benefit from your experience. - [Hadley Wickham](https://imstat.org/2014/12/16/hadley-wickham-impact-the-world-by-being-useful/)

-   What aspects of the social science research process can be automated? How can we teach a machine to perform these tasks for us?

![From BBC Bitesize](https://bam.files.bbci.co.uk/bam/live/content/znmb87h/large)

-   This question touches the essence of computational thinking: "formulating a problem and expressing its solution in a way that a computer—human or machine—can effectively carry out" (defined by [Jeannette M. Wing](http://www.cs.cmu.edu/afs/cs/usr/wing/www/publications/Wing06.pdf))

This book teaches how you to do that in R in incremental steps.

-   From graphic user interface to command-line interface (ch 3)

-   From short programs to long programs (ch 4-5)

-   The ultimate goal is to solve complex problems at scale using computation (ch 6-7)

> "[W]e wanted users to be able to begin in an interactive environment, where they did not consciously think of themselves as programming. Then as their needs became clearer and their sophistication increased, they should be able to slide gradually into programming, when the language and system aspects would become more important." - *Stages in the Evolution of S* by John Chambers (S is the progenitor of R)

-   Beginners! Learning programming is a long game. The most important learning method (for almost any training) is consistency. Never stop writing code even though your current code may fall far short of the perfection.
    ![](misc/wickham.png)

-   Intermediate programmers! Try to empower, not intimidate, newbies. The most important rule in the computational social science community (at least, in my opinion) is being nice. Read David Robinson's ["A Million Lines of Bad Code"](http://varianceexplained.org/programming/bad-code/) for more insights.

![](http://imgs.xkcd.com/comics/code_quality.png)

## Computational way of thinking about data

-   Berkeley's widely praised data science undergraduate education is built upon inferential (statistics) and computational thinking. [The textbook](https://www.inferentialthinking.com/chapters/intro) used for teaching its most fundamental course (Data8) underscores computational thinking because "programming allows us to apply analysis techniques to the large and diverse data sets that arise in real-world applications: not just numbers, but text, images, videos, and sensor readings." This is also precisely the point of this textbook and explains how its content is organized.

### Structure

-   Fixed number of columns and rows?

    -   Yes!: Structured data (e.g., Excel spreadsheets, CSVs)

        -   Tidy data (a special case of structured data)

    -   No!: semi-structured data (e.g., PDFs, websites, and social media posts) unstructured data (e.g., plain texts)

### Dimension

Suppose n = the number of observations and p = the number of variables.

-   Low-dimensional data (n \> p)

    -   Most survey, experimental, and administrative data

-   High-dimensional data (n \< p)

    -   Text, speech, image, video, etc

### Size

-   Small and medium data: Data fit in your laptop's memory
-   Big data: Data don't fit in your laptop's memory

## Computational way of thinking about the research process

Computational tools and techniques make ...

-   Doing traditional research easier, faster, and scalable

    -   Data wrangling
    -   Modeling
    -   Visualization

-   Documentation and collaboration easier, faster and more scalable

    -   Dynamic reporting (markdown)
    -   Version control system (Git and GitHub)

-   Collecting and analyzing large and complex data feasible

    -   Digital data collection (web scraping and API)

        -   Building a data infrastructure (SQL)

    -   Machine learning

        -   Text as data, image as data, etc
        -   Machine learning applications to surveys and experiments

## References

Here are a couple of useful videos that introduce the main concepts of computational social science. Matthew Salganik (Professor of Sociology at Princeton) is co-founder of the [Summer Institute in Computational Social Science](https://sicss.io/), and Rayid Ghani (Professor of Machine Learning and Public Policy at Carnegie Mellon) is founder of the [Data Science for Social Good](https://www.dssgfellowship.org/). (Full disclaimer: I'm a former participant (Princeton 2019) and local organizer ([Bay Area 2020](https://sicss.io/2020/bay_area/)) of the Summer Institute in Computational Social Science. If you become interested in computational social science and wonder what should be your next step, I would highly recommend applying for the program.) Data Science for Social Good is another cool program that deserves your attention.

```{=html}
<iframe width="560" height="315" src="https://www.youtube.com/embed/zGG9wPl1C5E" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p An Introduction to Computational Social Science, Summer Institute in Computational Social Science /p>
```
```{=html}
<iframe width="560" height="315" src="https://www.youtube.com/embed/GTUozT9qxVw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p Rayid Ghani | Keynote: Using Data Science for Social Good: Examples, Opportunities, and Challenges /p>
```

I also recommend looking at [the pedagogy article]((https://osf.io/preprints/socarxiv/pf7n6/?fbclid=IwAR2ZI0yw_pehS0mxAmeUBOGpzIhiO2LMUPGBzBLTLNo4C2HrJSoH9uZhgTY)) (forthcoming in *PS: Political Science and Politics*), I wrote with my colleague Margaret Ng, for those interested in more effective ways of learning and teaching computational methods. 

<!--chapter:end:01_motivation.Rmd-->

# Managing data and code {#git_bash}



## Using Bash (command-line interface)

As William Shotts the author of *[The Linux Command Line](http://linuxcommand.org/tlcl.php)* put it: 

> graphical user interfaces make easy tasks easy, while command-line interfaces make difficult tasks possible.

### Why bother using the command line?

Create a plain text file that contains the word "test."

- `echo`: "Write arguments to the standard output" This is equivalent to using a text editor (e.g., nano, vim, emacs) and write something.
- `> test` Save the expression in a file named test.   
- In general, if you don't know what a command does, just type `<command name> --help.` If you need further information, you can do `man <command name>.` `man` stands for manual. Finally, you can get more user-friendly information by using either [`tldr`](https://tldr.sh/). 

```sh

echo "test" > test 

```

- Make 100 duplicates of this file. Let's break down the seemingly complex commands. 
- I did this using for loop (`for i in {1..100}`). Curly braces `{}` make 1..100 integers from 1 to 100.  
- `;` is used to use multiple commands without making line breaks. 
- `$var` returns the value associated with a variable. Type `name=<Your name>`. Then, type `echo $name.` You should see your name printed. Variable assignment is one of the most basic things you'll learn in any programming.  
- For novice users, I warn you that there could be too many advanced concepts. If so, don't pay too much attention to this. For now, it's enough to have intuitions. 

```sh

for i in {1..100}; do cp test "test_$i"; done  

```

Append "COVID" to the file named test_100. Note that I used `>>` (append) not `>.` 

```sh

echo "COVID" >> test_100 

```

Let's read (=`cat` (concatenate)) what's in test_100 

```sh

cat test_100 

```

Find which fine contains the character "COVID." This is equivalent to finding a needle in a haystack. This is a daunting task for a human researcher, but not for our robotic assistant. `grep` finds PATTERNS in each FIEL. What follows - are options (called flags): `r` (recursive), `n` (line number), `w` (match only whole words), `e` (use patterns for matching). `rnw` are for output control and `e` is for pattern selection. 

You can write `grep -r -n -w -e "COVID",` but the simpler, the better. 

* `grep`: command 

* `-rnw -e`: flags 

* `COVID`: argument (usually file or file paths)

```sh

grep -rnw -e "COVID" 

```

Let's remove (=`rm`) all the duplicate files as well as the original file. `*` (any number of characters) is a wildcard (if you want to identify a single number of characters, use `?`). It finds every file whose name starts with `test_`.

```sh

rm test_* test 

```

This command should return "test_100:2:COVID." (file test_100; line number 2; COVID)

What is this black magic? Can you do the same thing using a graphical interface? Which method is more efficient? I hope that this quick demonstration will give you enough sense of why learning the command line could be incredibly useful. In my experience, mastering the command line helps to automate your research process almost from end to end. For instance, you don't need to write files from a website using your web browser. You can run the `wget` command in the terminal. Better yet, you don't even need to run the command for the second time. You can write a Shell script (`*.sh`) that automates downloading, moving, and sorting multiple files. You can find one example of this from the PS239T course repository. [`copy_syllabus.sh`](https://GitHub.com/PS239T/spring_2021/blob/main/copy_syllabus.sh) automatically runs an R markdown file, produces HTML and PDF outputs, and move these files to the desired location. When I modified something in the syllabus, I just need to run this Shell script again. (No worries! I will explain what is Shell shortly.) Finally, if you need to interact with servers or supercomputers for your research, you are likely to use the command-line interface.

### UNIX Shell 

The following materials on UNIX and Shell are adapted from [the software carpentry](https://bids.GitHub.io/2015-06-04-berkeley/shell/00-intro.html.

#### Unix

UNIX is an **operating system + a set of tools (utilities)**. It was developed by AT & T employees at Bell Labs (1969-1971). From Mac OS X to Linux, many of the current operation systems are some versions of UNIX. For this reason, if you're using Max OS, then you don't need to do anything else to experience UNIX. You're already all set. If you're using Windows, you need to install either GitBash (a good option if you only use Bash for Git and GitHub) or Windows Subsystem (highly recommended if your use case goes beyond Git and GitHub)￣. For more information, see [this installation guideline](https://GitHub.com/PS239T/spring_2021/blob/main/B_Install.md) from the course repo. If you're a Windows user and don't use Windows 10, I recommend installing [VirtualBox](https://www.virtualbox.org/).

UNIX is old, but it is still mainstream and it will be. Moreover, [the UNIX philosophy](https://en.wikipedia.org/wiki/Unix_philosophy) ("Do One Thing And Do It Well")---minimalist, modular software development---is highly and widely influential.  

![Ken Thompson and Dennis Ritchie, key proponents of the Unix philosophy](https://upload.wikimedia.org/wikipedia/commons/1/1b/Ken_Thompson_and_Dennis_Ritchie--1973.jpg)

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/tc4ROCJYbm0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  
<p>AT&T Archives: The UNIX Operating System</p>

```

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/xnCgoEyz31M" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p>Unix50 - Unix Today and Tomorrow: The Languages </p>
```

#### Kernel

The kernel of UNIX is the hub of the operating system: it allocates time and memory to programs and handles the [filestore](http://users.ox.ac.uk/~martinw/unix/chap3.html) (e.g., files and directories) and communications in response to system calls. 

#### Shell

The shell is an interactive program that provides an interface between the user and the kernel. The shell interprets commands entered by the user or supplied by a Shell script and passes them to the kernel for execution. 

#### Human-Computer interfaces

At a high level, computers do four things:

- run programs
- store data
- communicate with each other
- interact with us (through either CLI or GUI)

#### The Command Line 

This kind of interface is called a **command-line interface**, or CLI,
to distinguish it from the **graphical user interface**, or GUI, that most people now use.

The heart of a CLI is a **read-evaluate-print loop**, or REPL: when the user types a command and then presses the enter (or return) key, the computer reads it, executes it, and prints its output. The user then types another command, and so on until the user logs off.

If you're using RStudio, you can use terminal inside RStudio (next to the "Console"). (For instance, type Alt + Shift + M)

#### The Shell 

This description makes it sound as though the user sends commands directly to the computer, and the computer sends the output directly to the user. In fact, there is usually a program in between called a **command shell**.

![Source: Prashant Lakhera](https://miro.medium.com/max/1032/1*GuB5q_bWOSZa-8sDg1lEDA.png)

What the user types go into the shell; it figures out what commands to run and orders the computer to execute them. 

Note, the reason why the shell is called *the shell*: it encloses the operating system in order to hide some of its complexity and make it simpler to interact with. 

A shell is a program like any other. What's special about it is that its job is to run other programs rather than to do calculations itself. The commands are themselves programs: when they terminate, the shell gives the user another prompt ($ on our systems).

#### Bash

The most popular Unix shell is **Bash**, the Bourne Again Shell (so-called because it's derived from a shell written by Stephen Bourne --- this is what passes for wit among programmers). Bash is the default shell on most modern implementations of **Unix**, and in most packages that provide Unix-like tools for Windows.

#### Why Shell?

Using Bash or any other shell sometimes feels more like programming than like using a mouse. Commands are terse (often only a couple of characters long), their names are frequently cryptic, and their output is lines of text rather than something visual like a graph. 

On the other hand, the shell allows us to combine existing tools in powerful ways with only a few keystrokes and to set up pipelines to handle large volumes of data automatically.

In addition, the command line is often the easiest way to interact with remote machines (explains why we learn Bash before learning Git and GitHub). As clusters and cloud computing become more popular for scientific data crunching, being able to drive them is becoming a necessary skill.

#### Our first command

The part of the operating system responsible for managing files and directories is called the **file system**. It organizes our data into files, which hold information, and directories (also called "folders"), which hold files or other directories.

Several commands are frequently used to create, inspect, rename, and delete files and directories. To start exploring them, let's open a shell window:

```sh
jae@jae-X705UDR:~$ 
```

* jae: a specific user name 

* jae-X705UDR: your computer/server name 

* `~`: current directory (`~` = home)

* `$`: a **prompt**, which shows us that the shell is waiting for input; your shell may show something more elaborate.

Type the command `whoami`, then press the Enter key (sometimes marked Return) to send the command to the shell.

The command's output is the ID of the current user, i.e., it shows us whom the shell thinks we are:

```sh
$ whoami

# Should be your user name 
jae 
```

More specifically, when we type `whoami` the shell:

1.  finds a program called `whoami`,
2.  runs that program,
3.  displays that program's output, then
4.  displays a new prompt to tell us that it's ready for more commands.

#### Communicating to other systems

In the next unit, we'll be focusing on the structure of our own operating systems. But our operating systems rarely work in isolation; often, we are relying on the Internet to communicate with others! You can visualize this sort of communication within your own shell by asking your computer to `ping` (based on the old term for submarine sonar) an IP address provided by Google (8.8.8.8); in effect, this will test whether your Internet is working. 

```sh
$ ping 8.8.8.8
```

Note: Windows users may have to try a slightly different alternative:

```sh
$ ping -t 8.8.8.8
```

(Thanks [Paul Thissen](http://www.paulthissen.org/) for the suggestion!)

#### File system organization

Next, let's find out where we are by running a command called `pwd` (**print working directory**).

At any moment, our **current working directory** is our current default directory, i.e., the directory that the computer assumes we want to run commands in unless we explicitly specify something else.

Here, the computer's response is `/home/jae`, which is the **home directory**:

```sh
$ pwd

/home/jae
```

**Additional tips**

You can also download files in the terminal. 

1. Install wget utility 

```sh

sudo apt-get install wget 

```
2. Download target files 

```sh 

wget https://download1.rstudio.org/desktop/bionic/amd64/rstudio-1.4.1103-amd64.deb

```

![](misc/wget.png)

> #### Home Directory
>
> The home directory path will look different on different operating systems. On Linux it will look like `/home/jae`, and on Windows it will be similar to `C:\Documents and Settings\jae`. Note that it may look slightly different for different versions of Windows.

> #### Alphabet Soup
>
> If the command to find out who we are is `whoami`, the command to find out where we are ought to be called `whereami`, so why is it `pwd` instead? The usual answer is that in the early 1970s, when Unix was
>
> first being developed, every keystroke counted: the devices of the day were slow, and backspacing on a teletype was so painful that cutting the number of keystrokes in order to cut the number of typing mistakes was actually a win for usability. The reality is that commands were added to Unix one by one, without any master plan, by people who were immersed in its jargon. 
>
> The good news: because these basic commands were so integral to the development of early Unix, they have stuck around, and appear (in some form) in almost all programming languages.

To understand what a "home directory" is, let's have a look at how the file system as a whole is organized. At the top is the **root directory** that holds everything else.

We refer to it using a slash character `/` on its own; this is the leading slash in `/home/jae`.

Inside that directory are several other directories: `bin` (which is where some built-in programs are stored), `data` (holding miscellaneous data files) `etc` (where local configuration files are stored), `tmp` (for temporary files that don't need to be stored long-term), and so on.

> If you're working on a Mac, the file structure will look similar, but not identical. The following image shows a file system graph for the typical Mac.

![File Directory](https://swcarpentry.GitHub.io/shell-novice/fig/home-directories.svg)

We know that our current working directory `/home/jae` is stored inside `/home` because `/home` is the first part of its name. Similarly, we know that `/home` is stored inside the root directory `/` because its name begins with `/`.

**Food for thought**

This hierarchical way of thinking about organizing things is prevalent in the design of computation systems. However, it doesn't need to be that way, especially when the system concerns something like conversations. 

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/P0H1m14Krmc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> Reimagining the Internet 10: Amy Zhang, University of Washington, The Institute for Digital Public Infrastructure /p>
```

> #### Path
>
> Notice that there are two meanings for the `/` character.
> When it appears at the front of a file or directory name, it refers to the root directory. When it appears *inside* a name, it's just a separator.

#### Listing

Let's see what's in your home directory by running `ls` (**list files and directories):

```sh
$ ls

Applications		Dropbox			Pictures
Creative Cloud Files	Google Drive		Public
Desktop			Library			Untitled.ipynb
Documents		Movies			anaconda
Downloads		Music			file.txt
```

`ls` prints the names of the files and directories in the current directory in alphabetical order, arranged neatly into columns.

We can make `ls` more useful by adding flags. For instance, you can make your computer show only directories in the file system using the following command. Here `-F` flag classifies files based on some types. `/` indicates directories. 

```sh
ls -F /
```

The leading `/` tells the computer to follow the path from the root of the file system, so it always refers to exactly one directory, no matter where we are when we run the command.

If you want to see only directories in the current working directory, you can do the following. (Remember `^`? This wildcard identifies a single number of characters. In this case, `d`.)

```sh
ls -l | grep "^d"
```

What if we want to change our current working directory? Before we do this, `pwd` shows us that we're in `/home/jae`, and `ls` without any arguments shows us that directory's contents:

```sh
$ pwd

/home/jae

$ ls

Applications		Dropbox			Pictures
Creative Cloud Files	Google Drive		Public
Desktop			Library			Untitled.ipynb
Documents		Movies			anaconda
Downloads		Music			file.txt
```

Use relative paths (e.g., `../spring_2021/references.md`) whenever it's possible so that your code is not dependable on how your system is configured. 

**Additional tips**

How can I find pdf files in `Downloads` using the terminal? Remember `*` wildcard?

```sh
cd Downloads/ 

find *.pdf
```
Also, note that you don't need to type every character. Type the first few characters then press TAB (autocomplete). This is called **tab-completion**, and we will see it in many other tools as we go on.

#### Moving around

We can use `cd` (**change directory**) followed by a directory name to change our working directory. 

```sh
$ cd Desktop
```

`cd` doesn't print anything, but if we run `pwd` after it, we can see that we are now in `/home/jae/Desktop`.

If we run `ls` without arguments now, it lists the contents of `/home/jae/Desktop`, because that's where we now are:

```sh

$ pwd

/home/jae/Desktop

```

We now know how to go down the directory tree: how do we go up? We could use an absolute path:

```sh
$ cd /home/jae/
```

but it's almost always simpler to use `cd ..` to go up one level:

```sh

$ pwd

/home/jae/Desktop

$ cd ..

```

`..` is a special directory name meaning "the directory containing this one", or more succinctly, the **parent** of the current directory. Sure enough, if we run `pwd` after running `cd ..`, we're back in `/home/jae/`:

```sh
$ pwd

/home/jae/
```

The special directory `..` doesn't usually show up when we run `ls`. If we want to display it, we can give `ls` the `-a` flag:

```sh
$ ls -a

.		.localized	Shared
..		Guest		rachel
```

`-a` stands for "show all"; it forces `ls` to show us file and directory names that begin with `.`, such as `..`.

> #### Hidden Files: For Your Own Protection
> 
> As you can see, a bunch of other items just appeared when we enter `ls -a`. These files and directories begin with `.` followed by a name. These are usually files and directories that hold important programmatic information, not usually edited by the casual computer user. They are kept hidden so that users don't accidentally delete or edit them without knowing what they're doing.

As you can see, it also displays another special directory that's just called `.`, which means "the current working directory". It may seem redundant to have a name for it, but we'll see some uses for it soon.

> #### Phone Home
> 
> If you ever want to get to the home directory immediately, you can use the shortcut~`. For example, type `cd ~` and you'll get back home in a jiffy. `~` will also stand in for your home directory in paths, so for instance`~/Desktop` is tstand-inas `/home/jae/Desktop`. This only works if it is the first character in the path: `here/there/~/elsewhere` is not `/home/jae/elsewhere`.

**Additional tips**

Okay. These exercises help us get to know about `cd` command, but not very exciting. Let's do something more concrete and potentially useful. Let's say you downloaded a file using your web browser and locate that file. How could you do that?

Your first step should be learning more about `ls` command. You can do that by Googling or typing `ls --help`. By taking a look at the documentation, you can recognize that you need to add `-t` (sort by time). Then, what's `|`? It's called pipe and it chains commands. For instance, if `<command 1> | <command 2>`, then command1's output will be command2's input. `head` list the first ten lines of a file. `-n1` flag makes it show only the first line of the output (n1).

```sh
# Don't forget to use TAB completion
cd Downloads/ 

ls -t | head -n1
```

Yeah! We can actually do more cool things. How can you find the most recently downloaded PDF file? You can do this by combining the two neat tricks you learned earlier. 

```sh
ls -t | find *.pdf | head -n1 
```

#### Creating, copying, removing and renaming files 

##### Creating files 

1. First, let's create an empty directory named exercise 

```sh

mkdir exercise 

```

2. You can check whether the directory is created by typing `ls`. If the print format is difficult to read, add `-l` flag. Did you notice the difference?

3. Let's move to `exercise` subdirectory and create a file named test 

```sh 

cd exercise ; touch test ; ls 

```

4. Read test 

```sh

cat test 

```

5. Hmn. It's empty. Let's add something there. `>` = overwrite 

```sh 

echo "something" > test ; cat test 

```

6. Yeah! Can you add more? `>>` = append 

```sh 

echo "anything" >> test ; cat test 

```

7. Removing "anything" from `test` is a little bit more complex because you need to know how to use `grep` (remember that we used this command in the very first example). Here, I just demonstrate that you can do this task using Bash and let's dig into this more when we talk about working with text files.  

```sh 

grep -v 'anything' test

```

##### Copying and Removing Files 

1. Can we make a copy of `test`? Yes!

```sh

cp test test_1; cat 

```

2. Can we make 100 copies of `test?` Yes!

You can do this 

```sh

cp test test_1 
cp test test_2
cp test test_3 

... 

```

or 

```sh 

for i in {1..100}; do cp test "test_$i"; done  

```

Which one do you like? (Again, don't focus on for loop. We'll learn it and other similar tools to deal with iterations in the later chapters.)

3. Can you remove all of `test_` files?

You can do this 

```sh 
rm test_1
rm test_2
rm test_3 

...

```

or 

```

rm test_*

```

Which one do you like?

4. Let's remove the directory. 

```sh

cd .. 

rm exercise/

```

The `rm` command should not work because `exercise` is not a file. Type `rm --help` and see which flag is going to be helpful. It might be `-d` (remove empty directories).

```
rm -d exercise/  
```

Oops. Still not working because the directory is not empty. Try this. Now, it works. 

```
rm -r exercise/ 
```

What's `-r`? It stands for recursion (e.g., . Recursion is a very powerful idea in programming and helps to solve complex problems. We'll come back to it many times (e.g., `purrr::reduce` in R). 

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/Mv9NEXX1VHc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> What on Earth is Recursion? - Computerphile </p>
```

##### Renaming files

1. Using `mv`

First, we will learn how to move files and see how it's relevant for renaming files. 

```sh

# Create two directories 
mkdir exercise_1 ; mkdir exercise_2 

# Check whether they were indeed created 
find exer*

# Create an empty file 
touch exercise_1/test 

# Move to exercise_1 and check 
cd exercise_1 ; ls 

# Move this file to exercise_2 
mv test ../exercise_2 

# Move to exercise_2 and check 
cd exercise_2 ; ls 
```

What `mv` has something to do with renaming?

* [mv] [source] [destination]

```sh

mv test new_test ; ls 

```

2. Using `rename`

`mv` is a good tool to rename one file. But how about renaming many files? (Note that your pwd is still `exercise_2` where you have `new_test` file.)

```sh

for i in {1..100}; do cp new_test "test_$i.csv"; done  

```

Then install `rename`. Either `sudo apt-get install -y rename` or `brew install rename` (MacOS).

Basic syntax: rename [flags] perlexpr (Perl Expression) files. Note that [Perl](https://en.wikipedia.org/wiki/Perl) is another programming language. 

```sh
# Rename every csv file to txt file 
rename 's/.csv/.txt/' *.csv

# Check 
ls -l
```

The key part is `s/.csv/.txt/` = `s/FIND/REPLACE`

Can you perform the same task using GUI? Yes, you can but it would be more time-consuming. Using the command line, you did this via just one-liner(!). [Keith Brandnam](http://korflab.ucdavis.edu/Bios/bio_keithb.html) wrote a wonderful book titled [UNIX and Perl to the Rescue! (Cambridge University Press 2012)](https://www.amazon.com/Unix-Perl-Rescue-Keith-Bradnam/dp/0521169828) that discusses how to use UNIX and Perl to deal with massively large datasets.

#### Working with CSV and text files 

1. Download a CSV file (Forbes World’s Billionaires lists from 1996-2014). For more on the data source, see [this site](https://corgis-edu.github.io/corgis/csv/billionaires/).

```sh
wget https://corgis-edu.github.io/corgis/datasets/csv/billionaires/billionaires.csv
```

2. Read the first two lines. We have learned `cat`, `|`, and `head` already. So, there's nothing new here.

**Additional tips 1**
If you have a large text file, the fact that `cat` prints everything at once is inconvenient. The alternative using `less`. 

```sh
cat billionaires.csv | head -n2
```

3. Check the size of the dataset (2615 rows). So, there are 2014 observations (n-1 because of the header). `wc` prints newline, word, and byte counts for each file. If you run `wc` without `-l` flag, you get the following: `2615 (line) 20433 (word) 607861 (byte) billionaires.csv`

```sh
wc -l billionaires.csv
```

4. How about the number of columns? `sed` is a stream editor and very powerful when it's used to filter text in a pipeline. For more information, see [this article](https://www.gnu.org/software/sed/manual/sed.html). You've already seen `s/FIND/REPLACE`. Here, the pattern we are using is `s/delimiter/\n/g`. We've seen that the delimiter is `,`, so that's what I plugged in the command below. 

```sh
head -1 billionaires.csv | sed 's/,/\n/g' | nl
```

**Additional tips 2**
The other cool command for text parsing is `awk`. This command is especially useful for filtering.

1. This is the same as using `cat` (basically, printing). So, what's new? 

```sh
awk '{print}' billionaires.csv 
```

2. This is new. 

```sh
awk '/China/ {print}' billionaires.csv
```

3. Let's see only the five rows. We filtered rows so that every row in the final dataset contains 'China'. 

```sh
awk '/China/ {print}' billionaires.csv | head -n5 
```

4. You can also get the numbers of these rows. 

```sh
awk '/China/ {print NR}' billionaires.csv 
```

#### User roles and file permissions

1. If you need admin access, use `sudo`. For instance, `sudo apt-get install <package name>`.

2. To run a Shell script (.sh), you need to change its file mode. You can make the script executable by typing `chmod +x <Shell script>`. Then, you can run it by typing `./pdf_copy_sh.` `.` refers to the current working directory. Other options: `sh pdf_copy_sh.` or `bash pdf_copy_sh.` I use `./pdf_copy_sh.`

#### Writing your first Shell script (.sh)

Finally, we're learning how to write a Shell script (a file that ends with .sh). Here I show how to write a Shell script that creates a subdirectory called `/pdfs` under `/Download` directory, then find PDF files in `/Download` and copy those files to `pdfs`. Essentially, this Shell script creates a backup. Name this Shell script as 'pdf_copy.sh.' Pay attention to this example as a similar exercise is going to be part of your second assignment. 

```sh

#!/bin/sh # Stating this is a Shell script. 

mkdir /home/jae/Downloads/pdfs # Obviously, in your case this file path should be incorrect.

cd Download

cp *.pdf pdfs/ 

echo "Copied pdfs"

```

**Additional tips**

Using Make [TBD]

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/aw9wHbFTnAQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> Using make and writing Makefile (in C++ or C) by Programming Knowledge </p>
```

### References 

- [The Unix Workbench](https://seankross.com/the-unix-workbench/) by Sean Kross 

- [The Unix Shell](http://swcarpentry.GitHub.io/shell-novice/), Software Carpentry 

- [Data Science at the Command Line](https://www.datascienceatthecommandline.com/1e/) by Jeroen Janssens 

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/QxpOKbv-KQU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> Obtaining, Scrubbing, and Exploring Data at the Command Line by Jeroen Janssens from YPlan, Data Council </p>
```

- [Shell Tools and Scripting](https://missing.csail.mit.edu/2020/shell-tools/), ./missing-semester, MIT  

- [Command-line Environment](https://missing.csail.mit.edu/2020/command-line/), ./missing-semester, MIT

## Git and GitHub

### Version control system 

**The most important point**

* Backup != Version control

* If you do version control, you need to save your **raw data** in your hard disk, external drive, or cloud, but nothing else. In other words, anything that you are going to change should be subject to version control (also, it's not the same as saving your code with names like 20200120_Kim or something like that). Below, I will explain what is version control and how to do it using Git and GitHub. 

![Why you should do version control](https://i2.wp.com/cdn-images-1.medium.com/max/399/1*7HHA_UkjUK7wp7qP4CYu1g.png?zoom=1.75&w=456&ssl=1)

According to [GitHub Guides](https://guides.GitHub.com), a version control system "tracks the history of changes as people and teams collaborate on projects together". Specifically, it helps to track the following information:

* Which changes were made?
* Who made the changes?
* When were the changes made?
* Why were changes needed?

Git is a case of a [distributed version control system](https://en.wikipedia.org/wiki/Distributed_version_control), common in open source and commercial software development. This is no surprise given that Git [was originally created](https://lkml.org/lkml/2005/4/6/121) to deal with Linux kernel development. 

**Food for thought**

If you're curious about how the Internet works, learn one of the key ideas of the Internet: [end-to-end principle](https://en.wikipedia.org/wiki/End-to-end_principle). This also explains why [net neutrality](https://en.wikipedia.org/wiki/Net_neutrality) matters. 

The following images, from [Pro Git](git-scm.com), show how a centralized (e.g., CVS, Subversion, and Perforce) and decentralized VCS (e.g., Git, Mercurial, Bazzar or Darcs) works differently. 

![Centralized version control system](https://git-scm.com/book/en/v2/images/centralized.png)

Figure 2. Centralized VCS.

![Decentralized version control system](https://git-scm.com/book/en/v2/images/distributed.png)

Figure 3. Decentralized VCS.

For more information on the varieties of version control systems, please read [Petr Baudis's review](https://pdfs.semanticscholar.org/4490/4c70bc91e1bed4fe02b9e2282f031b7c90ea.pdf) on that subject.


```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/PFwUHTE6mFc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> Webcast • Introduction to Git and GitHub • Featuring Mehan Jayasuriya, GitHub Training & Guides </p>
```


![Figure 2.1. A schematic git workflow from Healy's "The Plain Person’s Guide to Plain Text Social Science"](https://plain-text.co/figures/git-basic.png)

For more information, watch the following video:

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/u6G3fbmpWr8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> The Basics of Git and GitHub, GitHub Training & Guides </p>

```

### Setup 

#### Signup 

1. Make sure you have installed Git ([[tutorial]](https://happygitwithr.com/install-git.html#install-git)). 

```sh
git --version 
# git version 2.xx.x
```

2. If you haven't, sign up for a GitHub account: https://github.com/
  - If you're a student, also sign up for GitHub Student Developer Pack: https://education.github.com/pack Basically, you can get a GitHub pro account for free (so why not?).
  
3. Access GitHub either using Hypertext Transfer Protocol Secure (HTTPS) or Secure Shell (SSH).

**HTTPS**

1. Create a personal access token. Follow this guideline: https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token

2. Store your credential somewhere safe. You can use an R package like this [gitcreds](https://gitcreds.r-lib.org/) and [credentials](https://docs.ropensci.org/credentials/) to do so.


```r
pacman::p_load(gitcreds)

# First time only 
gitcreds_set()

# Check 
gitcreds_get()
```
3. If you get asked to provide your password when you pull or push, the password should be your GitHub token (to be precise, personal access token). 

**SSH**

If possible, I highly recommend using SSH. Using SSH is safer and also makes connecting GitHub easier. SSH has two keys (public and private). The public key could be stored on any server (e.g., GitHub) and the private key could be saved in your client (e.g., your laptop). Only when the two are matched, the system unlocks. 

1. First, read [this tutorial](https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh ) and create SSH keys.

2. Second, read [this tutorial](https://happygitwithr.com/ssh-keys.html) and check the keys and provide the public key to GitHub and add the private key to ssh-agent.

Next time, if you want to use SSH, remember the following.

```sh
# SSH
git@github.com:<user>/<repo>.git

# HTTPS
https://github.com/<user>/<repo>.git
```

**Additional tips**

When you try to clone a git repo, you can get the links like the above by clicking CODE action button on GitHub.

![](misc/ssh.png)

#### Configurations 

1. Method 1: using the terminal 

```sh

# User name and email 
$ git config --global user.name "Firstname Lastname"
$ git config --global user.email username@school.extension

```

2. Method 2: using RStudio (if you insist on using R)


```r
pacman::p_load(usethis)
use_git_config(user.name = "<Firstname Lastname>",
               user.email = "<username@school.extension>")
```

You're all set!

### Cloning a repository 

Let's clone a repository. As a test, I will clone the GitHub repository for the course I'm co-teaching in Spring 2021.

```sh
git clone https://github.com/PS239T/spring_2021
```

If you `cd spring_2021/` you can move to the cloned course repository. Cloning: copying a public GitHub repo (remote) -> Your machine 

If I made some changes in the remote repo, you can make them applied to your local copy by typing `git pull`. You may get promoted to provide password. Then type the following to switch the remote URL's address from HTTPS to SSH.

```sh
git remote set-url origin git@github.com:[user]/[repo]
```

If this doesn't work and get the following error, then try the following (this assumes that your SSH key was removed). If you're using Mac, try this instead: `ssh-add -k ~/.ssh/id_rsa` 

```sh
ssh-add ~/.ssh/id_rsa
```

If you still face difficulties, see [this stack overflow thread](https://stackoverflow.com/questions/13509293/git-fatal-could-not-read-from-remote-repository).

If you screwed something up in your local copy, you can just overwrite the local copy using the remote repo and make it exactly looks like the latter. 

```sh
# Download content from a remote repo 
git fetch origin

# Going back to origin/main
git reset --hard origin/main 

# Remove local files 
git clean -f
```

Note that the default branch name changed from master to main: https://github.com/github/renaming (Finally!) For this reason, if you're interacting with old repositories, the main branch name is likely to master.

**Additional tips**
You can see cloning and forking on GitHub and they sound similar. Let me differentiate them.

* Cloning: creating a local copy of a **public** GitHub repo. In this case, you have writing access to the repo.

* Forking (for open source projects): creating a copy of a **public** GitHub repo to your GitHub account then you can clone it. In this case, you don't have writing access to the repo. If you want your changes reflected in the original repo, you need to create pull requests. Don't worry about pull requests as I will explain the concept shortly. For more information, see [this documentation](https://docs.github.com/en/desktop/contributing-and-collaborating-using-github-desktop/cloning-and-forking-repositories-from-github-desktop). 

### Making a repository 

Create a new directory and move to it. 

```sh 
$ mkdir code_exercise 
$ cd code_exercise 
```

```sh
$ git init 
```

Alternatively, you can create a Git repository via GitHub and then clone it on your local machine. Perhaps, it is an easier path for new users (I also do this all the time). When you do this, I highly recommend adding README (more on why we do this in the following subsection).

```sh
$ git clone /path/to/repository
```

**Additional tips**
If you're unfamiliar with basic Git commands, then please refer to [this Git cheat sheet](http://rogerdudler.GitHub.io/git-guide/files/git_cheat_sheet.pdf).

### Commit changes 

These features show how Git works as a version control system. 

If you edited files or added new ones, then you need to update your repository. In Git terms, this action is called committing changes. 

My current pwd is `spring_2021`. I created a text file named `test` that contains text `jae`. You can check the file exists by typing `find "test"`.

The following is a typical workflow to reflect this change to the remote. 

```sh
$ git status # check what's changed. 
$ git add . # update every change. In Git terms, you're staging. 
$ git add file_name # or stage a specific file.
$ git commit -m "your comment" # your comment for the commit. 
$ git push origin main # commit the change. Origin is a default name given to a server by Git. `origin main` are optional. 
```

Another image from [Pro Git](https://git-scm.com/about/staging-area) well illustrates this process.

![Git Workflow](https://git-scm.com/images/about/index1@2x.png)

If you made a mistake, don't panic. You can't revert the process.

```sh
git reset --soft HEAD~1 # if you still want to keep the change, but you go back to t-1 
git reset --hard HEAD~1 # if you're sure the change is unnecessary 
```

Writing an informative commit is important. To learn how to do this better, see the following video: 

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/m0t1mOeAJgs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> Your Commits Should Tell a Story • Featuring Eliza Brock Marcum, GitHub Training & Guides </p>

```

### Push and pull (or fetch)

These features show how Git works as a collaboration tool. 

If you have not already done it, let's clone the PS239T directory on your local machine.

```sh
$ git clone https://github.com/PS239T/spring_2021 # clone 
```


**Additional tips 1**

If you try to remove `spring_2021` using `rm -r spring_2021/`, you will get an error about the write-protected regular file. Then, try `rm -rf spring_2021/`. 

Then, let's learn more about the repository.

```sh
$ git remote -v 
```

You should see something like the following:

```sh
origin	git@github.com:PS239T/spring_2021 (fetch)
origin	git@github.com:PS239T/spring_2021 (push)
```

If you want to see more information, then type `git remote show origin`

Previously, we learned how to send your data to save in the local machine to the remote (the GitHub server). You can do that by editing or creating files, committing, and then typing **git push**. 

Instead, if you want to update your local data with the remote data, you can type **git pull origin** (something like pwd in bash). Alternatively, you can use fetch (retrieve data from a remote). When you do that, Git retrieves the data and merges it into your local data.

```sh
$ git fetch origin
```

**Additional tips 2**

Developers usually use PR to refer pull requests. When you are making PRs, it's recommended to scope down (small PRs) because they are easier on reviewers and to test. To learn about how to accomplish this, see [this blog post](https://www.netlify.com/blog/2020/03/31/how-to-scope-down-prs/) by Sarah Drasner.

### Branching 

It's an advanced feature of Git's version control system that allows developers to "diverge from the main line of development and continue to do work without messing with that main line" according to [Scott Chacon and Ben Straub](https://git-scm.com/book/en/v1/Git-Branching). 

If you start working on a new feature, then create a new branch. 

```sh
$ git branch new_features
$ git checkout new_features
```

You can see the newly created branch by typing **git branch**.

In short, branching makes Git [works like](https://git-scm.com/book/en/v2/Getting-Started-Git-Basics) a mini file system.


### Other useful commands 

1. For tracking history

```sh
$ git diff # to see what changed (e.g., inside a file)
$ git log # to track who committed what
$ git log -S <pattern> # you can find a log that contains the pattern 
$ git checkout # to recover old files 
$ git revert # revert to the previous commit 
```

2. For removing and renaming files 

```sh
$ git rm file_name # remove 
$ git mv old_file_name new_file_name # rename a file 
```

How about removing a directory only from GitHub but not local?

```sh
git rm -r --cached <directory>
git commit -m "<message>"
git push
```

### Collaborations 

Two options. 

* Sharing a repository (suitable for a private project).
* Fork and pull (suitable for an open-source project). 
    ​    * The one who maintains the repository becomes the maintainer. 
    ​    * The others can [fork](https://help.GitHub.com/articles/about-forks/), make changes, and even [pull](https://help.GitHub.com/articles/about-pull-requests/) them back.

### Deployment: GitHub Pages 

GitHub pages are also useful to deploy websites. GitHub Pages deploy this book. 

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/4TrOCv5Kukk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> Webcast • Get Started with GitHub Pages • Featuring Dani Traphagen, GitHub Training & Guides </p>

```

### Tracking progress: GitHub Issues 

I use GitHub issues to collect and respond to questions on the projects and classes I am involved in. 

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/TJlYiMp8FuY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> Webcast • GitHub Issues • A Quick Look, GitHub Training & Guides </p>

```

### Project management: GitHub Dashboards

I use GitHub dashboards for almost every project that I have done. 

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/YxKhb3fxtsU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> GitHub Projects Demo: Automation, Kanban, Scrum, Issues, Pull Request, Milestones, Issues, Tasks by Brandan Jones </p>
```

### Using Git clients

Okay. Using command-line Git helps you understand how Git works. Also, you know that if possible, I'd love to do almost everything in the terminal. However, using the command-line Git is sometimes too complicated or too buggy. An alternative is using Git clients (GUI). 

I use [Git Kraken](https://www.gitkraken.com/) because it's free, works on almost every OS (Windows, Mac, and Linux), and quite versatile. It's instrumental in tracing and understand your development process (e.g., commits, branches, pull requests, comments). I also heard positive things about [GitHub Desktop](https://desktop.github.com/) (Windows and Mac) and [Sourcetree](https://www.sourcetreeapp.com/) (Windows). 

## Getting started in R 

### RStudio 

There are two main ways of interacting with R: using the console or using script files (plain text files containing your code).

If R is ready to accept commands, the R console shows a `>` prompt. If it receives a command (by typing, copy-pasting, or sent from the script editor using `Ctrl-Enter`; `Command-Enter` will also work on Macs), R will try to execute it, and when ready, show the results and come back with a new `>`-prompt to wait for further commands. This is the equivalent of the `$` in your terminal. 

### Basic Syntax

**Comments**

Use `#` signs to comment. Comment liberally in your R scripts. Anything to the right of a `#` is ignored by R. For those of you familiar with other languages, there is no doc string, or equivalent to `"""` in R.

**Assignment operator**

`<-` is the assignment operator. It assigns values on the right to objects on the left. So, after executing `x <- 3`, the value of `x` is `3`. The arrow can be read as 3 **goes into** `x`.  You can also use `=` for assignments. 


```r
USweird <- "Why use lb for pound!" # Use this

"Why use lb for pound!" = USweird
```

Nonetheless, *can* do not mean you *should*. It is good practice to use `<-` for assignments. `=` should only be used to specify the values of arguments of functions. This is what Google and Hadley Wickham recommend as well. If they don't convince you enough, here's [a real example](https://csgillespie.wordpress.com/2010/11/16/assignment-operators-in-r-vs/).


```r
mean(x = 1:10) # Does it save x?
```

```
## [1] 5.5
```

```r
rm(x)
```

```
## Warning in rm(x): object 'x' not found
```

```r
mean(x <- 1:10) # Does it save x?
```

```
## [1] 5.5
```

```r
rm(x)
```

**Printing**

In R, an object's contents can be printed by either simply executing the object name or calling the ```print()``` function.

**Help**

* `?` + object opens a help page for that specific object
* `??` + object searches help pages containing the name of the object


```r
?mean
??mean
help(mean)

# The above three will do the same. 

example(ls) # provides an example(s) for how to use ls 

help.search("visualization") # search functions and packages that have "visualization" in their descriptions
```

### Environment 

Environment = a collection of pairs 

#### Objects 

- List objects in your current environment


```r
# Create a numeric object 
x <- c(1,2,3,4,5)

# List the object 
ls()

# Remove the object 
rm(x)
```

- Remove objects from your current environment


```r
# Create an object 
x <- 5

# Remove the object 
rm(x)
```

- Remove all objects from your current environment


```r
# Create an object 
a <- 7

b <- 3

# Remove the object 
rm(list = ls())
```

- Force memory release 


```r
# Garbage collect; for more information, type ?gc() 

gc()
```

#### Packages 

`install.packages(package-name)` will download a package from one of the CRAN mirrors, assuming that a binary is available for your operating system. 


```r
# From CRAN
install.packages("dplyr") 

# Load package 
library(dplyr)

# From GitHub 
devtools::install_GitHub("jaeyk/tidytweetjson") # my own package 

# Unload package 
# detach("package:stats", unload=TRUE)
```

**Tips**

If you have multiple packages to install, then please consider using pacman package. The following is the example. First, you install pacman. Then, you load several libraries by using `p_load()` method.


```r
install.packages("pacman")

pacman::p_load(
  ggplot2,
  dplyr, 
  broom
)
```

If you don't like to use `pacman`, then the other option is to create a list (we're going to learn what is list soon).


```r
pkgs <- c("ggplot2", "dplyr", "broom")

install.packages(pkgs)
```
  
Still, we have to write two lines. The simpler, the better, right? Here's another approach that can simplify the code further.

Note that `lapply()` applies (there's a family of apply functions) a function to a list. In this case, library to pkgs. apply is an advanced concept, which is related to anonymous functions. We will learn about it later when we study functions.


```r
inst <- lapply(pkgs, library, 
               character.only = TRUE)
```

## Project-oriented research

### Computational reproducibility

* Replication = code + data 

* Computational reproduciblity = code + data + environment + distribution 

* Reproducibility checklist by [Roger Peng](http://www.biostat.jhsph.edu/~rpeng/)

    1. Start with science (avoid vague questions and concepts)
    
    2. Don't do things by hand (not only about automation but also documentation)
    
    3. Don't point and click (same problem)
    
    4. Teach a computer (automation also solves documentation to some extent)
    
    5. Use some version control 
    
    6. Don't save output (instead, keep the input and code)
    
    7. Set your seed 
    
    8. Think about the entire pipeline 

#### Setup


```r
pacman::p_load(
  tidyverse, # tidyverse
  here # computational reproducibility
)
```

#### Motivation 

Why do you need to make your research project computationally reproducible?

For your self-interest and public benefits. 

![](https://GitHub.com/dlab-berkeley/efficient-reproducible-project-management-in-R/blob/master/misc/screenshot.png?raw=true)

#### How to organize files in a project 

You won't be able to reproduce your project unless it is efficiently organized. 

Step 1. [**Environment**](https://environments.rstudio.com/) is part of your project. If someone can't reproduce your environment, they won't be able to run your code.

- Launch R Studio. Tools > Global Options. You **should not** check Restore .RData into workspace at startup. Also, set the saving workspace option to **NEVER.**

Step 2. For each project, create a project directory named after the project. 

name_of_the_project 

- data: 
  - raw 
  - processed (all processed, cleaned, and tided)
- figures 
- packrat (optional) 
- reports (PDF, HTML, TEX, etc.,) 
- results (model outcomes, etc.,)
- scripts (i.e., functions)
- .gitignore (for Git)
- name_of_project.Rproj (for R)
- README.md (for Git) 



```r
# Don't name it a project. Use a more informative name. For instance, `us_election`, not `my_project.`

dir.create("../us_election")
```

Step 3. Launch R Studio. Choose File > New project > Browse existing directories > Create project. This allows each project has its workspace. 

Step 4. Organize files by putting them in separate subdirectories and sensibly naming them.

- Treat raw data as read-only (raw data should be RAW!) and put it in the `data` subdirectory.

    - Again, note that version control does not need to replace backup. You still need to back up your raw data. 


```r
dir.create(here::here("us_election", "data"))
```

- Separate read-only data from processed data and put in the `processed_data` subdirectory.


```r
dir.create(here::here("us_election", "processed_data"))
```

- Put your code in the `src` subdirectory. 


```r
dir.create(here::here("us_election", "src"))
```

- Put generated outputs (e.g., tables, figures) in the `outputs` subdirectory and treat them as disposable.


```r
dir.create(here::here("us_election", "outputs"))
```

- Put your custom functions in the `functions` subdirectory. You can gather some of these functions and distribute them as an open-source library. 


```r
dir.create(here::here("us_election", "functions"))
```

Are you tired of creating these directories one by one? Why not automate? See the following example. You can save this function as a rscript (e.g., `setup.r`) and run it in the terminal using `Rscript <script name>.`


```r
if (!require(pacman)) install.packages("pacman")

# Load here
pacman::p_load(
  purrr, # functional programming
  here # computational reproducibility
)

# Custom function
create_dirs <- function(name) {
  dir.create(here(name))
}

# Apply function 
purrr::map(c("data", "processed_data", "src", "outputs", "functions"), create_dirs)
```

**Challenge**

Set a project structure for a project named "starwars". 

#### How to organize code in an R markdown file 

- In addition to environment, **workflow** is an essential component of project efficiency and reproducibility. 

- What is R markdown? An R package, developed by [Yihui Xie](https://yihui.org/en/), provides an authoring framework for data science. Xie is also a developer of many widely popular R packages such as `knitr`, [`xaringan`](https://GitHub.com/yihui/xaringan) (cool kids use xaringan not [Beamer](https://en.wikipedia.org/wiki/Beamer_(LaTeX)) these days), `blogdown` (used to create [my personal website](https://jaeyk.GitHub.io/)), and `bookdown` (used to create this book) among many others.

  - Many applications: [reports](https://rstudio.GitHub.io/distill/basics.html), [presentations](https://bookdown.org/yihui/rmarkdown/xaringan.html), [dashboards](https://rmarkdown.rstudio.com/flexdashboard/), [websites](https://bookdown.org/yihui/rmarkdown/websites.html)  
  - Check out [Communicating with R markdown workshop](https://ysc-rmarkdown.netlify.app/) by [Alison Hill](https://alison.rbind.io/) (RStudio)
    - Alison Hill is a co-author of [`blogdown: Creating Websites with R Markdown.`](https://bookdown.org/yihui/blogdown/) 
  - Key strengths: dynamic reporting + reproducible science + easy deployment


![Concept map for R Markdown. By Gabriela Sandoval, Florencia D'Andrea, Yanina Bellini Saibene, Monica Alonso.](https://GitHub.com/rstudio/concept-maps/raw/master/en/rmarkdown.svg)


```{=html}
<iframe width="560" height="315" src="https://www.youtube.com/embed/s9aWmU0atlQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p>R Markdown The bigger picture - Garrett Grolemund</p>
```

```{=html}
<iframe width="560" height="315" src="https://www.youtube.com/embed/Xn5AmUf7gDQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p>R-Ladies Oslo (English) - Reports to impress your boss! Rmarkdown magic - Athanasia Mowinckel</p>
```

- R Markdown basic syntax 


```r
# Header 1
## Header 2
### Header 3
```

- Use these section headers to indicate workflow.


```r
# Import packages and data
# Tidy data
# Wrangle data
# Model data
# Visualize data
```

- Press `ctrl + shift + o`. You can see a document outline based on these headers. This is a nice feature for finding the code you need to focus on. 

- If your project's scale is large, divide these sections into files, numbers, and save them in the `code` subdirectory. 

   - 01_wrangling.Rmd
   - 02_modeling.Rmd 
   ... 

#### Making a project computationally reproducible

- `setwd()`: set a working directory. 

- Note that using `setwd()` is not a reproducible way to set up your project. For instance, none will be able to run the following code except me.


```r
# Set a working directory 
setwd("/home/jae/starwars")

# Do something 
ggplot(mtcars, aes(x = mpg, y = wt)) +
   geom_point()

# Export the object. 
# dot means the working directory set by setwd()
ggsave("./outputs/example.png") # This is called relative path 
```

- Instead, learn how to use `here()`'.

   - Key idea: separate workflow (e.g., workspace information) from products (code and data). For more information, read Jenny Bryan's excellent piece on [project-oriented workflow](https://www.tidyverse.org/blog/2017/12/workflow-vs-script/).

   - Example 


```r
# New: Reproducible 

ggplot(mtcars, aes(x = mpg, y = wt)) +
   geom_point()

ggsave(here("project", "outputs", "example.png"))
```

   - How `here` works 

   `here()` function shows what's the top-level project directory. 


```r
here::here()
```
   - Build a path including subdirectories 


```r
here::here("project", "outputs")
           #depth 1   #depth 2
```
   - How `here` defines the top-level project directory. The following list came from [the here package vignette](https://GitHub.com/jennybc/here_here)).

      - Is a file named .here present?
      - Is this an RStudio Project? (**Note that we already set up an RStudio Project!** So, if you use RStudio's project feature, then you are ready to use `here`.)
      - Is this an R package? Does it have a DESCRIPTION file?
      - Is this a remake project? Does it have a file named `remake.yml`?
      - Is this a projectile project? Does it have a file named `.projectile`?
      - Is this a checkout from a version control system? Does it have a directory named `.git` or `.svn`? Currently, only Git and Subversion are supported.

      - If there's no match then use `set_here()` to create an empty `.here` file. 

**Challenge**

1. Can you define computational reproducibility? 
2. Can you explain why sharing code and data is not enough for computational reproducibility

### References 

- Code and data management 

  - ["Code and Data for the Social Sciences: A Practitioner's Guide"](https://web.stanford.edu/~gentzkow/research/CodeAndData.pdf) by Matthew Gentkow and Jesse M. Shapiro 
  
- Project-oriented research
   
  - Computational reproducibility 

    - ["Good Enough Practices in Scientific Computing"](https://GitHub.com/swcarpentry/good-enough-practices-in-scientific-computing/blob/gh-pages/good-enough-practices-for-scientific-computing.pdf) by PLOS
      
    - [Project Management with RStudio](https://swcarpentry.GitHub.io/r-novice-gapminder/02-project-intro/) by Software Carpentry
      
    - [Initial steps toward reproducible research](https://kbroman.org/steps2rr/) by Karl Broman
      
  - Version control 
   
    - [Version Control with Git](https://swcarpentry.GitHub.io/git-novice/) by Software Carpentry
   
    - [The Plain Person’s Guide to Plain Text Social Science](http://plain-text.co/) by Kieran Healy 

## Writing code: How to code like a professional

### Write readable code

- What is code style?

> Every major open-source project has its style guide: a set of conventions (sometimes arbitrary) about writing code for that project. It is much easier to understand a large codebase when all the code in it is in a consistent style. - [Google Style Guides](https://google.GitHub.io/styleguide/) 

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/UjhX2sVf0eg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
allowfullscreen></iframe>

<p>10 Tips For Clean Code - Michael Toppa</p>

```

- How to avoid smelly code? 

  - Check out [the code-smells Git repository](https://GitHub.com/jennybc/code-smells-and-feels#readme) by Jenny Bryan. 
  
```{=html}
<iframe width="560" height="315" src="https://www.youtube.com/embed/7oyiPBjLAWY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> Code smells and feels - Jenny Bryan</p>

<p> "Code smell" is an evocative term for that vague feeling of unease we get when reading certain bits of code. It's not necessarily wrong, but neither is it obviously correct. We may be reluctant to work on such code because past experience suggests it's going to be fiddly and bug-prone. In contrast, there's another type of code that just feels good to read and work on. What's the difference? If we can be more precise about code smells and feels, we can be intentional about writing code that is easier and more pleasant to work on. I've been fortunate to spend the last couple of years embedded in a group of developers working on the tidyverse and r-lib packages. Based on this experience, I'll talk about specific code smells and deodorizing strategies for R. - Jenny Bryan</p>
```

- Naming matters 

  - When naming files, remember the following three rules:
      - Machine-readable (avoid spaces, punctuation, periods, and any other special characters except _ and -)
      - Human readable (should be meaningful. No text1, image1, etc.,)
      - Ordering (e.g., 01, 02, 03,  ... )
    


```r
# Good
fit_models.R

# Bad
fit models.R
```

  - When naming objects:
      - Don't use special characters.
      - Don't capitalize.


```r
# Good 
day_one
    
# Bad 
DayOne
```

  - When naming functions:
      - Don't use special characters.
      - Don't capitalize.
      - Use `verbs` instead of `nouns`. (Functions do something!)
    

```r
# Good 
run_rdd 

# Bad 
rdd
```
    
- Spacing 

Some people do spacing by pressing the Tab key and others do it by pressing the Space key multiple times (and this is a serious subject).

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/SsoOG6ZeyUI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> Tabs versus Spaces </p>

```



```r
# Good
x[, 1] 

mean(x, na.rm = TRUE) 

# Bad

x[,1]

mean (x, na.rm = TRUE)
```

- Indenting 

Indent at least 4 spaces. Note that some people, including none other than [Roger Peng](https://simplystatistics.org/2018/07/27/why-i-indent-my-code-8-spaces/), indent 8 spaces. The below example shows how you can change the default indentation setting using the RStudio configuration.
    
![Roger Peng's tweet](https://pbs.twimg.com/media/CuHHs7yXgAAFWeh?format=jpg&name=360x360)


```r
# Good
if (y < 0) {
  message("y is negative")
}

# Bad
if (y < 0) {
message("Y is negative")}
```

- Long lines


```r
# Good
do_something_very_complicated(
  something = "that",
  requires = many,
  arguments = "some of which may be long"
)

# Bad
do_something_very_complicated("that", requires = many, arguments =
                              "some of which may be long"
                              )
```

- Comments 
   - Use comments to explain your decisions. 
   - But, show your code; Do not try to explain your code by comments.
   - Also, try to comment out rather than delete the code that you experiment with. 


```r
# Average sleep hours of Jae
jae %>%
  # By week
  group_by(week) %>%
  # Mean sleep hours 
  summarise(week_sleep = mean(sleep, na.rm = TRUE))
```

- Pipes (chaining commands)


```r
# Good
iris %>%
  group_by(Species) %>%
  summarize_if(is.numeric, mean) %>%
  ungroup() %>%
  gather(measure, value, -Species) %>%
  arrange(value)

# Bad
iris %>% group_by(Species) %>% summarize_all(mean) %>%
ungroup %>% gather(measure, value, -Species) %>%
arrange(value)
```

- Additional tips 

- Use `lintr` to check whether your code complies with a recommended style guideline (e.g., `tidyverse`) and `styler` package to format your code according to the style guideline.

![how lintr works](https://camo.GitHubusercontent.com/6cb80270269165a8d3046d2da03cbf2b8f19ee2f/687474703a2f2f692e696d6775722e636f6d2f61635632374e562e676966)

### Write reusable code 

- Pasting 

> Copy-and-paste programming, sometimes referred to as just pasting, is the production of highly repetitive computer programming code, as produced by copy and paste operations. It is primarily a pejorative term; those who use the term are often implying a lack of programming competence. It may also be the result of technology limitations (e.g., an insufficiently expressive development environment) as subroutines or libraries would normally be used instead. However, there are occasions when copy-and-paste programming is considered acceptable or necessary, such as for boilerplate, loop unrolling (when not supported automatically by the compiler), or certain programming idioms, and it is supported by some source code editors in the form of snippets. - [Wikipedia](https://en.wikipedia.org/wiki/Copy-and-paste_programming) 

- It's okay for pasting for the first attempt to solve a problem. But if you copy and paste three times (a.k.a. [Rule of Three](https://en.wikipedia.org/wiki/Rule_of_three_(computer_programming)) in programming), something's wrong. You're working too hard. You need to be lazy. What do I mean and how can you do that?

- The following exercise was inspired by [Wickham's example](http://adv-r.had.co.nz/Functional-programming.html).

- Let's imagine `df` is a survey dataset. 

    - `a, b, c, d` = Survey questions 

    - `-99`: non-responses 
    
    - Your goal: replace `-99` with `NA` 
    

```r
# Data

set.seed(1234) # for reproducibility 

df <- tibble("a" = sample(c(-99, 1:3), size = 5 , replace= TRUE),
             "b" = sample(c(-99, 1:3), size = 5 , replace= TRUE),
             "c" = sample(c(-99, 1:3), size = 5 , replace= TRUE),
             "d" = sample(c(-99, 1:3), size = 5 , replace= TRUE))
```


```r
# Copy and paste 
df$a[df$a == -99] <- NA
df$b[df$b == -99] <- NA
df$c[df$c == -99] <- NA
df$d[df$d == -99] <- NA

df
```

```
## # A tibble: 5 x 4
##       a     b     c     d
##   <dbl> <dbl> <dbl> <dbl>
## 1     3     3     3     1
## 2     3     2     3     1
## 3     1    NA     1     2
## 4     1    NA     2     1
## 5    NA     1     1     3
```

- Using a function 
   - function: input + computation + output 
   - If you write a function, you gain efficiency because you don't need to copy and paste the computation part. 


```r
# Create a custom function
fix_missing <- function(x) { # INPUT
  x[x == -99] <- NA # COMPUTATION
  x # OUTPUT 
}

# Apply the function to each column (vector)
# This iterated part can and should be automated.
df$a <- fix_missing(df$a)
df$b <- fix_missing(df$b)
df$c <- fix_missing(df$c)
df$d <- fix_missing(df$d)

df
```

- Automation
   - Many options for automation in R: `for loop`, `apply` family, etc. 
   - Here's a tidy solution that comes from the `purrr` package.
   - The power and joy of one-liner. 


```r
df <- purrr::map_df(df, fix_missing) # What is this magic? We will unpack the blackbox (`map_df()`) later.

df
```

- Takeaways

1. Your code becomes more reusable, when it's easier to **change, debug, and scale-up**. Don't repeat yourself and embrace the power of lazy programming. 

> Lazy, because only lazy programmers will want to write the kind of tools that might replace them in the end. Lazy, because only a lazy programmer will avoid writing monotonous, repetitive code—thus avoiding redundancy, the enemy of software maintenance and flexible refactoring. Mostly, the tools and processes that come out of this endeavor fired by laziness will speed up the production. -  [Philipp Lenssen](http://blogoscoped.com/archive/2005-08-24-n14.html)
  
2. Only when your code becomes **reusable**, you would become **efficient** in your data work. Otherwise, you need to start from scratch or copy and paste, when you work on a new project.

> Code reuse aims to save time and resources and reduce redundancy by taking advantage of assets that have already been created in some form within the software product development process.[2] The key idea in reuse is that parts of a computer program written at one time can be or should be used in the construction of other programs written at a later time. - Wikipedia 

### Test your code systematically 

I strongly recommend switching from adhoc testing to formal automated testing (i.e., unit testing).

> Whenever you are tempted to type something into a print statement or a debugger expression, write it as a test instead. — Martin Fowler the author of *Refactoring* 

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/bx92oCMxUhg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> R language tip: Test your code with testthat by InfoWorld /p>
```


```r
if (!require(testthat)) install.packages("testthat")
```

```
## Loading required package: testthat
```

```
## 
## Attaching package: 'testthat'
```

```
## The following object is masked from 'package:dplyr':
## 
##     matches
```

```
## The following object is masked from 'package:purrr':
## 
##     is_null
```

```
## The following objects are masked from 'package:readr':
## 
##     edition_get, local_edition
```

```
## The following object is masked from 'package:tidyr':
## 
##     matches
```

```r
pacman::p_load(testthat)

context("Variable check")

test_that("Check whether instructor variable is setup correctly", {
  
  instructors <- c("Jae", "Nick")

  expect_equal(class(instructors), "character")

}
)
```

```
## Test passed
```

Inspired by an example in Hadley Wickham's [R Journal paper](https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf
) (2011).


```r
context("Model check")

test_that("Check whether the model is lm", {
  
  model <- lm(mpg ~ wt, data = mtcars)
  
  # Passes
  expect_that(model, is_a("lm"))

  # Fails
  expect_that(model, is_a("glm"))

})
```

## Run tests 


```r
test_file(file.choose()) # file 

test_dir() # directory

auto_test() # the test code tested when you save the file 
```

### Asking questions: Minimal reproducible example

- Chances are you're going to use StackOverflow a lot to solve a pressing problem you face. However, others can't understand/be interested in your problem unless you can provide an example that they can understand with minimal effort. Such an example is called a minimal reproducible example. 

- Read [this StackOverFlow post](https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example) to understand the concept and best practices.

- Simply put, an MRE consists of the following items:

    - A minimal dataset 
    - The minimal burnable code
    - The necessary information on package, R version, system (use `sessionInfo()`)
    - A seed for reproducibility (`set.seed()`), if you used a random process. 

In practice, use the `reprex` package to create the code component of the MRE.


```r
if (!require(reprex)) install.packages("reprex")
```

Copy the following code and type `reprex()` in the console.


```r
gpa <- c(3, 4, 4, 3)
mean(gpa)
```

### References

- Writing code 

   - Style guides 
      - R 
         - [Google's R style guide](https://google.GitHub.io/styleguide/Rguide.xml)
         - [R code style guide](http://r-pkgs.had.co.nz/r.html) by Hadley Wickham 
         - [The tidyverse style guide](http://style.tidyverse.org/) by Hadley Wickham
      - Python 
         - [Google Python Style Guide](https://GitHub.com/google/styleguide/blob/gh-pages/pyguide.md)
         - [Code Style](https://docs.python-guide.org/writing/style/#zen-of-python) by the Hitchhiker's Guide to Python

<!--chapter:end:02_intro.Rmd-->

# Tidy data and its friends {#tidy_data}



## Setup

-   Check your `dplyr` package is up-to-date by typing `packageVersion("dplyr")`. If the current installed version is less than 1.0, then update by typing `update.packages("dplyr")`. You may need to restart R to make it work.


```r
ifelse(packageVersion("dplyr") >= 1,
  "The installed version of dplyr package is greater than or equal to 1.0.0", update.packages("dplyr")
)
```

```
## [1] "The installed version of dplyr package is greater than or equal to 1.0.0"
```

```r
if (!require("pacman")) install.packages("pacman")
```

```
## Loading required package: pacman
```

```r
pacman::p_load(
  tidyverse, # the tidyverse framework
  skimr, # skimming data 
  here, # computational reproducibility
  infer, # statistical inference 
  tidymodels, # statistical modeling 
  gapminder, # toy data
  nycflights13, # for exercise
  ggthemes, # additional themes
  ggrepel, # arranging ggplots
  patchwork, # arranging ggplots
  broom, # tidying model outputs
  waldo # side-by-side code comparison
)
```

The rest of the chapter follows the basic structure in [the Data Wrangling Cheat Sheet](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) created by RStudio.

## R Data structures 

To make the best use of the R language, you'll need a strong understanding of the basic data types and data structures and how to operate on those. R is an **object-oriented** language, so the importance of this cannot be understated. 

It is **critical** to understand because these are the objects you will manipulate on a day-to-day basis in R, and they are not always as easy to work with as they sound at the outset. Dealing with object conversions is one of the most common sources of frustration for beginners.

> To understand computations in R, two slogans are helpful:
  - Everything that exists is an object.
  - Everything that happens is a function call.
  
> __John Chambers__the creator of S (the mother of R)

1. [Main Classes](#main-classes) introduces you to R's one-dimensional or atomic classes and data structures. R has five basic atomic classes: logical, integer, numeric, complex, character. Social scientists don't use complex classes. (Also, remember that we rarely use trigonometry.)

2. [Attributes](#attributes) takes a small detour to discuss attributes, R's flexible metadata specification. Here, you'll learn about factors, an important data structure created by setting attributes of an atomic vector. R has many data structures: vector, list, matrix, data frame, factors, tables.


![Concept map for data types. By Meghan Sposato, Brendan Cullen, Monica Alonso.](https://github.com/rstudio/concept-maps/raw/master/en/data-types.svg)


## 1D data: Vectors 

### Atomic classes

`R`'s main atomic classes are:

* character (or a "string" in Python and Stata)
* numeric (integer or float)
* integer (just integer)
* logical (booleans)

| Example | Type |
| ------- | ---- |
| "a", "swc" | character |
| 2, 15.5 | numeric | 
| 2 (Must add a `L` at end to denote integer) | integer |
| `TRUE`, `FALSE` | logical |

Like Python, R is dynamically typed. There are a few differences in terminology, however, that are pertinent. 

- First, "types" in Python are referred to as "classes" in R. 

What is a class?

![from https://brilliant.org/](https://ds055uzetaobb.cloudfront.net/brioche/uploads/pJZt3mh3Ht-prettycars.png?width=2400)

- Second, R has different names for the types string, integer, and float --- specifically **character**, **integer** (not different), and **numeric**. Because there is no "float" class in R, users tend to default to the "numeric" class when they want to work with numerical data.

The function for recovering object classes is ```class()```. L suffix to qualify any number with the intent of making it an explicit integer. See more from the [R language definition](https://cran.r-project.org/doc/manuals/R-lang.html).


```r
class(3)
```

```
## [1] "numeric"
```

```r
class(3L)
```

```
## [1] "integer"
```

```r
class("Three")
```

```
## [1] "character"
```

```r
class(F)
```

```
## [1] "logical"
```

### Data structures

R's base data structures can be organized by their dimensionality (1d, 2d, or nd) and whether they're homogeneous (all contents must be of the same type) or heterogeneous (the contents can be of different types). This gives rise to the five data types most often used in data analysis: 

|    | Homogeneous   | Heterogeneous |
|----|---------------|---------------|
| 1d | Atomic vector | List          |
| 2d | Matrix        | Data frame    |
| nd | Array         |               |

Each data structure has its specifications and behavior. For our purposes, an important thing to remember is that R is always **faster** (more efficient) working with homogeneous (**vectorized**) data.

#### Vector properties

Vectors have three common properties:

* Class, `class()`, or what type of object it is (same as `type()` in Python).
* Length, `length()`, how many elements it contains (same as `len()` in Python).
* Attributes, `attributes()`, additional arbitrary metadata.

They differ in the types of their elements: all atomic vector elements must be the same type, whereas the elements of a list can have different types.

#### Creating different types of atomic vectors

Remember, there are four common types of vectors: 
* `logical` 
* `integer` 
* `numeric` (same as `double`)
* `character`.

You can create an empty vector with `vector()` (By default, the mode is `logical`. You can be more explicit as shown in the examples below.) It is more common to use direct constructors such as `character()`, `numeric()`, etc.


```r
x <- vector()

# with a length and type
vector("character", length = 10)
```

```
##  [1] "" "" "" "" "" "" "" "" "" ""
```

```r
## character vector of length 5
character(5)
```

```
## [1] "" "" "" "" ""
```

```r
numeric(5)
```

```
## [1] 0 0 0 0 0
```

```r
logical(5)
```

```
## [1] FALSE FALSE FALSE FALSE FALSE
```

Atomic vectors are usually created with `c()`, which is short for concatenate:


```r
x <- c(1, 2, 3)

x
```

```
## [1] 1 2 3
```

```r
length(x)
```

```
## [1] 3
```

`x` is a numeric vector. These are the most common kind. You can also have logical vectors. 


```r
y <- c(TRUE, TRUE, FALSE, FALSE)

y
```

```
## [1]  TRUE  TRUE FALSE FALSE
```

Finally you can have character vectors:


```r
kim_family <- c("Jae", "Sun", "Jane")

is.integer(kim_family) # integer?
```

```
## [1] FALSE
```

```r
is.character(kim_family) # character?
```

```
## [1] TRUE
```

```r
is.atomic(kim_family) # atomic?
```

```
## [1] TRUE
```

```r
typeof(kim_family) # what's the type?
```

```
## [1] "character"
```

**Short exercise: Create and examine your vector**  

Create a character vector called `fruit` that contains 4 of your favorite fruits. Then evaluate its structure using the commands below.


```r
# First, create your fruit vector
# YOUR CODE HERE
fruit <-

  # Examine your vector
  length(fruit)
class(fruit)
str(fruit)
```

**Add elements**

You can add elements to the end of a vector by passing the original vector into the `c` function, like so:


```r
z <- c("Beyonce", "Kelly", "Michelle", "LeToya")

z <- c(z, "Farrah")

z
```

```
## [1] "Beyonce"  "Kelly"    "Michelle" "LeToya"   "Farrah"
```

More examples of vectors


```r
x <- c(0.5, 0.7)

x <- c(TRUE, FALSE)

x <- c("a", "b", "c", "d", "e")

x <- 9:100
```

You can also create vectors as a sequence of numbers:


```r
series <- 1:10

series
```

```
##  [1]  1  2  3  4  5  6  7  8  9 10
```

```r
seq(10)
```

```
##  [1]  1  2  3  4  5  6  7  8  9 10
```

```r
seq(1, 10, by = 0.1)
```

```
##  [1]  1.0  1.1  1.2  1.3  1.4  1.5  1.6  1.7  1.8  1.9  2.0  2.1  2.2  2.3  2.4
## [16]  2.5  2.6  2.7  2.8  2.9  3.0  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9
## [31]  4.0  4.1  4.2  4.3  4.4  4.5  4.6  4.7  4.8  4.9  5.0  5.1  5.2  5.3  5.4
## [46]  5.5  5.6  5.7  5.8  5.9  6.0  6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9
## [61]  7.0  7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9  8.0  8.1  8.2  8.3  8.4
## [76]  8.5  8.6  8.7  8.8  8.9  9.0  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8  9.9
## [91] 10.0
```

Atomic vectors are always flat, even if you nest `c()`'s:


```r
c(1, c(2, c(3, 4)))
```

```
## [1] 1 2 3 4
```

```r
# the same as
c(1, 2, 3, 4)
```

```
## [1] 1 2 3 4
```

**Types and Tests**

Given a vector, you can determine its class with `class`, or check if it's a specific type with an "is" function: `is.character()`, `is.numeric()`, `is.integer()`, `is.logical()`, or, more generally, `is.atomic()`.


```r
char_var <- c("harry", "sally")

class(char_var)
```

```
## [1] "character"
```

```r
is.character(char_var)
```

```
## [1] TRUE
```

```r
is.atomic(char_var)
```

```
## [1] TRUE
```

```r
num_var <- c(1, 2.5, 4.5)

class(num_var)
```

```
## [1] "numeric"
```

```r
is.numeric(num_var)
```

```
## [1] TRUE
```

```r
is.atomic(num_var)
```

```
## [1] TRUE
```

NB: `is.vector()` does not test if an object is a vector. Instead, it returns `TRUE` only if the object is a vector with no attributes apart from names. Use `is.atomic(x) || is.list(x)` to test if an object is actually a vector.

**Coercion**

All atomic vector elements must be the same type, so when you attempt to combine different types, they will be __coerced__ to the most flexible type. Types from least to most flexible are: logical, integer, double, and character. 

For example, combining a character and an integer yields a character:


```r
str(c("a", 1))
```

```
##  chr [1:2] "a" "1"
```

**Guess what the following do without running them first**


```r
c(1.7, "a")

c(TRUE, 2)

c("a", TRUE)
```

Notice that when a logical vector is coerced to an integer or double, `TRUE` becomes 1 and `FALSE` becomes 0. This is very useful in conjunction with `sum()` and `mean()`


```r
x <- c(FALSE, FALSE, TRUE)

as.numeric(x)
```

```
## [1] 0 0 1
```

```r
# Total number of TRUEs
sum(x)
```

```
## [1] 1
```

```r
# Proportion that are TRUE
mean(x)
```

```
## [1] 0.3333333
```

Coercion often happens automatically. This is called implicit coercion. Most mathematical functions (`+`, `log`, `abs`, etc.) will coerce to a numeric or integer, and most logical operations (`&`, `|`, `any`, etc) will coerce to a logical. You will usually get a warning message if the coercion might lose information. 


```r
1 < "2"
```

```
## [1] TRUE
```

```r
"1" > 2
```

```
## [1] FALSE
```

You can also coerce vectors explicitly coerce with `as.character()`, `as.numeric()`, `as.integer()`, or `as.logical()`. Example:


```r
x <- 0:6

as.numeric(x)
```

```
## [1] 0 1 2 3 4 5 6
```

```r
as.logical(x)
```

```
## [1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
```

```r
as.character(x)
```

```
## [1] "0" "1" "2" "3" "4" "5" "6"
```

Sometimes coercions, especially nonsensical ones, won’t work.


```r
x <- c("a", "b", "c")

as.numeric(x)
```

```
## Warning: NAs introduced by coercion
```

```
## [1] NA NA NA
```

```r
as.logical(x)
```

```
## [1] NA NA NA
```

**Short Exercise**


```r
# 1. Create a vector of a sequence of numbers between 1 to 10.

# 2. Coerce that vector into a character vector

# 3. Add the element "11" to the end of the vector

# 4. Coerce it back to a numeric vector.
```

#### Lists

Lists are also vectors, but different from atomic vectors because their elements can be of any type. In short, they are generic vectors. You construct lists by using `list()` instead of `c()`: 

Lists are sometimes called recursive vectors, because a list can contain other lists. This makes them fundamentally different from atomic vectors. 


```r
x <- list(1, "a", TRUE, c(4, 5, 6))

x
```

```
## [[1]]
## [1] 1
## 
## [[2]]
## [1] "a"
## 
## [[3]]
## [1] TRUE
## 
## [[4]]
## [1] 4 5 6
```

You can coerce other objects using `as.list()`. You can test for a list with `is.list()`


```r
x <- 1:10

x <- as.list(x)

is.list(x)
```

```
## [1] TRUE
```

```r
length(x)
```

```
## [1] 10
```

`c()` will combine several lists into one. If given a combination of atomic vectors and lists, `c()` (con**c**atenate) will coerce the vectors to lists before combining them. Compare the results of `list()` and `c()`:


```r
x <- list(list(1, 2), c(3, 4))

y <- c(list(1, 2), c(3, 4))

str(x)
```

```
## List of 2
##  $ :List of 2
##   ..$ : num 1
##   ..$ : num 2
##  $ : num [1:2] 3 4
```

```r
str(y)
```

```
## List of 4
##  $ : num 1
##  $ : num 2
##  $ : num 3
##  $ : num 4
```

You can turn a list into an atomic vector with `unlist()`. If the elements of a list have different types, `unlist()` uses the same coercion rules as `c()`.


```r
x <- list(list(1, 2), c(3, 4))

x
```

```
## [[1]]
## [[1]][[1]]
## [1] 1
## 
## [[1]][[2]]
## [1] 2
## 
## 
## [[2]]
## [1] 3 4
```

```r
unlist(x)
```

```
## [1] 1 2 3 4
```

Lists are used to build up many of the more complicated data structures in R. For example, both data frames and linear models objects (as produced by `lm()`) are lists:


```r
is.list(mtcars)
```

```
## [1] TRUE
```

```r
mod <- lm(mpg ~ wt, data = mtcars)

is.list(mod)
```

```
## [1] TRUE
```

For this reason, lists are handy inside functions. You can "staple" together many different kinds of results into a single object that a function can return.

A list does not print to the console like a vector. Instead, each element of the list starts on a new line.


```r
x.vec <- c(1, 2, 3)
x.list <- list(1, 2, 3)
x.vec
```

```
## [1] 1 2 3
```

```r
x.list
```

```
## [[1]]
## [1] 1
## 
## [[2]]
## [1] 2
## 
## [[3]]
## [1] 3
```

For lists, elements are **indexed by double brackets**. Single brackets will still return a(nother) list. (We'll talk more about subsetting and indexing in the fourth lesson.)

**Exercises**

1. What are the four basic types of atomic vector? How does a list differ from an
   atomic vector?

2. Why is `1 == "1"` true? Why is `-1 < FALSE` true? Why is `"one" < 2` false?

3. Create three vectors and then combine them into a list.

4.  If `x` is a list, what is the class of `x[1]`?  How about `x[[1]]`?


### Attributes

Attributes provide additional information about the data to you, the user, and to R. We've already seen the following three attributes in action:

* Names (`names(x)`), a character vector giving each element a name. 

* Dimensions (`dim(x)`), used to turn vectors into matrices.

* Class (`class(x)`), used to implement the S3 object system.

**Additional tips**

In an object-oriented system, a [class](https://www.google.com/search?q=what+is+class+programming&oq=what+is+class+programming&aqs=chrome.0.0l6.3543j0j4&sourceid=chrome&ie=UTF-8) (an extensible problem-code-template) defines a type of objects like what its properties are, how it behaves, and how it relates to other types of objects. Therefore, technically, an object is an [instance](https://en.wikipedia.org/wiki/Instance_(computer_science)) (or occurrence) of a class. A method is a function associated with a particular type of object.

#### Names

You can name a vector when you create it:


```r
x <- c(a = 1, b = 2, c = 3)
```

You can also modify an existing vector: 


```r
x <- 1:3

names(x)
```

```
## NULL
```

```r
names(x) <- c("e", "f", "g")

names(x)
```

```
## [1] "e" "f" "g"
```

Names don't have to be unique. However, character subsetting, described in the next lesson, is the most important reason to use names, and it is most useful when the names are unique. (For Python users: when names are unique, a vector behaves like a Python dictionary key.)

Not all elements of a vector need to have a name. If some names are missing, `names()` will return an empty string for those elements. If all names are missing, `names()` will return `NULL`.


```r
y <- c(a = 1, 2, 3)

names(y)
```

```
## [1] "a" ""  ""
```

```r
z <- c(1, 2, 3)

names(z)
```

```
## NULL
```

You can create a new vector without names using `unname(x)`, or remove names in place with `names(x) <- NULL`.

#### Factors

Factors are special vectors that represent categorical data. Factors can be ordered (ordinal variable) or unordered (nominal or categorical variable) and are important for modeling functions such as `lm()` and `glm()` and also in plot methods.

**Quiz**
1. If you want to enter dummy variables (Democrats = 1, Non-democrats = 0) in your regression model, should you use a numeric or factor variable?

Factors can only contain pre-defined values. Set allowed values using the `levels()` attribute. Note that a factor's levels will always be character values. 



```r
x <- c("a", "b", "b", "a")

x <- factor(c("a", "b", "b", "a"))

x
```

```
## [1] a b b a
## Levels: a b
```

```r
class(x)
```

```
## [1] "factor"
```

```r
levels(x)
```

```
## [1] "a" "b"
```

```r
# You can't use values that are not in the levels
x[2] <- "c"
```

```
## Warning in `[<-.factor`(`*tmp*`, 2, value = "c"): invalid factor level, NA
## generated
```

```r
# NB: you can't combine factors
c(factor("a"), factor("b"))
```

```
## [1] a b
## Levels: a b
```

```r
rep(1:5, rep(6, 5))
```

```
##  [1] 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4 5 5 5 5 5 5
```

Factors are pretty much integers that have labels on them. Underneath, it's really numbers (1, 2, 3...). 


```r
x <- factor(c("a", "b", "b", "a"))

str(x)
```

```
##  Factor w/ 2 levels "a","b": 1 2 2 1
```

They are better than using simple integer labels because factors are what are called self-describing. For example, `democrat` and `republican` is more descriptive than `1`s and `2`s. 

Factors are useful when you know the possible values a variable may take, even if you don't see all values in a given dataset. Using a factor instead of a character vector makes it obvious when some groups contain no observations:


```r
party_char <- c("democrat", "democrat", "democrat")

party_char
```

```
## [1] "democrat" "democrat" "democrat"
```

```r
party_factor <- factor(party_char, levels = c("democrat", "republican"))

party_factor
```

```
## [1] democrat democrat democrat
## Levels: democrat republican
```

```r
table(party_char) # shows only democrats
```

```
## party_char
## democrat 
##        3
```

```r
table(party_factor) # shows republicans too
```

```
## party_factor
##   democrat republican 
##          3          0
```

Sometimes factors can be left unordered. Example: `democrat`, `republican`.

Other times you might want factors to be ordered (or ranked). Example: `low`, `medium`, `high`. 


```r
x <- factor(c("low", "medium", "high"))

str(x)
```

```
##  Factor w/ 3 levels "high","low","medium": 2 3 1
```

```r
is.ordered(x)
```

```
## [1] FALSE
```

```r
y <- ordered(c("low", "medium", "high"), levels = c("high", "medium", "low"))

is.ordered(y)
```

```
## [1] TRUE
```

While factors look (and often behave) like character vectors, they are integers. Be careful when treating them like strings. Some string methods (like `gsub()` and `grepl()`) will coerce factors to strings, while others (like `nchar()`) will throw an error, and still others (like `c()`) will use the underlying integer values. 


```r
x <- c("a", "b", "b", "a")

x
```

```
## [1] "a" "b" "b" "a"
```

```r
is.factor(x)
```

```
## [1] FALSE
```

```r
x <- as.factor(x)

x
```

```
## [1] a b b a
## Levels: a b
```

```r
c(x, "c")
```

```
## [1] "1" "2" "2" "1" "c"
```

For this reason, it's usually best to explicitly convert factors to character vectors if you need string-like behavior. There was a memory advantage to using factors instead of character vectors in early versions of R, but this is no longer the case.

Unfortunately, most data loading functions in R automatically convert character vectors to factors. This is suboptimal, because there's no way for those functions to know the set of all possible levels or their optimal order. If this becomes a problem, use the argument `stringsAsFactors = FALSE` to suppress this behavior, and then manually convert character vectors to factors using your knowledge of the data.

**More attributes**

All R objects can have arbitrary additional attributes, used to store metadata about the object. Attributes can be thought of as a named list (with unique names). Attributes can be accessed individually with `attr()` or all at once (as a list) with `attributes()`. 


```r
y <- 1:10

attr(y, "my_attribute") <- "This is a vector"

attr(y, "my_attribute")
```

```
## [1] "This is a vector"
```

```r
# str returns a new object with modified information
str(attributes(y))
```

```
## List of 1
##  $ my_attribute: chr "This is a vector"
```

**Exercises**

1.  What happens to a factor when you modify its levels? 
    

```r
f1 <- factor(letters)

levels(f1) <- rev(levels(f1))

f1
```

```
##  [1] z y x w v u t s r q p o n m l k j i h g f e d c b a
## Levels: z y x w v u t s r q p o n m l k j i h g f e d c b a
```

2.  What does this code do? How do `f2` and `f3` differ from `f1`?


```r
f2 <- rev(factor(letters))

f3 <- factor(letters, levels = rev(letters))
```

## 2D data: Matrices and dataframes 

1. Matrices:  data structures for storing 2d data that is all the same class.
2. Dataframes: teaches you about the dataframe, the most important data structure for storing data in R, because it stores different kinds of (2d) data.

### Matrices

Matrices are created when we combine multiple vectors with the same class (e.g., numeric). This creates a dataset with rows and columns. By definition, if you want to combine multiple classes of vectors, you want a dataframe. You can coerce a matrix to become a dataframe, and vice-versa, but as with all vector coercions, the results can be unpredictable, so be sure you know how each variable (column) will convert.


```r
m <- matrix(nrow = 2, ncol = 2)

m
```

```
##      [,1] [,2]
## [1,]   NA   NA
## [2,]   NA   NA
```

```r
dim(m)
```

```
## [1] 2 2
```

Matrices are filled column-wise. 


```r
m <- matrix(1:6, nrow = 2, ncol = 3)

m
```

```
##      [,1] [,2] [,3]
## [1,]    1    3    5
## [2,]    2    4    6
```

Other ways to construct a matrix


```r
m <- 1:10

dim(m) <- c(2, 5)

m
```

```
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    3    5    7    9
## [2,]    2    4    6    8   10
```

```r
dim(m) <- c(5, 2)

m
```

```
##      [,1] [,2]
## [1,]    1    6
## [2,]    2    7
## [3,]    3    8
## [4,]    4    9
## [5,]    5   10
```

You can transpose a matrix (or dataframe) with `t()`


```r
m <- 1:10

dim(m) <- c(2, 5)

m
```

```
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    3    5    7    9
## [2,]    2    4    6    8   10
```

```r
t(m)
```

```
##      [,1] [,2]
## [1,]    1    2
## [2,]    3    4
## [3,]    5    6
## [4,]    7    8
## [5,]    9   10
```

Another way is to bind columns or rows using `cbind()` and `rbind()`.


```r
x <- 1:3

y <- 10:12

cbind(x, y)
```

```
##      x  y
## [1,] 1 10
## [2,] 2 11
## [3,] 3 12
```

```r
# or

rbind(x, y)
```

```
##   [,1] [,2] [,3]
## x    1    2    3
## y   10   11   12
```

You can also use the `byrow` argument to specify how the matrix is filled. From R's own documentation:


```r
mdat <- matrix(c(1, 2, 3, 11, 12, 13),
  nrow = 2,
  ncol = 3,
  byrow = TRUE,
  dimnames = list(
    c("row1", "row2"),
    c("C.1", "C.2", "C.3")
  )
)
mdat
```

```
##      C.1 C.2 C.3
## row1   1   2   3
## row2  11  12  13
```

Notice that we gave `names` to the dimensions in `mdat`.


```r
dimnames(mdat)
```

```
## [[1]]
## [1] "row1" "row2"
## 
## [[2]]
## [1] "C.1" "C.2" "C.3"
```

```r
rownames(mdat)
```

```
## [1] "row1" "row2"
```

```r
colnames(mdat)
```

```
## [1] "C.1" "C.2" "C.3"
```

### Dataframes 

A data frame is an essential data type in R. It's pretty much the **de facto** data structure for most tabular data and what we use for statistics. 

#### Creation

You create a data frame using `data.frame()`, which takes named vectors as input:


```r
vec1 <- 1:3
vec2 <- c("a", "b", "c")
df <- data.frame(vec1, vec2)
df
```

```
##   vec1 vec2
## 1    1    a
## 2    2    b
## 3    3    c
```

```r
str(df)
```

```
## 'data.frame':	3 obs. of  2 variables:
##  $ vec1: int  1 2 3
##  $ vec2: chr  "a" "b" "c"
```

Beware: `data.frame()`'s default behavior which turns strings into factors. Remember to use `stringAsFactors = FALSE` to suppress this behavior as needed:


```r
df <- data.frame(
  x = 1:3,
  y = c("a", "b", "c"),
  stringsAsFactors = FALSE
)
str(df)
```

```
## 'data.frame':	3 obs. of  2 variables:
##  $ x: int  1 2 3
##  $ y: chr  "a" "b" "c"
```

In reality, we rarely type up our datasets ourselves, and certainly not in R. The most common way to make a data.frame is by calling a file using `read.csv` (which relies on the `foreign` package), `read.dta` (if you're using a Stata file), or some other kinds of data file input.

#### Structure and Attributes

Under the hood, a data frame is a list of equal-length vectors. This makes it a 2-dimensional structure, so it shares properties of both the matrix and the list. 


```r
vec1 <- 1:3
vec2 <- c("a", "b", "c")
df <- data.frame(vec1, vec2)

str(df)
```

```
## 'data.frame':	3 obs. of  2 variables:
##  $ vec1: int  1 2 3
##  $ vec2: chr  "a" "b" "c"
```

This means that a dataframe has `names()`, `colnames()`, and `rownames()`, although `names()` and `colnames()` are the same thing. 

** Summary **

- Set column names: `names()` in data frame, `colnames()` in matrix 
- Set row names: `row.names()` in data frame, `rownames()` in matrix


```r
vec1 <- 1:3
vec2 <- c("a", "b", "c")
df <- data.frame(vec1, vec2)

# these two are equivalent
names(df)
```

```
## [1] "vec1" "vec2"
```

```r
colnames(df)
```

```
## [1] "vec1" "vec2"
```

```r
# change the colnames
colnames(df) <- c("Number", "Character")
df
```

```
##   Number Character
## 1      1         a
## 2      2         b
## 3      3         c
```


```r
names(df) <- c("Number", "Character")
df
```

```
##   Number Character
## 1      1         a
## 2      2         b
## 3      3         c
```


```r
# change the rownames
rownames(df)
```

```
## [1] "1" "2" "3"
```

```r
rownames(df) <- c("donut", "pickle", "pretzel")
df
```

```
##         Number Character
## donut        1         a
## pickle       2         b
## pretzel      3         c
```

The `length()` of a dataframe is the length of the underlying list and so is the same as `ncol()`; `nrow()` gives the number of rows. 


```r
vec1 <- 1:3
vec2 <- c("a", "b", "c")
df <- data.frame(vec1, vec2)

# these two are equivalent - number of columns
length(df)
```

```
## [1] 2
```

```r
ncol(df)
```

```
## [1] 2
```

```r
# get number of rows
nrow(df)
```

```
## [1] 3
```

```r
# get number of both columns and rows
dim(df)
```

```
## [1] 3 2
```

#### Testing and coercion

To check if an object is a dataframe, use `class()` or test explicitly with `is.data.frame()`:


```r
class(df)
```

```
## [1] "data.frame"
```

```r
is.data.frame(df)
```

```
## [1] TRUE
```

You can coerce an object to a dataframe with `as.data.frame()`:

* A vector will create a one-column dataframe.

* A list will create one column for each element; it's an error if they're 
  not all the same length.
  
* A matrix will create a data frame with the same number of columns and rows as the matrix.

#### Combining dataframes

You can combine dataframes using `cbind()` and `rbind()`:


```r
df <- data.frame(
  x = 1:3,
  y = c("a", "b", "c"),
  stringsAsFactors = FALSE
)

cbind(df, data.frame(z = 3:1))
```

```
##   x y z
## 1 1 a 3
## 2 2 b 2
## 3 3 c 1
```

```r
rbind(df, data.frame(x = 10, y = "z"))
```

```
##    x y
## 1  1 a
## 2  2 b
## 3  3 c
## 4 10 z
```

When combining column-wise, the number of rows must match, but row names are ignored. When combining row-wise, both the number and names of columns must match. (If you want to combine rows that don't have the same columns, there are other functions/packages in R that can help.)

It's a common mistake to try and create a dataframe by `cbind()`ing vectors together. This doesn't work because `cbind()` will create a matrix unless one of the arguments is already a dataframe. Instead use `data.frame()` directly:


```r
bad <- (cbind(x = 1:2, y = c("a", "b")))
bad
```

```
##      x   y  
## [1,] "1" "a"
## [2,] "2" "b"
```

```r
str(bad)
```

```
##  chr [1:2, 1:2] "1" "2" "a" "b"
##  - attr(*, "dimnames")=List of 2
##   ..$ : NULL
##   ..$ : chr [1:2] "x" "y"
```

```r
good <- data.frame(
  x = 1:2, y = c("a", "b"),
  stringsAsFactors = FALSE
)
good
```

```
##   x y
## 1 1 a
## 2 2 b
```

```r
str(good)
```

```
## 'data.frame':	2 obs. of  2 variables:
##  $ x: int  1 2
##  $ y: chr  "a" "b"
```

The conversion rules for `cbind()` are complicated and best avoided by ensuring all inputs are of the same type.

**Other objects**

Missing values are specified with `NA`, which is a logical vector of length 1. `NA` will always be coerced to the correct type if used inside `c()`


```r
x <- c(NA, 1)
x
```

```
## [1] NA  1
```

```r
typeof(NA)
```

```
## [1] "logical"
```

```r
typeof(x)
```

```
## [1] "double"
```

`Inf` is infinity. You can have either positive or negative infinity.


```r
1 / 0
```

```
## [1] Inf
```

```r
1 / Inf
```

```
## [1] 0
```

`NaN` means Not a number. It's an undefined value.


```r
0 / 0
```

```
## [1] NaN
```

## Subset

When working with data, you'll need to subset objects early and often. Luckily, R's subsetting operators are powerful and fast. Mastery of subsetting allows you to succinctly express complex operations in a way that few other languages can match. Subsetting is hard to learn because you need to master several interrelated concepts:

* The three subsetting operators, `[`, `[[`, and `$`.

* Important differences in behavior for different objects (e.g., vectors, lists, factors, matrices, and data frames).

* The use of subsetting in conjunction with assignment.

This unit helps you master subsetting by starting with the simplest type of subsetting: subsetting an atomic vector with `[`. It then gradually extends your knowledge, first to more complicated data types (like dataframes and lists), and then to the other subsetting operators, `[[` and `$`. You'll then learn how subsetting and assignment can be combined to modify parts of an object, and, finally, you'll see a large number of useful applications.

### Atomic vectors

Let's explore the different types of subsetting with a simple vector, `x`. 


```r
x <- c(2.1, 4.2, 3.3, 5.4)
```

Note that the number after the decimal point gives the original position in the vector.

**NB:** In R, positions start at 1, unlike Python, which starts at 0. Fun!**

There are five things that you can use to subset a vector: 

#### Positive integers


```r
x <- c(2.1, 4.2, 3.3, 5.4)
x
```

```
## [1] 2.1 4.2 3.3 5.4
```

```r
x[1]
```

```
## [1] 2.1
```

```r
x[c(3, 1)]
```

```
## [1] 3.3 2.1
```

```r
# `order(x)` gives the positions of smallest to largest values.
order(x)
```

```
## [1] 1 3 2 4
```

```r
x[order(x)]
```

```
## [1] 2.1 3.3 4.2 5.4
```

```r
x[c(1, 3, 2, 4)]
```

```
## [1] 2.1 3.3 4.2 5.4
```

```r
# Duplicated indices yield duplicated values
x[c(1, 1)]
```

```
## [1] 2.1 2.1
```

#### Negative integers


```r
x <- c(2.1, 4.2, 3.3, 5.4)
x[-1]
```

```
## [1] 4.2 3.3 5.4
```

```r
x[-c(3, 1)]
```

```
## [1] 4.2 5.4
```

You can't mix positive and negative integers in a single subset:


```r
x <- c(2.1, 4.2, 3.3, 5.4)
x[c(-1, 2)]
```

```
## Error in x[c(-1, 2)]: only 0's may be mixed with negative subscripts
```

#### Logical vectors


```r
x <- c(2.1, 4.2, 3.3, 5.4)

x[c(TRUE, TRUE, FALSE, FALSE)]
```

```
## [1] 2.1 4.2
```

This is probably the most useful type of subsetting because you write the expression that creates the logical vector


```r
x <- c(2.1, 4.2, 3.3, 5.4)

# this returns a logical vector
x > 3
```

```
## [1] FALSE  TRUE  TRUE  TRUE
```

```r
x
```

```
## [1] 2.1 4.2 3.3 5.4
```

```r
# use a conditional statement to create an implicit logical vector
x[x > 3]
```

```
## [1] 4.2 3.3 5.4
```

You can combine conditional statements with `&` (and), `|` (or), and `!` (not)


```r
x <- c(2.1, 4.2, 3.3, 5.4)

# combing two conditional statements with &
x > 3 & x < 5
```

```
## [1] FALSE  TRUE  TRUE FALSE
```

```r
x[x > 3 & x < 5]
```

```
## [1] 4.2 3.3
```

```r
# combing two conditional statements with |
x < 3 | x > 5
```

```
## [1]  TRUE FALSE FALSE  TRUE
```

```r
x[x < 3 | x > 5]
```

```
## [1] 2.1 5.4
```

```r
# combining conditional statements with !
!x > 5
```

```
## [1]  TRUE  TRUE  TRUE FALSE
```

```r
x[!x > 5]
```

```
## [1] 2.1 4.2 3.3
```

Another way to generate implicit conditional statements is using the `%in%` operator, which works like the `in` keywords in Python.


```r
# generate implicit logical vectors through the %in% operator
x %in% c(3.3, 4.2)
```

```
## [1] FALSE  TRUE  TRUE FALSE
```

```r
x
```

```
## [1] 2.1 4.2 3.3 5.4
```

```r
x[x %in% c(3.3, 4.2)]
```

```
## [1] 4.2 3.3
```

#### Character vectors


```r
x <- c(2.1, 4.2, 3.3, 5.4)

# apply names
names(x) <- c("a", "b", "c", "d")
x
```

```
##   a   b   c   d 
## 2.1 4.2 3.3 5.4
```

```r
# subset using names
x[c("d", "c", "a")]
```

```
##   d   c   a 
## 5.4 3.3 2.1
```

```r
# Like integer indices, you can repeat indices
x[c("a", "a", "a")]
```

```
##   a   a   a 
## 2.1 2.1 2.1
```

```r
# Careful! names are always matched exactly
x <- c(abc = 1, def = 2)
x
```

```
## abc def 
##   1   2
```

```r
x[c("a", "d")]
```

```
## <NA> <NA> 
##   NA   NA
```

###### More on string operations 


```r
firstName <- "Jae Yeon"
lastName <- "Kim"
```

Unlike in Python, R does not have a reserved operator for string concatenation such as `+`.  Furthermore, using the usual concatenation operator ```c()``` on two or more character strings will not create a single character string, but rather a **vector** of character strings. 


```r
fullName <- c(firstName, lastName)

print(fullName)
```

```
## [1] "Jae Yeon" "Kim"
```

```r
length(fullName)
```

```
## [1] 2
```

To combine two or more character strings into one larger character string, we use the ```paste()``` function.  This function takes character strings or vectors and collapses their values into a single character string, with each value separated by a character string selected by the user.


```r
fullName <- paste(firstName, lastName)

print(fullName)

fullName <- paste(firstName, lastName, sep = "+")

print(fullName)

fullName <- paste(firstName, lastName, sep = "___")
print(fullName)
```

As with Python, R can also extract substrings based on the index position of its characters.  There are, however, two critical differences.  First, **index positions in R start at 1**.  This is in contrast to Python, where indexation begins at 0.  

Second, **object subsets using index positions in R contain all the elements in the specified range**.  If some object called ```data``` contains five elements, ```data[2:4]``` will return the elements at the second, third, and fourth positions.  By contrast, the same subset in Python would return the objects at the third and fourth positions (or second and third positions, depending upon whether your index starts at 0 or 1).  

Third, **R does not allow indexing of character strings***. Instead, you must use the ```substr()``` function.  Note that this function must receive both the ```start``` and ```stop``` arguments.  So if you want to get all the characters between some index and the end of the string, you must make use of the ```nchar()``` function, which will tell you the length of a character string.


```r
fullName <- paste(firstName, lastName)

# this won't work like in Python
fullName[1] # R sees the string as a unitary object - it can't be indexed this way
```

```
## [1] "Jae Yeon Kim"
```

```r
fullName[1:4]
```

```
## [1] "Jae Yeon Kim" NA             NA             NA
```

```r
# So use this instead
substr(x = fullName, start = 1, stop = 2)
```

```
## [1] "Ja"
```

```r
substr(x = fullName, start = 5, stop = 5)
```

```
## [1] "Y"
```

```r
substr(x = fullName, start = 1, stop = 10)
```

```
## [1] "Jae Yeon K"
```

```r
substr(x = fullName, start = 11, stop = nchar(fullName))
```

```
## [1] "im"
```

Like Python, R has a number of string methods, though these exist as individual rather than "mix-and-match" functions. For example:


```r
toupper(x = fullName)
```

```
## [1] "JAE YEON KIM"
```

```r
tolower(x = fullName)
```

```
## [1] "jae yeon kim"
```

```r
strsplit(x = fullName, split = " ")
```

```
## [[1]]
## [1] "Jae"  "Yeon" "Kim"
```

```r
strsplit(x = fullName, split = "n")
```

```
## [[1]]
## [1] "Jae Yeo" " Kim"
```

```r
gsub(pattern = "Kim", replacement = "Choi", x = fullName)
```

```
## [1] "Jae Yeon Choi"
```

```r
gsub(pattern = "Jae Yeon", replacement = "Danny", x = fullName)
```

```
## [1] "Danny Kim"
```

```r
# Note the importance of cases! This doesn't throw an error, so you won't realize your function didn't work unless you double-check several entries

gsub(pattern = " ", replacement = "", x = fullName) # The same function is used for replacements and stripping
```

```
## [1] "JaeYeonKim"
```

### Lists

Subsetting a list works in the same way as subsetting an atomic vector. Using `[` will always return a list; `[[` and `$`, as described below, let you pull out the list's components.


```r
l <- list("a" = 1, "b" = 2)
l
```

```
## $a
## [1] 1
## 
## $b
## [1] 2
```

```r
l[1]
```

```
## $a
## [1] 1
```

```r
l[[1]]
```

```
## [1] 1
```

```r
l["a"]
```

```
## $a
## [1] 1
```

### Matrices

The most common way of subsetting matrices (2d) is a simple generalization of 1d subsetting: you supply a 1d index for each dimension, separated by a comma. Blank subsetting is now useful because it lets you keep all rows or all columns.


```r
a <- matrix(1:9, nrow = 3)
colnames(a) <- c("A", "B", "C")
a
```

```
##      A B C
## [1,] 1 4 7
## [2,] 2 5 8
## [3,] 3 6 9
```

```r
# rows come first, then columns
a[c(1, 2), ]
```

```
##      A B C
## [1,] 1 4 7
## [2,] 2 5 8
```

```r
a[c(T, F, T), c("B", "A")]
```

```
##      B A
## [1,] 4 1
## [2,] 6 3
```

```r
a[0, -2]
```

```
##      A C
```

```r
a[c(1, 2), -2]
```

```
##      A C
## [1,] 1 7
## [2,] 2 8
```

### Data frames

Data from data frames can be addressed like matrices (with row and column indicators separated by a comma).


```r
df <- data.frame(x = 4:6, y = 3:1, z = letters[1:3])
df
```

```
##   x y z
## 1 4 3 a
## 2 5 2 b
## 3 6 1 c
```

```r
# return only the rows where x == 6
df[df$x == 6, ]
```

```
##   x y z
## 3 6 1 c
```

```r
# return the first and third row
df[c(1, 3), ]
```

```
##   x y z
## 1 4 3 a
## 3 6 1 c
```

```r
# return the first and third row and the first and second column
df[c(1, 3), c(1, 2)]
```

```
##   x y
## 1 4 3
## 3 6 1
```

Data frames possess both lists and matrices' characteristics: if you subset with a single vector, they behave like lists and return only the columns.


```r
# There are two ways to select columns from a data frame
# Like a list:
df[c("x", "z")]
```

```
##   x z
## 1 4 a
## 2 5 b
## 3 6 c
```

```r
# Like a matrix
df[, c("x", "z")]
```

```
##   x z
## 1 4 a
## 2 5 b
## 3 6 c
```

But there's a significant difference when selecting a single column: matrix subsetting simplifies by default, list subsetting does not.


```r
(df["x"])
```

```
##   x
## 1 4
## 2 5
## 3 6
```

```r
class((df["x"]))
```

```
## [1] "data.frame"
```

```r
(df[, "x"])
```

```
## [1] 4 5 6
```

```r
class((df[, "x"]))
```

```
## [1] "integer"
```

See the bottom section on [Simplying and Preserving to know more](#simplify-preserve)

### Subsetting operators 

There are two other subsetting operators: `[[` and `$`. 

* `[[` is similar to `[`, except it can only return a single value, and it allows you to pull pieces out of a list. 
* `$` is a useful shorthand for `[[` combined with character subsetting. 

##### `[[`

You need `[[` when working with lists. When `[` is applied to a list it always returns a list: it never gives you the contents of the list. To get the contents, you need `[[`:

>  "If list `x` is a train carrying objects, then `x[[5]]` is
> the object in car 5; `x[4:6]` is a train of cars 4-6." 
>
> --- @RLangTip

Because data frames are lists of columns, you can use `[[` to extract a column from data frames:


```r
mtcars
```

```
##                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
## Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1
## Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4
## Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
## Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
## Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
## Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4
## Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3
## Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3
## Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
## Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4
## Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4
## Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4
## Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
## Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
## Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1
## Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
## Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2
## AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2
## Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4
## Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2
## Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1
## Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
## Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2
## Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4
## Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6
## Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8
## Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2
```

```r
# these two are equivalent
mtcars[[1]]
```

```
##  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4
## [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7
## [31] 15.0 21.4
```

```r
mtcars[, 1]
```

```
##  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4
## [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7
## [31] 15.0 21.4
```

```r
# which differs from this:
mtcars[1]
```

```
##                      mpg
## Mazda RX4           21.0
## Mazda RX4 Wag       21.0
## Datsun 710          22.8
## Hornet 4 Drive      21.4
## Hornet Sportabout   18.7
## Valiant             18.1
## Duster 360          14.3
## Merc 240D           24.4
## Merc 230            22.8
## Merc 280            19.2
## Merc 280C           17.8
## Merc 450SE          16.4
## Merc 450SL          17.3
## Merc 450SLC         15.2
## Cadillac Fleetwood  10.4
## Lincoln Continental 10.4
## Chrysler Imperial   14.7
## Fiat 128            32.4
## Honda Civic         30.4
## Toyota Corolla      33.9
## Toyota Corona       21.5
## Dodge Challenger    15.5
## AMC Javelin         15.2
## Camaro Z28          13.3
## Pontiac Firebird    19.2
## Fiat X1-9           27.3
## Porsche 914-2       26.0
## Lotus Europa        30.4
## Ford Pantera L      15.8
## Ferrari Dino        19.7
## Maserati Bora       15.0
## Volvo 142E          21.4
```

##### `$`

`$` is a shorthand operator, where `x$y` is equivalent to `x[["y", exact = FALSE]]`.  It's often used to access variables in a data frame:


```r
# these two are equivalent
mtcars[["cyl"]]
```

```
##  [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
```

```r
mtcars$cyl
```

```
##  [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
```

One common mistake with `$` is to try and use it when you have the name of a column stored in a variable:


```r
var <- "cyl"
# Doesn't work - mtcars$var translated to mtcars[["var"]]
mtcars$var
```

```
## NULL
```

```r
# Instead use [[
mtcars[[var]]
```

```
##  [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
```

### Subassignment

All subsetting operators can be combined with an assignment operator to modify selected values of the input vector.


```r
x <- 1:5
x
```

```
## [1] 1 2 3 4 5
```

```r
x[c(1, 2)] <- 2:3
x
```

```
## [1] 2 3 3 4 5
```

```r
# The length of the LHS needs to match the RHS!
x[-1] <- 4:1
x
```

```
## [1] 2 4 3 2 1
```

```r
x[1] <- 4:1
```

```
## Warning in x[1] <- 4:1: number of items to replace is not a multiple of
## replacement length
```

```r
# This is mostly useful when conditionally modifying vectors
df <- data.frame(a = c(1, 10, NA))
df
```

```
##    a
## 1  1
## 2 10
## 3 NA
```

```r
df$a[df$a < 5] <- 0
df
```

```
##    a
## 1  0
## 2 10
## 3 NA
```

## Tidyverse

* I adapted the following content from Wickham's [R for Data Science](https://r4ds.had.co.nz/tidy-data.html), his [earlier paper](http://www.jstatsoft.org/v59/i10/paper) published in the Journal of Statistical Software, [Efficient R Programming](https://csgillespie.github.io/efficientR/) by Gillespie and Lovelace, and [R Programming for Data Science](https://bookdown.org/rdpeng/rprogdatascience/) by Roger P. Peng.

-   [Tidyverse design guide](https://design.tidyverse.org/unifying-principles.html)

    -   Human-centered

    -   Consistent

    -   Composable (modularized)

    -   Inclusive

    -   Influenced by the [Basics of the Unix Philosophy](https://homepage.cs.uri.edu/~thenry/resources/unix_art/ch01s06.html), [The Zen of Python](https://www.python.org/dev/peps/pep-0020/), and the [Design Principles Behind Smalltalk](https://refs.devinmcgloin.com/smalltalk/Design-Principles-Behind-Smalltalk.pdf)

## Tidy data

> "Tidy data sets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table." - Hadley Wickham

1.  Variables -\> **Columns**
2.  Observations -\> **Rows**
3.  Values -\> **Cells**

![Tidy Data Example (Source: R for Data Science)](https://garrettgman.github.io/images/tidy-1.png)

If dataframes are tidy, it's easy to transform, visualize, model, and program them using tidyverse packages (a whole workflow).

![Tidyverse: an opinionated collection of R packages](https://miro.medium.com/max/960/0*mlPyX0NE0WQwEzpS.png)

-   Nevertheless, don't be **religious**.

> In summary, tidy data is a useful conceptual idea and is often the right way to go for general, small data sets, but may not be appropriate for all problems. - Jeff Leek

For instance, in many data science applications, linear algebra-based computations are essential (e.g., [Principal Component Analysis](https://www.math.upenn.edu/~kazdan/312S13/JJ/PCA-JJ.pdf)). These computations are optimized to work on matrices, not tidy data frames (for more information, read [Jeff Leek's blog post](https://simplystatistics.org/2016/02/17/non-tidy-data/)).

This is what a tidy data looks like.


```r
library(tidyverse)

table1
```

```
## # A tibble: 6 x 4
##   country      year  cases population
##   <chr>       <int>  <int>      <int>
## 1 Afghanistan  1999    745   19987071
## 2 Afghanistan  2000   2666   20595360
## 3 Brazil       1999  37737  172006362
## 4 Brazil       2000  80488  174504898
## 5 China        1999 212258 1272915272
## 6 China        2000 213766 1280428583
```


**Additional tips** 

There are so many different ways of taking a look at data in R. Can you discuss the pros and cons of each approach? Which one do you prefer and why?


* `str(table1)`

* `glimpse(table1)`: similar to `str()` cleaner output 

* `skim(table1)`: `str()` + `summary()` + more 


- The big picture 
    - Tidying data with **tidyr**
    - Processing data with **dplyr**
    
These two packages don't do anything new but simplify most common tasks in data manipulation. Plus, they are fast, consistent, and more readable.

Practically, this approach is right because you're going to have consistency in data format across all the projects you're working on. Also, tidy data works well with key packages (e.g., dplyr, ggplot2) in R.

Computationally, this approach is useful for vectorized programming because "different variables from the same observation are always paired". Vectorized means a function applies to a vector treats each element individually (=operations working in parallel).

## Tidying (tidyr)

### Reshaping

**Signs of messy datasets**

* 1. Column headers are values, not variable names.
* 2. Multiple variables are not stored in one column.
* 3. Variables are stored in both rows and columns.
* 4. Multiple types of observational units are stored in the same table.
* 5. A single observational unit is stored in multiple tables.

Let's take a look at the cases of untidy data.

![Messy Data Case 1 (Source: R for Data Science)](https://garrettgman.github.io/images/tidy-5.png)

-   Make It Longer

    | Col1 | Col2 | Col3 |
    |------|------|------|
    |      |      |      |
    |      |      |      |
    |      |      |      |

**Challenge**: Why is this data not tidy?


```r
table4a
```

```
## # A tibble: 3 x 3
##   country     `1999` `2000`
## * <chr>        <int>  <int>
## 1 Afghanistan    745   2666
## 2 Brazil       37737  80488
## 3 China       212258 213766
```

-   Let's pivot (rotate by 90 degrees).


![Concept map for pivoting. By Florian Schmoll, Monica Alonso.](https://github.com/rstudio/concept-maps/raw/master/en/pivoting.svg)


-   [`pivot_longer()`](https://tidyr.tidyverse.org/reference/pivot_longer.html) increases the number of rows (longer) and decreases the number of columns. The inverse function is `pivot_wider()`. These functions improve the usability of `gather()` and `spread()`.

![What pivot\_longer() does (Source: <https://www.storybench.org>)](https://www.storybench.org/wp-content/uploads/2019/08/pivot-longer-image.png)


![Concept map for pipe operator. By Jeroen Janssens, Monica Alonso.](https://education.rstudio.com/blog/2020/09/concept-maps/pipe-operator.png)

- The pipe operator `%>%` originally comes from the `magrittr` package. The idea behind the pipe operator is [similar to](https://www.datacamp.com/community/tutorials/pipe-r-tutorial) what we learned about chaining functions in high school. f: B -> C and g: A -> B can be expressed as $f(g(x))$. The pipe operator chains operations. When you read pipe operator, read as "and then" (Wickham's recommendation). The keyboard shortcut is ctrl + shift + M. The key idea here is not creating temporary variables and focusing on verbs (functions). We'll learn more about this functional programming paradigm later on.


```r
table4a 
```

```
## # A tibble: 3 x 3
##   country     `1999` `2000`
## * <chr>        <int>  <int>
## 1 Afghanistan    745   2666
## 2 Brazil       37737  80488
## 3 China       212258 213766
```

```r
# Old way, less intuitive
table4a %>%
  gather(
    key = "year", # Current column names
    value = "cases", # The values matched to cases
    c("1999", "2000")
  ) # Selected columns
```

```
## # A tibble: 6 x 3
##   country     year   cases
##   <chr>       <chr>  <int>
## 1 Afghanistan 1999     745
## 2 Brazil      1999   37737
## 3 China       1999  212258
## 4 Afghanistan 2000    2666
## 5 Brazil      2000   80488
## 6 China       2000  213766
```


```r
# New way, more intuitive
table4a %>%
  pivot_longer(
    cols = c("1999", "2000"), # Selected columns
    names_to = "year", # Shorter columns (the columns going to be in one column called year)
    values_to = "cases"
  ) # Longer rows (the values are going to be in a separate column called named cases)
```

```
## # A tibble: 6 x 3
##   country     year   cases
##   <chr>       <chr>  <int>
## 1 Afghanistan 1999     745
## 2 Afghanistan 2000    2666
## 3 Brazil      1999   37737
## 4 Brazil      2000   80488
## 5 China       1999  212258
## 6 China       2000  213766
```

-   There's another problem, did you catch it?

-   The data type of `year` variable should be `numeric` not `character`. By default, `pivot_longer()` transforms uninformative columns to character.

-   You can fix this problem by using `names_transform` argument.


```r
table4a %>%
  pivot_longer(
    cols = c("1999", "2000"), # Put two columns together
    names_to = "year", # Shorter columns (the columns going to be in one column called year)
    values_to = "cases", # Longer rows (the values are going to be in a separate column called named cases)
    names_transform = list(year = readr::parse_number)
  ) # Transform the variable
```

```
## # A tibble: 6 x 3
##   country      year  cases
##   <chr>       <dbl>  <int>
## 1 Afghanistan  1999    745
## 2 Afghanistan  2000   2666
## 3 Brazil       1999  37737
## 4 Brazil       2000  80488
## 5 China        1999 212258
## 6 China        2000 213766
```

**Additional tips**

`parse_number()` also keeps only numeric information in a variable.


```r
parse_number("reply1994")
```

```
## [1] 1994
```

A flat file (e.g., CSV) is a rectangular shaped combination of strings. [Parsing](https://cran.r-project.org/web/packages/readr/vignettes/readr.html) determines the type of each column and turns into a vector of a more specific type. Tidyverse has `parse_` functions (from `readr` package) that are flexible and fast (e.g., `parse_integer()`, `parse_double()`, `parse_logical()`, `parse_datetime()`, `parse_date()`, `parse_time()`, `parse_factor()`, etc).

-   Let's do another practice.

**Challenge**

1.  Why is this data not tidy? (This exercise comes from [`pivot` function vigenette](https://tidyr.tidyverse.org/articles/pivot.html).) Too long or too wide?


```r
billboard
```

```
## # A tibble: 317 x 79
##    artist   track   date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8
##    <chr>    <chr>   <date>       <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
##  1 2 Pac    Baby D~ 2000-02-26      87    82    72    77    87    94    99    NA
##  2 2Ge+her  The Ha~ 2000-09-02      91    87    92    NA    NA    NA    NA    NA
##  3 3 Doors~ Krypto~ 2000-04-08      81    70    68    67    66    57    54    53
##  4 3 Doors~ Loser   2000-10-21      76    76    72    69    67    65    55    59
##  5 504 Boyz Wobble~ 2000-04-15      57    34    25    17    17    31    36    49
##  6 98^0     Give M~ 2000-08-19      51    39    34    26    26    19     2     2
##  7 A*Teens  Dancin~ 2000-07-08      97    97    96    95   100    NA    NA    NA
##  8 Aaliyah  I Don'~ 2000-01-29      84    62    51    41    38    35    35    38
##  9 Aaliyah  Try Ag~ 2000-03-18      59    53    38    28    21    18    16    14
## 10 Adams, ~ Open M~ 2000-08-26      76    76    74    69    68    67    61    58
## # ... with 307 more rows, and 68 more variables: wk9 <dbl>, wk10 <dbl>,
## #   wk11 <dbl>, wk12 <dbl>, wk13 <dbl>, wk14 <dbl>, wk15 <dbl>, wk16 <dbl>,
## #   wk17 <dbl>, wk18 <dbl>, wk19 <dbl>, wk20 <dbl>, wk21 <dbl>, wk22 <dbl>,
## #   wk23 <dbl>, wk24 <dbl>, wk25 <dbl>, wk26 <dbl>, wk27 <dbl>, wk28 <dbl>,
## #   wk29 <dbl>, wk30 <dbl>, wk31 <dbl>, wk32 <dbl>, wk33 <dbl>, wk34 <dbl>,
## #   wk35 <dbl>, wk36 <dbl>, wk37 <dbl>, wk38 <dbl>, wk39 <dbl>, wk40 <dbl>,
## #   wk41 <dbl>, wk42 <dbl>, wk43 <dbl>, wk44 <dbl>, wk45 <dbl>, wk46 <dbl>, ...
```

2.  How can you fix it? Which pivot?


```r
# Old way
billboard %>%
  gather(
    key = "week",
    value = "rank",
    starts_with("wk")
  ) %>% # Use regular expressions
  drop_na() # Drop NAs
```

```
## # A tibble: 5,307 x 5
##    artist         track                   date.entered week   rank
##    <chr>          <chr>                   <date>       <chr> <dbl>
##  1 2 Pac          Baby Don't Cry (Keep... 2000-02-26   wk1      87
##  2 2Ge+her        The Hardest Part Of ... 2000-09-02   wk1      91
##  3 3 Doors Down   Kryptonite              2000-04-08   wk1      81
##  4 3 Doors Down   Loser                   2000-10-21   wk1      76
##  5 504 Boyz       Wobble Wobble           2000-04-15   wk1      57
##  6 98^0           Give Me Just One Nig... 2000-08-19   wk1      51
##  7 A*Teens        Dancing Queen           2000-07-08   wk1      97
##  8 Aaliyah        I Don't Wanna           2000-01-29   wk1      84
##  9 Aaliyah        Try Again               2000-03-18   wk1      59
## 10 Adams, Yolanda Open My Heart           2000-08-26   wk1      76
## # ... with 5,297 more rows
```

-   Note that `pivot_longer()` is more versatile than `gather()`.


```r
# New way
billboard %>%
  pivot_longer(
    cols = starts_with("wk"), # Use regular expressions
    names_to = "week",
    values_to = "rank",
    values_drop_na = TRUE # Drop NAs
  )
```

```
## # A tibble: 5,307 x 5
##    artist  track                   date.entered week   rank
##    <chr>   <chr>                   <date>       <chr> <dbl>
##  1 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk1      87
##  2 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk2      82
##  3 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk3      72
##  4 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk4      77
##  5 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk5      87
##  6 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk6      94
##  7 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk7      99
##  8 2Ge+her The Hardest Part Of ... 2000-09-02   wk1      91
##  9 2Ge+her The Hardest Part Of ... 2000-09-02   wk2      87
## 10 2Ge+her The Hardest Part Of ... 2000-09-02   wk3      92
## # ... with 5,297 more rows
```

-   Make It Wider

-   Why is this data not tidy?


```r
table2
```

```
## # A tibble: 12 x 4
##    country      year type            count
##    <chr>       <int> <chr>           <int>
##  1 Afghanistan  1999 cases             745
##  2 Afghanistan  1999 population   19987071
##  3 Afghanistan  2000 cases            2666
##  4 Afghanistan  2000 population   20595360
##  5 Brazil       1999 cases           37737
##  6 Brazil       1999 population  172006362
##  7 Brazil       2000 cases           80488
##  8 Brazil       2000 population  174504898
##  9 China        1999 cases          212258
## 10 China        1999 population 1272915272
## 11 China        2000 cases          213766
## 12 China        2000 population 1280428583
```

-   Each observation is spread across two rows.

-   How can you fix it?: `pivot_wider()`.

**Two differences between `pivot_longer()` and `pivot_wider()`**

-   In `pivot_longer()`, the arguments are named `names_to` and `values_to` (*to*).

-   In `pivot_wider()`, this pattern is opposite. The arguments are named `names_from` and `values_from` (*from*).

-   The number of required arguments for `pivot_longer()` is 3 (col, names\_to, values\_to).

-   The number of required arguments for `pivot_wider()` is 2 (names\_from, values\_from).

![What pivot\_wider() does (Source: <https://www.storybench.org>)](https://www.storybench.org/wp-content/uploads/2019/08/pivot-wider-image.png)


```r
# Old way
table2 %>%
  spread(
    key = type,
    value = count
  )
```

```
## # A tibble: 6 x 4
##   country      year  cases population
##   <chr>       <int>  <int>      <int>
## 1 Afghanistan  1999    745   19987071
## 2 Afghanistan  2000   2666   20595360
## 3 Brazil       1999  37737  172006362
## 4 Brazil       2000  80488  174504898
## 5 China        1999 212258 1272915272
## 6 China        2000 213766 1280428583
```


```r
# New way
table2 %>%
  pivot_wider(
    names_from = type, # first
    values_from = count # second
  )
```

```
## # A tibble: 6 x 4
##   country      year  cases population
##   <chr>       <int>  <int>      <int>
## 1 Afghanistan  1999    745   19987071
## 2 Afghanistan  2000   2666   20595360
## 3 Brazil       1999  37737  172006362
## 4 Brazil       2000  80488  174504898
## 5 China        1999 212258 1272915272
## 6 China        2000 213766 1280428583
```

Sometimes, a consultee came to me and asked: "I don't have missing values in my original dataframe. Then R said that I have missing values after I've done some data transformations. What happened?"

Here's an answer.

R defines missing values in two ways.

-   *Implicit missing values*: simply not present in the data.

-   *Explicit missing values*: flagged with NA

**Challenge**

The example comes from [*R for Data Science*](https://r4ds.had.co.nz/tidy-data.html).


```r
stocks <- tibble(
  year = c(2019, 2019, 2019, 2020, 2020, 2020),
  qtr = c(1, 2, 3, 2, 3, 4),
  return = c(1, 2, 3, NA, 2, 3)
)

stocks
```

```
## # A tibble: 6 x 3
##    year   qtr return
##   <dbl> <dbl>  <dbl>
## 1  2019     1      1
## 2  2019     2      2
## 3  2019     3      3
## 4  2020     2     NA
## 5  2020     3      2
## 6  2020     4      3
```

-   Where is the explicit missing value?

-   Does `stocks` have implicit missing values?


```r
# implicit missing values become explicit
stocks %>%
  pivot_wider(
    names_from = year,
    values_from = return
  )
```

```
## # A tibble: 4 x 3
##     qtr `2019` `2020`
##   <dbl>  <dbl>  <dbl>
## 1     1      1     NA
## 2     2      2     NA
## 3     3      3      2
## 4     4     NA      3
```

**Challenge**

-   This exercise comes from [`pivot` function vigenette](https://tidyr.tidyverse.org/articles/pivot.html).

-   Could you make `station` a series of dummy variables using `pivot_wider()`?


```r
fish_encounters
```

```
## # A tibble: 114 x 3
##    fish  station  seen
##    <fct> <fct>   <int>
##  1 4842  Release     1
##  2 4842  I80_1       1
##  3 4842  Lisbon      1
##  4 4842  Rstr        1
##  5 4842  Base_TD     1
##  6 4842  BCE         1
##  7 4842  BCW         1
##  8 4842  BCE2        1
##  9 4842  BCW2        1
## 10 4842  MAE         1
## # ... with 104 more rows
```

1.  Which pivot should you use?

2.  Are there explicit missing values?

3.  How could you turn these NAs into 0s? Check `values_fill` argument in the `pivot_wider()` function.

-   Separate

![Messy Data Case 2 (Source: R for Data Science)](https://garrettgman.github.io/images/tidy-6.png)


```r
# Toy example
df <- data.frame(x = c(NA, "Dad.apple", "Mom.orange", "Daughter.banana"))

df
```

```
##                 x
## 1            <NA>
## 2       Dad.apple
## 3      Mom.orange
## 4 Daughter.banana
```


```r
# Separate
df %>%
  separate(x, into = c("Name", "Preferred_fruit"))
```

```
##       Name Preferred_fruit
## 1     <NA>            <NA>
## 2      Dad           apple
## 3      Mom          orange
## 4 Daughter          banana
```

```r
# Don't need the first variable

df %>%
  separate(x, into = c(NA, "Preferred_fruit"))
```

```
##   Preferred_fruit
## 1            <NA>
## 2           apple
## 3          orange
## 4          banana
```

**Practice**


```r
table3
```

```
## # A tibble: 6 x 3
##   country      year rate             
## * <chr>       <int> <chr>            
## 1 Afghanistan  1999 745/19987071     
## 2 Afghanistan  2000 2666/20595360    
## 3 Brazil       1999 37737/172006362  
## 4 Brazil       2000 80488/174504898  
## 5 China        1999 212258/1272915272
## 6 China        2000 213766/1280428583
```

-   Note `sep` argument. You can specify how to separate joined values.


```r
table3 %>%
  separate(rate,
    into = c("cases", "population"),
    sep = "/"
  )
```

```
## # A tibble: 6 x 4
##   country      year cases  population
##   <chr>       <int> <chr>  <chr>     
## 1 Afghanistan  1999 745    19987071  
## 2 Afghanistan  2000 2666   20595360  
## 3 Brazil       1999 37737  172006362 
## 4 Brazil       2000 80488  174504898 
## 5 China        1999 212258 1272915272
## 6 China        2000 213766 1280428583
```

-   Note `convert` argument. You can specify whether automatically convert the new values or not.


```r
table3 %>%
  separate(rate,
    into = c("cases", "population"),
    sep = "/",
    convert = TRUE
  ) # cases and population become integers
```

```
## # A tibble: 6 x 4
##   country      year  cases population
##   <chr>       <int>  <int>      <int>
## 1 Afghanistan  1999    745   19987071
## 2 Afghanistan  2000   2666   20595360
## 3 Brazil       1999  37737  172006362
## 4 Brazil       2000  80488  174504898
## 5 China        1999 212258 1272915272
## 6 China        2000 213766 1280428583
```

-   Unite

`pivot_longer()` \<-\> `pivot_wider()`

`separate()` \<-\> `unite()`


```r
# Create a toy example
df <- data.frame(
  name = c("Jae", "Sun", "Jane", NA),
  birthmonth = c("April", "April", "June", NA)
)

# Include missing values
df %>% unite(
  "contact",
  c("name", "birthmonth")
)
```

```
##     contact
## 1 Jae_April
## 2 Sun_April
## 3 Jane_June
## 4     NA_NA
```

```r
# Do not include missing values
df %>% unite("contact",
  c("name", "birthmonth"),
  na.rm = TRUE
)
```

```
##     contact
## 1 Jae_April
## 2 Sun_April
## 3 Jane_June
## 4
```

### Filling

This is a relatively less-known function of the tidyr package. I found this function super useful to complete time-series data. For instance, how can you replace NA in the following example (this use case is drawn from the [tidyr package vignette](https://tidyr.tidyverse.org/reference/fill.html).)?


```r
# Example 
stock <- tibble::tribble(
  ~ quarter, ~ year, ~stock_price, 
  "Q1", 2000, 10000, 
  "Q2", NA, 10001, # Replace NA with 2000  
  "Q3", NA, 10002, # Replace NA with 2000 
  "Q4", NA, 10003, # Replace NA with 2000 
  "Q1", 2001, 10004, 
  "Q2", NA, 10005, # Replace NA with 2001 
  "Q3", NA, 10006, # Replace NA with 2001 
  "Q4", NA, 10007, # Replace NA with 2001
)

fill(stock, year)
```

```
## # A tibble: 8 x 3
##   quarter  year stock_price
##   <chr>   <dbl>       <dbl>
## 1 Q1       2000       10000
## 2 Q2       2000       10001
## 3 Q3       2000       10002
## 4 Q4       2000       10003
## 5 Q1       2001       10004
## 6 Q2       2001       10005
## 7 Q3       2001       10006
## 8 Q4       2001       10007
```

Let's take a slightly more complex example. 


```r
# Example 
yelp_rate <- tibble::tribble(
  ~ neighborhood, ~restraurant_type, ~popularity_rate, 
  "N1", "Chinese", 5, 
  "N2", NA, 4,   
  "N3", NA, 3,  
  "N4", NA, 2,  
  "N1", "Indian", 1, 
  "N2", NA, 2,  
  "N3", NA, 3,  
  "N4", NA, 4, 
  "N1", "Mexican", 5
)

fill(yelp_rate, restraurant_type) # default is direction = .down 
```

```
## # A tibble: 9 x 3
##   neighborhood restraurant_type popularity_rate
##   <chr>        <chr>                      <dbl>
## 1 N1           Chinese                        5
## 2 N2           Chinese                        4
## 3 N3           Chinese                        3
## 4 N4           Chinese                        2
## 5 N1           Indian                         1
## 6 N2           Indian                         2
## 7 N3           Indian                         3
## 8 N4           Indian                         4
## 9 N1           Mexican                        5
```

```r
fill(yelp_rate, restraurant_type, .direction = "up") 
```

```
## # A tibble: 9 x 3
##   neighborhood restraurant_type popularity_rate
##   <chr>        <chr>                      <dbl>
## 1 N1           Chinese                        5
## 2 N2           Indian                         4
## 3 N3           Indian                         3
## 4 N4           Indian                         2
## 5 N1           Indian                         1
## 6 N2           Mexican                        2
## 7 N3           Mexican                        3
## 8 N4           Mexican                        4
## 9 N1           Mexican                        5
```

## Manipulating (dplyr)


![Concept map for dplyr. By Monica Alonso, Greg Wilson.](https://education.rstudio.com/blog/2020/09/concept-maps/dplyr.png)

`dplyr` is better than the base R approaches to data processing:

- fast to run (due to the C++ backed) and intuitive to type
- works well with tidy data and databases (thanks to [`dbplyr`](https://dbplyr.tidyverse.org/))

### Rearranging

-   Arrange

-   Order rows


```r
dplyr::arrange(mtcars, mpg) # Low to High (default)
```

```
##                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb
## Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4
## Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4
## Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4
## Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4
## Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4
## Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8
## Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
## AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2
## Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2
## Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4
## Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3
## Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3
## Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4
## Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1
## Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
## Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
## Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2
## Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6
## Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
## Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
## Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2
## Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
## Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
## Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
## Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
## Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
## Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1
## Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
## Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2
## Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
## Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1
```

```r
dplyr::arrange(mtcars, desc(mpg)) # High to Row
```

```
##                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb
## Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1
## Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
## Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
## Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2
## Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1
## Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
## Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
## Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
## Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
## Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
## Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
## Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2
## Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
## Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6
## Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
## Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2
## Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
## Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1
## Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4
## Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3
## Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3
## Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4
## Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2
## Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
## AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2
## Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8
## Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4
## Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4
## Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4
## Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4
## Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4
```

-   Rename

-   Rename columns


```r
df <- tibble(y = c(2011, 2012, 2013))

df %>%
  rename(
    Year = # NEW name
    y
  ) # OLD name
```

```
## # A tibble: 3 x 1
##    Year
##   <dbl>
## 1  2011
## 2  2012
## 3  2013
```

### Subset observations (rows)

-   Choose row by logical condition

-   Single condition


```r
starwars %>%
  filter(gender == "feminine") %>%
  arrange(desc(height))
```

```
## # A tibble: 17 x 14
##    name    height  mass hair_color skin_color  eye_color birth_year sex   gender
##    <chr>    <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr> <chr> 
##  1 Taun We    213  NA   none       grey        black             NA fema~ femin~
##  2 Adi Ga~    184  50   none       dark        blue              NA fema~ femin~
##  3 Ayla S~    178  55   none       blue        hazel             48 fema~ femin~
##  4 Shaak ~    178  57   none       red, blue,~ black             NA fema~ femin~
##  5 Lumina~    170  56.2 black      yellow      blue              58 fema~ femin~
##  6 Zam We~    168  55   blonde     fair, gree~ yellow            NA fema~ femin~
##  7 Jocast~    167  NA   white      fair        blue              NA fema~ femin~
##  8 Barris~    166  50   black      yellow      blue              40 fema~ femin~
##  9 Beru W~    165  75   brown      light       blue              47 fema~ femin~
## 10 Dormé      165  NA   brown      light       brown             NA fema~ femin~
## 11 Padmé ~    165  45   brown      light       brown             46 fema~ femin~
## 12 Shmi S~    163  NA   black      fair        brown             72 fema~ femin~
## 13 Cordé      157  NA   brown      light       brown             NA fema~ femin~
## 14 Leia O~    150  49   brown      light       brown             19 fema~ femin~
## 15 Mon Mo~    150  NA   auburn     fair        blue              48 fema~ femin~
## 16 R4-P17      96  NA   none       silver, red red, blue         NA none  femin~
## 17 Rey         NA  NA   brown      light       hazel             NA fema~ femin~
## # ... with 5 more variables: homeworld <chr>, species <chr>, films <list>,
## #   vehicles <list>, starships <list>
```

The following filtering example was inspired by [the suzanbert's dplyr blog post](https://suzan.rbind.io/2018/02/dplyr-tutorial-3/).

-   Multiple conditions (numeric)


```r
# First example
starwars %>%
  filter(height < 180, height > 160) %>%
  nrow()
```

```
## [1] 24
```

```r
# Same as above
starwars %>%
  filter(height < 180 & height > 160) %>%
  nrow()
```

```
## [1] 24
```

```r
# Not same as above
starwars %>%
  filter(height < 180 | height > 160) %>%
  nrow()
```

```
## [1] 81
```

**Challenge**

(1) Use `filter(between())` to find characters whose heights are between 180 and 160 and (2) count the number of these observations.

-   Minimum reproducible example


```r
df <- tibble(
  heights = c(160:180),
  char = rep("none", length(c(160:180)))
)

df %>%
  filter(between(heights, 161, 179))
```

```
## # A tibble: 19 x 2
##    heights char 
##      <int> <chr>
##  1     161 none 
##  2     162 none 
##  3     163 none 
##  4     164 none 
##  5     165 none 
##  6     166 none 
##  7     167 none 
##  8     168 none 
##  9     169 none 
## 10     170 none 
## 11     171 none 
## 12     172 none 
## 13     173 none 
## 14     174 none 
## 15     175 none 
## 16     176 none 
## 17     177 none 
## 18     178 none 
## 19     179 none
```

-   Multiple conditions (character)


```r
# Filter names include ars; `grepl` is a base R function

starwars %>%
  filter(grepl("ars", tolower(name)))
```

```
## # A tibble: 4 x 14
##   name     height  mass hair_color  skin_color eye_color birth_year sex   gender
##   <chr>     <int> <dbl> <chr>       <chr>      <chr>          <dbl> <chr> <chr> 
## 1 Owen La~    178   120 brown, grey light      blue              52 male  mascu~
## 2 Beru Wh~    165    75 brown       light      blue              47 fema~ femin~
## 3 Quarsh ~    183    NA black       dark       brown             62 <NA>  <NA>  
## 4 Cliegg ~    183    NA brown       fair       blue              82 male  mascu~
## # ... with 5 more variables: homeworld <chr>, species <chr>, films <list>,
## #   vehicles <list>, starships <list>
```

```r
# Or, if you prefer dplyr way

starwars %>%
  filter(str_detect(tolower(name), "ars"))
```

```
## # A tibble: 4 x 14
##   name     height  mass hair_color  skin_color eye_color birth_year sex   gender
##   <chr>     <int> <dbl> <chr>       <chr>      <chr>          <dbl> <chr> <chr> 
## 1 Owen La~    178   120 brown, grey light      blue              52 male  mascu~
## 2 Beru Wh~    165    75 brown       light      blue              47 fema~ femin~
## 3 Quarsh ~    183    NA black       dark       brown             62 <NA>  <NA>  
## 4 Cliegg ~    183    NA brown       fair       blue              82 male  mascu~
## # ... with 5 more variables: homeworld <chr>, species <chr>, films <list>,
## #   vehicles <list>, starships <list>
```

```r
# Filter brown and black hair_color

starwars %>%
  filter(hair_color %in% c("black", "brown"))
```

```
## # A tibble: 31 x 14
##    name     height  mass hair_color skin_color eye_color birth_year sex   gender
##    <chr>     <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> 
##  1 Leia Or~    150  49   brown      light      brown           19   fema~ femin~
##  2 Beru Wh~    165  75   brown      light      blue            47   fema~ femin~
##  3 Biggs D~    183  84   black      light      brown           24   male  mascu~
##  4 Chewbac~    228 112   brown      unknown    blue           200   male  mascu~
##  5 Han Solo    180  80   brown      fair       brown           29   male  mascu~
##  6 Wedge A~    170  77   brown      fair       hazel           21   male  mascu~
##  7 Jek Ton~    180 110   brown      fair       blue            NA   male  mascu~
##  8 Boba Fe~    183  78.2 black      fair       brown           31.5 male  mascu~
##  9 Lando C~    177  79   black      dark       brown           31   male  mascu~
## 10 Arvel C~     NA  NA   brown      fair       brown           NA   male  mascu~
## # ... with 21 more rows, and 5 more variables: homeworld <chr>, species <chr>,
## #   films <list>, vehicles <list>, starships <list>
```

**Challenge**

Use `str_detect()` to find characters whose names include "Han".

-   Choose row by position (row index)


```r
starwars %>%
  arrange(desc(height)) %>%
  slice(1:6)
```

```
## # A tibble: 6 x 14
##   name    height  mass hair_color skin_color  eye_color  birth_year sex   gender
##   <chr>    <int> <dbl> <chr>      <chr>       <chr>           <dbl> <chr> <chr> 
## 1 Yarael~    264    NA none       white       yellow             NA male  mascu~
## 2 Tarfful    234   136 brown      brown       blue               NA male  mascu~
## 3 Lama Su    229    88 none       grey        black              NA male  mascu~
## 4 Chewba~    228   112 brown      unknown     blue              200 male  mascu~
## 5 Roos T~    224    82 none       grey        orange             NA male  mascu~
## 6 Grievo~    216   159 none       brown, whi~ green, ye~         NA male  mascu~
## # ... with 5 more variables: homeworld <chr>, species <chr>, films <list>,
## #   vehicles <list>, starships <list>
```

-   Sample by a fraction


```r
# For reproducibility
set.seed(1234)

# Old way

starwars %>%
  sample_frac(0.10,
    replace = FALSE
  ) # Without replacement
```

```
## # A tibble: 9 x 14
##   name    height  mass hair_color skin_color  eye_color birth_year sex    gender
##   <chr>    <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr>  <chr> 
## 1 Arvel ~     NA    NA brown      fair        brown           NA   male   mascu~
## 2 Sly Mo~    178    48 none       pale        white           NA   <NA>   <NA>  
## 3 IG-88      200   140 none       metal       red             15   none   mascu~
## 4 Biggs ~    183    84 black      light       brown           24   male   mascu~
## 5 Leia O~    150    49 brown      light       brown           19   female femin~
## 6 Watto      137    NA black      blue, grey  yellow          NA   male   mascu~
## 7 Jabba ~    175  1358 <NA>       green-tan,~ orange         600   herma~ mascu~
## 8 Darth ~    202   136 none       white       yellow          41.9 male   mascu~
## 9 Taun We    213    NA none       grey        black           NA   female femin~
## # ... with 5 more variables: homeworld <chr>, species <chr>, films <list>,
## #   vehicles <list>, starships <list>
```

```r
# New way

starwars %>%
  slice_sample(
    prop = 0.10,
    replace = FALSE
  )
```

```
## # A tibble: 8 x 14
##   name     height  mass hair_color skin_color eye_color birth_year sex    gender
##   <chr>     <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr>  <chr> 
## 1 Raymus ~    188  79   brown      light      brown           NA   male   mascu~
## 2 Tarfful     234 136   brown      brown      blue            NA   male   mascu~
## 3 Han Solo    180  80   brown      fair       brown           29   male   mascu~
## 4 Mas Ame~    196  NA   none       blue       blue            NA   male   mascu~
## 5 Barriss~    166  50   black      yellow     blue            40   female femin~
## 6 Darth V~    202 136   none       white      yellow          41.9 male   mascu~
## 7 Finn         NA  NA   black      dark       dark            NA   male   mascu~
## 8 Boba Fe~    183  78.2 black      fair       brown           31.5 male   mascu~
## # ... with 5 more variables: homeworld <chr>, species <chr>, films <list>,
## #   vehicles <list>, starships <list>
```

-   Sample by number


```r
# Old way

starwars %>%
  sample_n(20,
    replace = FALSE
  ) # Without replacement
```

```
## # A tibble: 20 x 14
##    name    height  mass hair_color skin_color  eye_color birth_year sex   gender
##    <chr>    <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr> <chr> 
##  1 Quarsh~    183    NA black      dark        brown             62 <NA>  <NA>  
##  2 Poe Da~     NA    NA brown      light       brown             NA male  mascu~
##  3 Mas Am~    196    NA none       blue        blue              NA male  mascu~
##  4 Zam We~    168    55 blonde     fair, gree~ yellow            NA fema~ femin~
##  5 Leia O~    150    49 brown      light       brown             19 fema~ femin~
##  6 Jango ~    183    79 black      tan         brown             66 male  mascu~
##  7 Ben Qu~    163    65 none       grey, gree~ orange            NA male  mascu~
##  8 Padmé ~    165    45 brown      light       brown             46 fema~ femin~
##  9 Mace W~    188    84 none       dark        brown             72 male  mascu~
## 10 R2-D2       96    32 <NA>       white, blue red               33 none  mascu~
## 11 Shmi S~    163    NA black      fair        brown             72 fema~ femin~
## 12 Ratts ~     79    15 none       grey, blue  unknown           NA male  mascu~
## 13 Nute G~    191    90 none       mottled gr~ red               NA male  mascu~
## 14 Darth ~    175    80 none       red         yellow            54 male  mascu~
## 15 Bib Fo~    180    NA none       pale        pink              NA male  mascu~
## 16 C-3PO      167    75 <NA>       gold        yellow           112 none  mascu~
## 17 Yarael~    264    NA none       white       yellow            NA male  mascu~
## 18 Ki-Adi~    198    82 white      pale        yellow            92 male  mascu~
## 19 BB8         NA    NA none       none        black             NA none  mascu~
## 20 Eeth K~    171    NA black      brown       brown             NA male  mascu~
## # ... with 5 more variables: homeworld <chr>, species <chr>, films <list>,
## #   vehicles <list>, starships <list>
```

```r
# New way

starwars %>%
  slice_sample(
    n = 20,
    replace = FALSE
  ) # Without replacement
```

```
## # A tibble: 20 x 14
##    name    height  mass hair_color  skin_color eye_color birth_year sex   gender
##    <chr>    <int> <dbl> <chr>       <chr>      <chr>          <dbl> <chr> <chr> 
##  1 Owen L~    178   120 brown, grey light      blue              52 male  mascu~
##  2 Ki-Adi~    198    82 white       pale       yellow            92 male  mascu~
##  3 Captai~     NA    NA unknown     unknown    unknown           NA <NA>  <NA>  
##  4 Gregar~    185    85 black       dark       brown             NA male  mascu~
##  5 R5-D4       97    32 <NA>        white, red red               NA none  mascu~
##  6 Ackbar     180    83 none        brown mot~ orange            41 male  mascu~
##  7 Wedge ~    170    77 brown       fair       hazel             21 male  mascu~
##  8 Dormé      165    NA brown       light      brown             NA fema~ femin~
##  9 Rey         NA    NA brown       light      hazel             NA fema~ femin~
## 10 IG-88      200   140 none        metal      red               15 none  mascu~
## 11 Roos T~    224    82 none        grey       orange            NA male  mascu~
## 12 Shmi S~    163    NA black       fair       brown             72 fema~ femin~
## 13 R2-D2       96    32 <NA>        white, bl~ red               33 none  mascu~
## 14 Poe Da~     NA    NA brown       light      brown             NA male  mascu~
## 15 Obi-Wa~    182    77 auburn, wh~ fair       blue-gray         57 male  mascu~
## 16 Plo Ko~    188    80 none        orange     black             22 male  mascu~
## 17 Tarfful    234   136 brown       brown      blue              NA male  mascu~
## 18 Lobot      175    79 none        light      blue              37 male  mascu~
## 19 San Hi~    191    NA none        grey       gold              NA male  mascu~
## 20 Kit Fi~    196    87 none        green      black             NA male  mascu~
## # ... with 5 more variables: homeworld <chr>, species <chr>, films <list>,
## #   vehicles <list>, starships <list>
```

-   Top 10 rows orderd by height


```r
# Old way
starwars %>%
  top_n(10, height)
```

```
## # A tibble: 10 x 14
##    name    height  mass hair_color skin_color  eye_color birth_year sex   gender
##    <chr>    <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr> <chr> 
##  1 Darth ~    202   136 none       white       yellow          41.9 male  mascu~
##  2 Chewba~    228   112 brown      unknown     blue           200   male  mascu~
##  3 Roos T~    224    82 none       grey        orange          NA   male  mascu~
##  4 Rugor ~    206    NA none       green       orange          NA   male  mascu~
##  5 Yarael~    264    NA none       white       yellow          NA   male  mascu~
##  6 Lama Su    229    88 none       grey        black           NA   male  mascu~
##  7 Taun We    213    NA none       grey        black           NA   fema~ femin~
##  8 Grievo~    216   159 none       brown, whi~ green, y~       NA   male  mascu~
##  9 Tarfful    234   136 brown      brown       blue            NA   male  mascu~
## 10 Tion M~    206    80 none       grey        black           NA   male  mascu~
## # ... with 5 more variables: homeworld <chr>, species <chr>, films <list>,
## #   vehicles <list>, starships <list>
```

```r
# New way
starwars %>%
  slice_max(height, n = 10) # Variable first, Argument second
```

```
## # A tibble: 10 x 14
##    name    height  mass hair_color skin_color  eye_color birth_year sex   gender
##    <chr>    <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr> <chr> 
##  1 Yarael~    264    NA none       white       yellow          NA   male  mascu~
##  2 Tarfful    234   136 brown      brown       blue            NA   male  mascu~
##  3 Lama Su    229    88 none       grey        black           NA   male  mascu~
##  4 Chewba~    228   112 brown      unknown     blue           200   male  mascu~
##  5 Roos T~    224    82 none       grey        orange          NA   male  mascu~
##  6 Grievo~    216   159 none       brown, whi~ green, y~       NA   male  mascu~
##  7 Taun We    213    NA none       grey        black           NA   fema~ femin~
##  8 Rugor ~    206    NA none       green       orange          NA   male  mascu~
##  9 Tion M~    206    80 none       grey        black           NA   male  mascu~
## 10 Darth ~    202   136 none       white       yellow          41.9 male  mascu~
## # ... with 5 more variables: homeworld <chr>, species <chr>, films <list>,
## #   vehicles <list>, starships <list>
```

### Subset variables (columns)


```r
names(msleep)
```

```
##  [1] "name"         "genus"        "vore"         "order"        "conservation"
##  [6] "sleep_total"  "sleep_rem"    "sleep_cycle"  "awake"        "brainwt"     
## [11] "bodywt"
```

-   Select only numeric columns


```r
# Only numeric
msleep %>%
  dplyr::select(where(is.numeric))
```

```
## # A tibble: 83 x 6
##    sleep_total sleep_rem sleep_cycle awake  brainwt  bodywt
##          <dbl>     <dbl>       <dbl> <dbl>    <dbl>   <dbl>
##  1        12.1      NA        NA      11.9 NA        50    
##  2        17         1.8      NA       7    0.0155    0.48 
##  3        14.4       2.4      NA       9.6 NA         1.35 
##  4        14.9       2.3       0.133   9.1  0.00029   0.019
##  5         4         0.7       0.667  20    0.423   600    
##  6        14.4       2.2       0.767   9.6 NA         3.85 
##  7         8.7       1.4       0.383  15.3 NA        20.5  
##  8         7        NA        NA      17   NA         0.045
##  9        10.1       2.9       0.333  13.9  0.07     14    
## 10         3        NA        NA      21    0.0982   14.8  
## # ... with 73 more rows
```

**Challenge**

Use `select(where())` to find only non-numeric columns

-   Select the columns that include "sleep" in their names


```r
msleep %>%
  dplyr::select(contains("sleep"))
```

```
## # A tibble: 83 x 3
##    sleep_total sleep_rem sleep_cycle
##          <dbl>     <dbl>       <dbl>
##  1        12.1      NA        NA    
##  2        17         1.8      NA    
##  3        14.4       2.4      NA    
##  4        14.9       2.3       0.133
##  5         4         0.7       0.667
##  6        14.4       2.2       0.767
##  7         8.7       1.4       0.383
##  8         7        NA        NA    
##  9        10.1       2.9       0.333
## 10         3        NA        NA    
## # ... with 73 more rows
```

-   Select the columns that include either "sleep" or "wt" in their names

-   Basic R way

`grepl` is one of the R base pattern matching functions.


```r
msleep[grepl("sleep|wt", names(msleep))]
```

```
## # A tibble: 83 x 5
##    sleep_total sleep_rem sleep_cycle  brainwt  bodywt
##          <dbl>     <dbl>       <dbl>    <dbl>   <dbl>
##  1        12.1      NA        NA     NA        50    
##  2        17         1.8      NA      0.0155    0.48 
##  3        14.4       2.4      NA     NA         1.35 
##  4        14.9       2.3       0.133  0.00029   0.019
##  5         4         0.7       0.667  0.423   600    
##  6        14.4       2.2       0.767 NA         3.85 
##  7         8.7       1.4       0.383 NA        20.5  
##  8         7        NA        NA     NA         0.045
##  9        10.1       2.9       0.333  0.07     14    
## 10         3        NA        NA      0.0982   14.8  
## # ... with 73 more rows
```

**Challenge**

Use `select(match())` to find columns whose names include either "sleep" or "wt".

-   Select the columns that start with "b"


```r
msleep %>%
  dplyr::select(starts_with("b"))
```

```
## # A tibble: 83 x 2
##     brainwt  bodywt
##       <dbl>   <dbl>
##  1 NA        50    
##  2  0.0155    0.48 
##  3 NA         1.35 
##  4  0.00029   0.019
##  5  0.423   600    
##  6 NA         3.85 
##  7 NA        20.5  
##  8 NA         0.045
##  9  0.07     14    
## 10  0.0982   14.8  
## # ... with 73 more rows
```

-   Select the columns that end with "wt"


```r
msleep %>%
  dplyr::select(ends_with("wt"))
```

```
## # A tibble: 83 x 2
##     brainwt  bodywt
##       <dbl>   <dbl>
##  1 NA        50    
##  2  0.0155    0.48 
##  3 NA         1.35 
##  4  0.00029   0.019
##  5  0.423   600    
##  6 NA         3.85 
##  7 NA        20.5  
##  8 NA         0.045
##  9  0.07     14    
## 10  0.0982   14.8  
## # ... with 73 more rows
```

-   Select the columns using both beginning and end string patterns

The key idea is you can use Boolean operators (`!`, `&`, `|`)to combine different string pattern matching statements.


```r
msleep %>%
  dplyr::select(starts_with("b") & ends_with("wt"))
```

```
## # A tibble: 83 x 2
##     brainwt  bodywt
##       <dbl>   <dbl>
##  1 NA        50    
##  2  0.0155    0.48 
##  3 NA         1.35 
##  4  0.00029   0.019
##  5  0.423   600    
##  6 NA         3.85 
##  7 NA        20.5  
##  8 NA         0.045
##  9  0.07     14    
## 10  0.0982   14.8  
## # ... with 73 more rows
```

-   Select the order and move it before everything


```r
# By specifying a column
msleep %>%
  dplyr::select(order, everything())
```

```
## # A tibble: 83 x 11
##    order  name  genus vore  conservation sleep_total sleep_rem sleep_cycle awake
##    <chr>  <chr> <chr> <chr> <chr>              <dbl>     <dbl>       <dbl> <dbl>
##  1 Carni~ Chee~ Acin~ carni lc                  12.1      NA        NA      11.9
##  2 Prima~ Owl ~ Aotus omni  <NA>                17         1.8      NA       7  
##  3 Roden~ Moun~ Aplo~ herbi nt                  14.4       2.4      NA       9.6
##  4 Soric~ Grea~ Blar~ omni  lc                  14.9       2.3       0.133   9.1
##  5 Artio~ Cow   Bos   herbi domesticated         4         0.7       0.667  20  
##  6 Pilosa Thre~ Brad~ herbi <NA>                14.4       2.2       0.767   9.6
##  7 Carni~ Nort~ Call~ carni vu                   8.7       1.4       0.383  15.3
##  8 Roden~ Vesp~ Calo~ <NA>  <NA>                 7        NA        NA      17  
##  9 Carni~ Dog   Canis carni domesticated        10.1       2.9       0.333  13.9
## 10 Artio~ Roe ~ Capr~ herbi lc                   3        NA        NA      21  
## # ... with 73 more rows, and 2 more variables: brainwt <dbl>, bodywt <dbl>
```

-   Select variables from a character vector.


```r
msleep %>%
  dplyr::select(any_of(c("name", "order"))) %>%
  colnames()
```

```
## [1] "name"  "order"
```

-   Select the variables named in character + number pattern


```r
msleep$week8 <- NA

msleep$week12 <- NA

msleep$week_extra <- 0

msleep %>%
  dplyr::select(num_range("week", c(1:12)))
```

```
## # A tibble: 83 x 2
##    week8 week12
##    <lgl> <lgl> 
##  1 NA    NA    
##  2 NA    NA    
##  3 NA    NA    
##  4 NA    NA    
##  5 NA    NA    
##  6 NA    NA    
##  7 NA    NA    
##  8 NA    NA    
##  9 NA    NA    
## 10 NA    NA    
## # ... with 73 more rows
```

**Additional tips**

`msleep` data has nicely cleaned column names. But real-world data are usually messier. The `janitor` package is useful to fix this kind of problem.


```r
messy_df <- tibble::tribble(~"ColNum1", ~"COLNUM2", ~ "COL & NUM3",
                            1, 2, 3)


messy_df
```

```
## # A tibble: 1 x 3
##   ColNum1 COLNUM2 `COL & NUM3`
##     <dbl>   <dbl>        <dbl>
## 1       1       2            3
```

```r
pacman::p_load(janitor)

janitor::clean_names(messy_df) 
```

```
## # A tibble: 1 x 3
##   col_num1 colnum2 col_num3
##      <dbl>   <dbl>    <dbl>
## 1        1       2        3
```

`janitor::tabyl()` is helpful for doing crosstabulation and a nice alternative to `table()` function. 


```r
# Frequency table; The default output class is table 
table(gapminder$country)
```

```
## 
##              Afghanistan                  Albania                  Algeria 
##                       12                       12                       12 
##                   Angola                Argentina                Australia 
##                       12                       12                       12 
##                  Austria                  Bahrain               Bangladesh 
##                       12                       12                       12 
##                  Belgium                    Benin                  Bolivia 
##                       12                       12                       12 
##   Bosnia and Herzegovina                 Botswana                   Brazil 
##                       12                       12                       12 
##                 Bulgaria             Burkina Faso                  Burundi 
##                       12                       12                       12 
##                 Cambodia                 Cameroon                   Canada 
##                       12                       12                       12 
## Central African Republic                     Chad                    Chile 
##                       12                       12                       12 
##                    China                 Colombia                  Comoros 
##                       12                       12                       12 
##         Congo, Dem. Rep.              Congo, Rep.               Costa Rica 
##                       12                       12                       12 
##            Cote d'Ivoire                  Croatia                     Cuba 
##                       12                       12                       12 
##           Czech Republic                  Denmark                 Djibouti 
##                       12                       12                       12 
##       Dominican Republic                  Ecuador                    Egypt 
##                       12                       12                       12 
##              El Salvador        Equatorial Guinea                  Eritrea 
##                       12                       12                       12 
##                 Ethiopia                  Finland                   France 
##                       12                       12                       12 
##                    Gabon                   Gambia                  Germany 
##                       12                       12                       12 
##                    Ghana                   Greece                Guatemala 
##                       12                       12                       12 
##                   Guinea            Guinea-Bissau                    Haiti 
##                       12                       12                       12 
##                 Honduras         Hong Kong, China                  Hungary 
##                       12                       12                       12 
##                  Iceland                    India                Indonesia 
##                       12                       12                       12 
##                     Iran                     Iraq                  Ireland 
##                       12                       12                       12 
##                   Israel                    Italy                  Jamaica 
##                       12                       12                       12 
##                    Japan                   Jordan                    Kenya 
##                       12                       12                       12 
##         Korea, Dem. Rep.              Korea, Rep.                   Kuwait 
##                       12                       12                       12 
##                  Lebanon                  Lesotho                  Liberia 
##                       12                       12                       12 
##                    Libya               Madagascar                   Malawi 
##                       12                       12                       12 
##                 Malaysia                     Mali               Mauritania 
##                       12                       12                       12 
##                Mauritius                   Mexico                 Mongolia 
##                       12                       12                       12 
##               Montenegro                  Morocco               Mozambique 
##                       12                       12                       12 
##                  Myanmar                  Namibia                    Nepal 
##                       12                       12                       12 
##              Netherlands              New Zealand                Nicaragua 
##                       12                       12                       12 
##                    Niger                  Nigeria                   Norway 
##                       12                       12                       12 
##                     Oman                 Pakistan                   Panama 
##                       12                       12                       12 
##                 Paraguay                     Peru              Philippines 
##                       12                       12                       12 
##                   Poland                 Portugal              Puerto Rico 
##                       12                       12                       12 
##                  Reunion                  Romania                   Rwanda 
##                       12                       12                       12 
##    Sao Tome and Principe             Saudi Arabia                  Senegal 
##                       12                       12                       12 
##                   Serbia             Sierra Leone                Singapore 
##                       12                       12                       12 
##          Slovak Republic                 Slovenia                  Somalia 
##                       12                       12                       12 
##             South Africa                    Spain                Sri Lanka 
##                       12                       12                       12 
##                    Sudan                Swaziland                   Sweden 
##                       12                       12                       12 
##              Switzerland                    Syria                   Taiwan 
##                       12                       12                       12 
##                 Tanzania                 Thailand                     Togo 
##                       12                       12                       12 
##      Trinidad and Tobago                  Tunisia                   Turkey 
##                       12                       12                       12 
##                   Uganda           United Kingdom            United States 
##                       12                       12                       12 
##                  Uruguay                Venezuela                  Vietnam 
##                       12                       12                       12 
##       West Bank and Gaza              Yemen, Rep.                   Zambia 
##                       12                       12                       12 
##                 Zimbabwe 
##                       12
```

```r
# Frequency table (unique value, n, percentage)
janitor::tabyl(gapminder$country)
```

```
##         gapminder$country  n     percent
##               Afghanistan 12 0.007042254
##                   Albania 12 0.007042254
##                   Algeria 12 0.007042254
##                    Angola 12 0.007042254
##                 Argentina 12 0.007042254
##                 Australia 12 0.007042254
##                   Austria 12 0.007042254
##                   Bahrain 12 0.007042254
##                Bangladesh 12 0.007042254
##                   Belgium 12 0.007042254
##                     Benin 12 0.007042254
##                   Bolivia 12 0.007042254
##    Bosnia and Herzegovina 12 0.007042254
##                  Botswana 12 0.007042254
##                    Brazil 12 0.007042254
##                  Bulgaria 12 0.007042254
##              Burkina Faso 12 0.007042254
##                   Burundi 12 0.007042254
##                  Cambodia 12 0.007042254
##                  Cameroon 12 0.007042254
##                    Canada 12 0.007042254
##  Central African Republic 12 0.007042254
##                      Chad 12 0.007042254
##                     Chile 12 0.007042254
##                     China 12 0.007042254
##                  Colombia 12 0.007042254
##                   Comoros 12 0.007042254
##          Congo, Dem. Rep. 12 0.007042254
##               Congo, Rep. 12 0.007042254
##                Costa Rica 12 0.007042254
##             Cote d'Ivoire 12 0.007042254
##                   Croatia 12 0.007042254
##                      Cuba 12 0.007042254
##            Czech Republic 12 0.007042254
##                   Denmark 12 0.007042254
##                  Djibouti 12 0.007042254
##        Dominican Republic 12 0.007042254
##                   Ecuador 12 0.007042254
##                     Egypt 12 0.007042254
##               El Salvador 12 0.007042254
##         Equatorial Guinea 12 0.007042254
##                   Eritrea 12 0.007042254
##                  Ethiopia 12 0.007042254
##                   Finland 12 0.007042254
##                    France 12 0.007042254
##                     Gabon 12 0.007042254
##                    Gambia 12 0.007042254
##                   Germany 12 0.007042254
##                     Ghana 12 0.007042254
##                    Greece 12 0.007042254
##                 Guatemala 12 0.007042254
##                    Guinea 12 0.007042254
##             Guinea-Bissau 12 0.007042254
##                     Haiti 12 0.007042254
##                  Honduras 12 0.007042254
##          Hong Kong, China 12 0.007042254
##                   Hungary 12 0.007042254
##                   Iceland 12 0.007042254
##                     India 12 0.007042254
##                 Indonesia 12 0.007042254
##                      Iran 12 0.007042254
##                      Iraq 12 0.007042254
##                   Ireland 12 0.007042254
##                    Israel 12 0.007042254
##                     Italy 12 0.007042254
##                   Jamaica 12 0.007042254
##                     Japan 12 0.007042254
##                    Jordan 12 0.007042254
##                     Kenya 12 0.007042254
##          Korea, Dem. Rep. 12 0.007042254
##               Korea, Rep. 12 0.007042254
##                    Kuwait 12 0.007042254
##                   Lebanon 12 0.007042254
##                   Lesotho 12 0.007042254
##                   Liberia 12 0.007042254
##                     Libya 12 0.007042254
##                Madagascar 12 0.007042254
##                    Malawi 12 0.007042254
##                  Malaysia 12 0.007042254
##                      Mali 12 0.007042254
##                Mauritania 12 0.007042254
##                 Mauritius 12 0.007042254
##                    Mexico 12 0.007042254
##                  Mongolia 12 0.007042254
##                Montenegro 12 0.007042254
##                   Morocco 12 0.007042254
##                Mozambique 12 0.007042254
##                   Myanmar 12 0.007042254
##                   Namibia 12 0.007042254
##                     Nepal 12 0.007042254
##               Netherlands 12 0.007042254
##               New Zealand 12 0.007042254
##                 Nicaragua 12 0.007042254
##                     Niger 12 0.007042254
##                   Nigeria 12 0.007042254
##                    Norway 12 0.007042254
##                      Oman 12 0.007042254
##                  Pakistan 12 0.007042254
##                    Panama 12 0.007042254
##                  Paraguay 12 0.007042254
##                      Peru 12 0.007042254
##               Philippines 12 0.007042254
##                    Poland 12 0.007042254
##                  Portugal 12 0.007042254
##               Puerto Rico 12 0.007042254
##                   Reunion 12 0.007042254
##                   Romania 12 0.007042254
##                    Rwanda 12 0.007042254
##     Sao Tome and Principe 12 0.007042254
##              Saudi Arabia 12 0.007042254
##                   Senegal 12 0.007042254
##                    Serbia 12 0.007042254
##              Sierra Leone 12 0.007042254
##                 Singapore 12 0.007042254
##           Slovak Republic 12 0.007042254
##                  Slovenia 12 0.007042254
##                   Somalia 12 0.007042254
##              South Africa 12 0.007042254
##                     Spain 12 0.007042254
##                 Sri Lanka 12 0.007042254
##                     Sudan 12 0.007042254
##                 Swaziland 12 0.007042254
##                    Sweden 12 0.007042254
##               Switzerland 12 0.007042254
##                     Syria 12 0.007042254
##                    Taiwan 12 0.007042254
##                  Tanzania 12 0.007042254
##                  Thailand 12 0.007042254
##                      Togo 12 0.007042254
##       Trinidad and Tobago 12 0.007042254
##                   Tunisia 12 0.007042254
##                    Turkey 12 0.007042254
##                    Uganda 12 0.007042254
##            United Kingdom 12 0.007042254
##             United States 12 0.007042254
##                   Uruguay 12 0.007042254
##                 Venezuela 12 0.007042254
##                   Vietnam 12 0.007042254
##        West Bank and Gaza 12 0.007042254
##               Yemen, Rep. 12 0.007042254
##                    Zambia 12 0.007042254
##                  Zimbabwe 12 0.007042254
```

```r
# If you want to add percentage ... 
gapminder %>%
  tabyl(country) %>%
  adorn_pct_formatting(digits = 0, affix_sign = TRUE)
```

```
##                   country  n percent
##               Afghanistan 12      1%
##                   Albania 12      1%
##                   Algeria 12      1%
##                    Angola 12      1%
##                 Argentina 12      1%
##                 Australia 12      1%
##                   Austria 12      1%
##                   Bahrain 12      1%
##                Bangladesh 12      1%
##                   Belgium 12      1%
##                     Benin 12      1%
##                   Bolivia 12      1%
##    Bosnia and Herzegovina 12      1%
##                  Botswana 12      1%
##                    Brazil 12      1%
##                  Bulgaria 12      1%
##              Burkina Faso 12      1%
##                   Burundi 12      1%
##                  Cambodia 12      1%
##                  Cameroon 12      1%
##                    Canada 12      1%
##  Central African Republic 12      1%
##                      Chad 12      1%
##                     Chile 12      1%
##                     China 12      1%
##                  Colombia 12      1%
##                   Comoros 12      1%
##          Congo, Dem. Rep. 12      1%
##               Congo, Rep. 12      1%
##                Costa Rica 12      1%
##             Cote d'Ivoire 12      1%
##                   Croatia 12      1%
##                      Cuba 12      1%
##            Czech Republic 12      1%
##                   Denmark 12      1%
##                  Djibouti 12      1%
##        Dominican Republic 12      1%
##                   Ecuador 12      1%
##                     Egypt 12      1%
##               El Salvador 12      1%
##         Equatorial Guinea 12      1%
##                   Eritrea 12      1%
##                  Ethiopia 12      1%
##                   Finland 12      1%
##                    France 12      1%
##                     Gabon 12      1%
##                    Gambia 12      1%
##                   Germany 12      1%
##                     Ghana 12      1%
##                    Greece 12      1%
##                 Guatemala 12      1%
##                    Guinea 12      1%
##             Guinea-Bissau 12      1%
##                     Haiti 12      1%
##                  Honduras 12      1%
##          Hong Kong, China 12      1%
##                   Hungary 12      1%
##                   Iceland 12      1%
##                     India 12      1%
##                 Indonesia 12      1%
##                      Iran 12      1%
##                      Iraq 12      1%
##                   Ireland 12      1%
##                    Israel 12      1%
##                     Italy 12      1%
##                   Jamaica 12      1%
##                     Japan 12      1%
##                    Jordan 12      1%
##                     Kenya 12      1%
##          Korea, Dem. Rep. 12      1%
##               Korea, Rep. 12      1%
##                    Kuwait 12      1%
##                   Lebanon 12      1%
##                   Lesotho 12      1%
##                   Liberia 12      1%
##                     Libya 12      1%
##                Madagascar 12      1%
##                    Malawi 12      1%
##                  Malaysia 12      1%
##                      Mali 12      1%
##                Mauritania 12      1%
##                 Mauritius 12      1%
##                    Mexico 12      1%
##                  Mongolia 12      1%
##                Montenegro 12      1%
##                   Morocco 12      1%
##                Mozambique 12      1%
##                   Myanmar 12      1%
##                   Namibia 12      1%
##                     Nepal 12      1%
##               Netherlands 12      1%
##               New Zealand 12      1%
##                 Nicaragua 12      1%
##                     Niger 12      1%
##                   Nigeria 12      1%
##                    Norway 12      1%
##                      Oman 12      1%
##                  Pakistan 12      1%
##                    Panama 12      1%
##                  Paraguay 12      1%
##                      Peru 12      1%
##               Philippines 12      1%
##                    Poland 12      1%
##                  Portugal 12      1%
##               Puerto Rico 12      1%
##                   Reunion 12      1%
##                   Romania 12      1%
##                    Rwanda 12      1%
##     Sao Tome and Principe 12      1%
##              Saudi Arabia 12      1%
##                   Senegal 12      1%
##                    Serbia 12      1%
##              Sierra Leone 12      1%
##                 Singapore 12      1%
##           Slovak Republic 12      1%
##                  Slovenia 12      1%
##                   Somalia 12      1%
##              South Africa 12      1%
##                     Spain 12      1%
##                 Sri Lanka 12      1%
##                     Sudan 12      1%
##                 Swaziland 12      1%
##                    Sweden 12      1%
##               Switzerland 12      1%
##                     Syria 12      1%
##                    Taiwan 12      1%
##                  Tanzania 12      1%
##                  Thailand 12      1%
##                      Togo 12      1%
##       Trinidad and Tobago 12      1%
##                   Tunisia 12      1%
##                    Turkey 12      1%
##                    Uganda 12      1%
##            United Kingdom 12      1%
##             United States 12      1%
##                   Uruguay 12      1%
##                 Venezuela 12      1%
##                   Vietnam 12      1%
##        West Bank and Gaza 12      1%
##               Yemen, Rep. 12      1%
##                    Zambia 12      1%
##                  Zimbabwe 12      1%
```


### Create variables 



#### Change values using conditions 

You can think of `case_when()` (multiple conditions) as an extended version of `ifelse()` (binary conditions). 


```r
mtcars <- mtcars %>%
  mutate(cyl_dummy = case_when(cyl > median(cyl) ~ "High", # if condition
                               cyl < median(cyl) ~ "Low", # else if condition 
                               TRUE ~ 'Median')) # else condition 

mtcars %>% pull(cyl_dummy)
```

```
##  [1] "Median" "Median" "Low"    "Median" "High"   "Median" "High"   "Low"   
##  [9] "Low"    "Median" "Median" "High"   "High"   "High"   "High"   "High"  
## [17] "High"   "Low"    "Low"    "Low"    "Low"    "High"   "High"   "High"  
## [25] "High"   "Low"    "Low"    "Low"    "High"   "Median" "High"   "Low"
```

#### Change values manually 


```r
mtcars %>%
  mutate(cyl_dummy = recode(cyl_dummy, # Target column 
                            "High" = "2", # Old - New
                            "Low" = "0",
                            "Median" = "1")) %>%
  pull(cyl_dummy)
```

```
##  [1] "1" "1" "0" "1" "2" "1" "2" "0" "0" "1" "1" "2" "2" "2" "2" "2" "2" "0" "0"
## [20] "0" "0" "2" "2" "2" "2" "0" "0" "0" "2" "1" "2" "0"
```


### Counting

-   How may countries in each continent?


```r
gapminder %>%
  count(continent)
```

```
## # A tibble: 5 x 2
##   continent     n
##   <fct>     <int>
## 1 Africa      624
## 2 Americas    300
## 3 Asia        396
## 4 Europe      360
## 5 Oceania      24
```

-   Let's arrange the result.


```r
# Just add a new argument `sort = TRUE`
gapminder %>%
  count(continent, sort = TRUE)
```

```
## # A tibble: 5 x 2
##   continent     n
##   <fct>     <int>
## 1 Africa      624
## 2 Asia        396
## 3 Europe      360
## 4 Americas    300
## 5 Oceania      24
```

```r
# Same as above; How nice!
gapminder %>%
  count(continent) %>%
  arrange(desc(n))
```

```
## # A tibble: 5 x 2
##   continent     n
##   <fct>     <int>
## 1 Africa      624
## 2 Asia        396
## 3 Europe      360
## 4 Americas    300
## 5 Oceania      24
```

**Challenge**

Count the number of observations per `continent` and `year` and arrange them in descending order.

Let's take a deeper look at how things work under the hood.

-   `tally()` works similar to `nrow()`: Calculate the total number of cases in a dataframe

-   `count` = `group_by()` + `tally()`


```r
gapminder %>%
  tally()
```

```
## # A tibble: 1 x 1
##       n
##   <int>
## 1  1704
```

-   `add_tally()` = `mutate(n = n())`

**Challenge**

What does n in the below example represent?


```r
gapminder %>%
  dplyr::select(continent, country) %>%
  add_tally()
```

```
## # A tibble: 1,704 x 3
##    continent country         n
##    <fct>     <fct>       <int>
##  1 Asia      Afghanistan  1704
##  2 Asia      Afghanistan  1704
##  3 Asia      Afghanistan  1704
##  4 Asia      Afghanistan  1704
##  5 Asia      Afghanistan  1704
##  6 Asia      Afghanistan  1704
##  7 Asia      Afghanistan  1704
##  8 Asia      Afghanistan  1704
##  9 Asia      Afghanistan  1704
## 10 Asia      Afghanistan  1704
## # ... with 1,694 more rows
```

-   `add_count`

Add count as a column.


```r
# Add count as a column
gapminder %>%
  group_by(continent) %>%
  add_count(year)
```

```
## # A tibble: 1,704 x 7
## # Groups:   continent [5]
##    country     continent  year lifeExp      pop gdpPercap     n
##    <fct>       <fct>     <int>   <dbl>    <int>     <dbl> <int>
##  1 Afghanistan Asia       1952    28.8  8425333      779.    33
##  2 Afghanistan Asia       1957    30.3  9240934      821.    33
##  3 Afghanistan Asia       1962    32.0 10267083      853.    33
##  4 Afghanistan Asia       1967    34.0 11537966      836.    33
##  5 Afghanistan Asia       1972    36.1 13079460      740.    33
##  6 Afghanistan Asia       1977    38.4 14880372      786.    33
##  7 Afghanistan Asia       1982    39.9 12881816      978.    33
##  8 Afghanistan Asia       1987    40.8 13867957      852.    33
##  9 Afghanistan Asia       1992    41.7 16317921      649.    33
## 10 Afghanistan Asia       1997    41.8 22227415      635.    33
## # ... with 1,694 more rows
```

**Challenge**

Do cases 1 and 2 in the below code chunk produce the same outputs? If so, why?


```r
# Case 1
gapminder %>%
  group_by(continent, year) %>%
  count()
```

```
## # A tibble: 60 x 3
## # Groups:   continent, year [60]
##    continent  year     n
##    <fct>     <int> <int>
##  1 Africa     1952    52
##  2 Africa     1957    52
##  3 Africa     1962    52
##  4 Africa     1967    52
##  5 Africa     1972    52
##  6 Africa     1977    52
##  7 Africa     1982    52
##  8 Africa     1987    52
##  9 Africa     1992    52
## 10 Africa     1997    52
## # ... with 50 more rows
```

```r
# Case 2
gapminder %>%
  group_by(continent) %>%
  count(year)
```

```
## # A tibble: 60 x 3
## # Groups:   continent [5]
##    continent  year     n
##    <fct>     <int> <int>
##  1 Africa     1952    52
##  2 Africa     1957    52
##  3 Africa     1962    52
##  4 Africa     1967    52
##  5 Africa     1972    52
##  6 Africa     1977    52
##  7 Africa     1982    52
##  8 Africa     1987    52
##  9 Africa     1992    52
## 10 Africa     1997    52
## # ... with 50 more rows
```

`count()` is a simple function, but it is still helpful to learn an essential concept underlying complex data wrangling: split-apply-combine strategy. For more information, read Wickham's article (2011) ["The Split-Apply-Combine Strategy for Data Analysis"](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.182.5667&rep=rep1&type=pdf) published in the *Journal of Statistical Software* (especially pages 7-8). [`plyr`](https://github.com/hadley/plyr) was the package (retired) that demonstrated this idea, which has evolved into two directions: [dplyr](https://dplyr.tidyverse.org/) (for data frames) and [purrr](https://purrr.tidyverse.org/) (for lists)

### Summarizing

#### Basic

- Create a summary
- Think of `summarise()` as an extended version of `count()`.


```r
gapminder %>%
  group_by(continent) %>%
  summarise(
    n = n(),
    mean_gdp = mean(gdpPercap),
    sd_gdp = sd(gdpPercap)
  )
```

```
## # A tibble: 5 x 4
##   continent     n mean_gdp sd_gdp
##   <fct>     <int>    <dbl>  <dbl>
## 1 Africa      624    2194.  2828.
## 2 Americas    300    7136.  6397.
## 3 Asia        396    7902. 14045.
## 4 Europe      360   14469.  9355.
## 5 Oceania      24   18622.  6359.
```

```r
tablea <- gapminder %>%
  group_by(continent) %>%
  summarise(
    n = n(),
    mean_gdp = mean(gdpPercap),
    sd_gdp = sd(gdpPercap)
  )
```

-   Produce publishable tables


```r
pacman::p_load(kableExtra,
               flextable)

# For HTML and LaTeX
tablea %>% kableExtra::kable()
```


\begin{tabular}{l|r|r|r}
\hline
continent & n & mean\_gdp & sd\_gdp\\
\hline
Africa & 624 & 2193.755 & 2827.930\\
\hline
Americas & 300 & 7136.110 & 6396.764\\
\hline
Asia & 396 & 7902.150 & 14045.373\\
\hline
Europe & 360 & 14469.476 & 9355.213\\
\hline
Oceania & 24 & 18621.609 & 6358.983\\
\hline
\end{tabular}

```r
# For HTML and MS Office suite
tablea %>% flextable::flextable()
```

\providecommand{\docline}[3]{\noalign{\global\setlength{\arrayrulewidth}{#1}}\arrayrulecolor[HTML]{#2}\cline{#3}}

\setlength{\tabcolsep}{2pt}

\renewcommand*{\arraystretch}{1.5}

\begin{longtable}[c]{|p{0.75in}|p{0.75in}|p{0.75in}|p{0.75in}}



\hhline{>{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}-}

\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedright}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{continent}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{n}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{mean\_gdp}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{sd\_gdp}}}} \\

\hhline{>{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}-}

\endfirsthead

\hhline{>{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}-}

\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedright}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{continent}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{n}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{mean\_gdp}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{sd\_gdp}}}} \\

\hhline{>{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}-}\endhead



\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedright}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{Africa}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{624}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{2,193.755}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{2,827.930}}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedright}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{Americas}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{300}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{7,136.110}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{6,396.764}}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedright}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{Asia}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{396}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{7,902.150}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{14,045.373}}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedright}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{Europe}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{360}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{14,469.476}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{9,355.213}}}} \\





\multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedright}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{Oceania}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{24}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{18,621.609}}}} & \multicolumn{1}{!{\color[HTML]{000000}\vrule width 0pt}>{\raggedleft}p{\dimexpr 0.75in+0\tabcolsep+0\arrayrulewidth}!{\color[HTML]{000000}\vrule width 0pt}}{\fontsize{11}{11}\selectfont{\textcolor[HTML]{000000}{\global\setmainfont{DejaVu Sans}{6,358.983}}}} \\

\hhline{>{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}->{\arrayrulecolor[HTML]{666666}\global\arrayrulewidth=2pt}-}



\end{longtable}

#### Scoped summaries

-   Old way

-   `summarise_all()`


```r
# Create a wide-shaped data example
wide_gapminder <- gapminder %>%
  filter(continent == "Europe") %>%
  pivot_wider(
    names_from = country,
    values_from = gdpPercap
  )

# Apply summarise_all
wide_gapminder %>%
  dplyr::select(-c(1:4)) %>%
  summarise_all(mean, na.rm = TRUE)
```

```
## # A tibble: 1 x 30
##   Albania Austria Belgium `Bosnia and Herzego~ Bulgaria Croatia `Czech Republic`
##     <dbl>   <dbl>   <dbl>                <dbl>    <dbl>   <dbl>            <dbl>
## 1   3255.  20412.  19901.                3485.    6384.   9332.           13920.
## # ... with 23 more variables: Denmark <dbl>, Finland <dbl>, France <dbl>,
## #   Germany <dbl>, Greece <dbl>, Hungary <dbl>, Iceland <dbl>, Ireland <dbl>,
## #   Italy <dbl>, Montenegro <dbl>, Netherlands <dbl>, Norway <dbl>,
## #   Poland <dbl>, Portugal <dbl>, Romania <dbl>, Serbia <dbl>,
## #   Slovak Republic <dbl>, Slovenia <dbl>, Spain <dbl>, Sweden <dbl>,
## #   Switzerland <dbl>, Turkey <dbl>, United Kingdom <dbl>
```

-   `summarise_if()`: using a logical condition


```r
wide_gapminder %>%
  summarise_if(is.double, mean, na.rm = TRUE)
```

```
## # A tibble: 1 x 31
##   lifeExp Albania Austria Belgium `Bosnia and Herzegovina` Bulgaria Croatia
##     <dbl>   <dbl>   <dbl>   <dbl>                    <dbl>    <dbl>   <dbl>
## 1    71.9   3255.  20412.  19901.                    3485.    6384.   9332.
## # ... with 24 more variables: Czech Republic <dbl>, Denmark <dbl>,
## #   Finland <dbl>, France <dbl>, Germany <dbl>, Greece <dbl>, Hungary <dbl>,
## #   Iceland <dbl>, Ireland <dbl>, Italy <dbl>, Montenegro <dbl>,
## #   Netherlands <dbl>, Norway <dbl>, Poland <dbl>, Portugal <dbl>,
## #   Romania <dbl>, Serbia <dbl>, Slovak Republic <dbl>, Slovenia <dbl>,
## #   Spain <dbl>, Sweden <dbl>, Switzerland <dbl>, Turkey <dbl>,
## #   United Kingdom <dbl>
```

-   `summarise_at()`

-   `vars() = select()`


```r
wide_gapminder %>%
  summarise_at(vars(-c(1:4)),
    mean,
    na.rm = TRUE
  )
```

```
## # A tibble: 1 x 30
##   Albania Austria Belgium `Bosnia and Herzego~ Bulgaria Croatia `Czech Republic`
##     <dbl>   <dbl>   <dbl>                <dbl>    <dbl>   <dbl>            <dbl>
## 1   3255.  20412.  19901.                3485.    6384.   9332.           13920.
## # ... with 23 more variables: Denmark <dbl>, Finland <dbl>, France <dbl>,
## #   Germany <dbl>, Greece <dbl>, Hungary <dbl>, Iceland <dbl>, Ireland <dbl>,
## #   Italy <dbl>, Montenegro <dbl>, Netherlands <dbl>, Norway <dbl>,
## #   Poland <dbl>, Portugal <dbl>, Romania <dbl>, Serbia <dbl>,
## #   Slovak Republic <dbl>, Slovenia <dbl>, Spain <dbl>, Sweden <dbl>,
## #   Switzerland <dbl>, Turkey <dbl>, United Kingdom <dbl>
```

```r
wide_gapminder %>%
  summarise_at(vars(contains("life")),
    mean,
    na.rm = TRUE
  )
```

```
## # A tibble: 1 x 1
##   lifeExp
##     <dbl>
## 1    71.9
```

**Additional tips**


![Concept map for regular expressions. By Monica Alonso, Greg Wilson.](https://github.com/rstudio/concept-maps/raw/master/en/regular-expressions.svg)


-   New way

-   `summarise()` + `across()`


![Concept map for across. By Emma Vestesson](https://github.com/rstudio/concept-maps/raw/master/en/across.svg)


-   If you find using `summarise_all()`, `summarise_if()` and `summarise_at()` confusing, here's a solution: use `summarise()` with `across()`.

-   `summarise_all()`


```r
wide_gapminder %>%
  summarise(across(Albania:`United Kingdom`, mean, na.rm = TRUE))
```

```
## # A tibble: 1 x 30
##   Albania Austria Belgium `Bosnia and Herzego~ Bulgaria Croatia `Czech Republic`
##     <dbl>   <dbl>   <dbl>                <dbl>    <dbl>   <dbl>            <dbl>
## 1   3255.  20412.  19901.                3485.    6384.   9332.           13920.
## # ... with 23 more variables: Denmark <dbl>, Finland <dbl>, France <dbl>,
## #   Germany <dbl>, Greece <dbl>, Hungary <dbl>, Iceland <dbl>, Ireland <dbl>,
## #   Italy <dbl>, Montenegro <dbl>, Netherlands <dbl>, Norway <dbl>,
## #   Poland <dbl>, Portugal <dbl>, Romania <dbl>, Serbia <dbl>,
## #   Slovak Republic <dbl>, Slovenia <dbl>, Spain <dbl>, Sweden <dbl>,
## #   Switzerland <dbl>, Turkey <dbl>, United Kingdom <dbl>
```

```r
wide_gapminder %>%
  summarise(across(-c(1:4), mean, na.rm = TRUE))
```

```
## # A tibble: 1 x 30
##   Albania Austria Belgium `Bosnia and Herzego~ Bulgaria Croatia `Czech Republic`
##     <dbl>   <dbl>   <dbl>                <dbl>    <dbl>   <dbl>            <dbl>
## 1   3255.  20412.  19901.                3485.    6384.   9332.           13920.
## # ... with 23 more variables: Denmark <dbl>, Finland <dbl>, France <dbl>,
## #   Germany <dbl>, Greece <dbl>, Hungary <dbl>, Iceland <dbl>, Ireland <dbl>,
## #   Italy <dbl>, Montenegro <dbl>, Netherlands <dbl>, Norway <dbl>,
## #   Poland <dbl>, Portugal <dbl>, Romania <dbl>, Serbia <dbl>,
## #   Slovak Republic <dbl>, Slovenia <dbl>, Spain <dbl>, Sweden <dbl>,
## #   Switzerland <dbl>, Turkey <dbl>, United Kingdom <dbl>
```

-   `summarise_if()`


```r
wide_gapminder %>%
  summarise(across(is.double, mean, na.rm = TRUE))
```

```
## Warning: Predicate functions must be wrapped in `where()`.
## 
##   # Bad
##   data %>% select(is.double)
## 
##   # Good
##   data %>% select(where(is.double))
## 
## i Please update your code.
## This message is displayed once per session.
```

```
## # A tibble: 1 x 31
##   lifeExp Albania Austria Belgium `Bosnia and Herzegovina` Bulgaria Croatia
##     <dbl>   <dbl>   <dbl>   <dbl>                    <dbl>    <dbl>   <dbl>
## 1    71.9   3255.  20412.  19901.                    3485.    6384.   9332.
## # ... with 24 more variables: Czech Republic <dbl>, Denmark <dbl>,
## #   Finland <dbl>, France <dbl>, Germany <dbl>, Greece <dbl>, Hungary <dbl>,
## #   Iceland <dbl>, Ireland <dbl>, Italy <dbl>, Montenegro <dbl>,
## #   Netherlands <dbl>, Norway <dbl>, Poland <dbl>, Portugal <dbl>,
## #   Romania <dbl>, Serbia <dbl>, Slovak Republic <dbl>, Slovenia <dbl>,
## #   Spain <dbl>, Sweden <dbl>, Switzerland <dbl>, Turkey <dbl>,
## #   United Kingdom <dbl>
```

-   `summarise_at()`


```r
wide_gapminder %>%
  summarise(across(-c(1:4),
    mean,
    na.rm = TRUE
  ))
```

```
## # A tibble: 1 x 30
##   Albania Austria Belgium `Bosnia and Herzego~ Bulgaria Croatia `Czech Republic`
##     <dbl>   <dbl>   <dbl>                <dbl>    <dbl>   <dbl>            <dbl>
## 1   3255.  20412.  19901.                3485.    6384.   9332.           13920.
## # ... with 23 more variables: Denmark <dbl>, Finland <dbl>, France <dbl>,
## #   Germany <dbl>, Greece <dbl>, Hungary <dbl>, Iceland <dbl>, Ireland <dbl>,
## #   Italy <dbl>, Montenegro <dbl>, Netherlands <dbl>, Norway <dbl>,
## #   Poland <dbl>, Portugal <dbl>, Romania <dbl>, Serbia <dbl>,
## #   Slovak Republic <dbl>, Slovenia <dbl>, Spain <dbl>, Sweden <dbl>,
## #   Switzerland <dbl>, Turkey <dbl>, United Kingdom <dbl>
```

```r
wide_gapminder %>%
  summarise(across(contains("life"),
    mean,
    na.rm = TRUE
  ))
```

```
## # A tibble: 1 x 1
##   lifeExp
##     <dbl>
## 1    71.9
```

```r
wide_gapminder %>%
  summarise(across(contains("A", ignore.case = FALSE)))
```

```
## # A tibble: 360 x 2
##    Albania Austria
##      <dbl>   <dbl>
##  1   1601.      NA
##  2   1942.      NA
##  3   2313.      NA
##  4   2760.      NA
##  5   3313.      NA
##  6   3533.      NA
##  7   3631.      NA
##  8   3739.      NA
##  9   2497.      NA
## 10   3193.      NA
## # ... with 350 more rows
```

Note that this workshop does not cover creating and manipulating variables using `mutate()` because many techniques you learned from playing with `summarise()` can be directly applied to `mutate()`.

**Challenge**

1.  Summarize the average GDP of countries whose names starting with the alphabet "A".

2.  Turn the summary dataframe into a publishable table using either `kableExtra` or `flextable` package.

#### Tabulation (TBD)

### Grouping

#### Grouped summaries

- Calculate the mean of `gdpPercap`.

- Some functions are designed to work together. For instance, the group_by
function defines the strata that you're going to use for summary statistics. Then, use summarise() or summarize() for producing summary statistics.


```r
gapminder %>%
  group_by(continent) %>% #
  summarise(mean_gdp = mean(gdpPercap))
```

```
## # A tibble: 5 x 2
##   continent mean_gdp
##   <fct>        <dbl>
## 1 Africa       2194.
## 2 Americas     7136.
## 3 Asia         7902.
## 4 Europe      14469.
## 5 Oceania     18622.
```

-   Calculate multiple summary statistics.


```r
gapminder %>%
  group_by(continent) %>% #
  summarise(
    mean_gdp = mean(gdpPercap),
    count = n()
  )
```

```
## # A tibble: 5 x 3
##   continent mean_gdp count
##   <fct>        <dbl> <int>
## 1 Africa       2194.   624
## 2 Americas     7136.   300
## 3 Asia         7902.   396
## 4 Europe      14469.   360
## 5 Oceania     18622.    24
```

**Optional**

-   Other summary statistics

1.  Measures of spread: `median(x)`, `sd(x)`, `IQR(x)`, `mad(x)` (the median absolute deviation)


```r
# The Interquartile Range = The Difference Between 75t and 25t Percentiles

gapminder %>%
  group_by(continent) %>% #
  summarise(IQR_gdp = IQR(gdpPercap))
```

```
## # A tibble: 5 x 2
##   continent IQR_gdp
##   <fct>       <dbl>
## 1 Africa      1616.
## 2 Americas    4402.
## 3 Asia        7492.
## 4 Europe     13248.
## 5 Oceania     8072.
```

2.  Measures of rank: `min(x)`, `quantile(x, 0.25)`, `max(x)`


```r
gapminder %>%
  group_by(continent) %>% #
  summarise(
    min_gdp = min(gdpPercap),
    max_gdp = max(gdpPercap)
  )
```

```
## # A tibble: 5 x 3
##   continent min_gdp max_gdp
##   <fct>       <dbl>   <dbl>
## 1 Africa       241.  21951.
## 2 Americas    1202.  42952.
## 3 Asia         331  113523.
## 4 Europe       974.  49357.
## 5 Oceania    10040.  34435.
```

3.  Measures of position: `first(x)`, `last(x)`, `nth(x, 2)`


```r
gapminder %>%
  group_by(continent) %>%
  summarise(
    first_gdp = first(gdpPercap),
    last_gdp = last(gdpPercap)
  )
```

```
## # A tibble: 5 x 3
##   continent first_gdp last_gdp
##   <fct>         <dbl>    <dbl>
## 1 Africa        2449.     470.
## 2 Americas      5911.   11416.
## 3 Asia           779.    2281.
## 4 Europe        1601.   33203.
## 5 Oceania      10040.   25185.
```

```r
gapminder %>%
  group_by(continent) %>%
  arrange(gdpPercap) %>% # Adding arrange
  summarise(
    first_gdp = first(gdpPercap),
    last_gdp = last(gdpPercap)
  )
```

```
## # A tibble: 5 x 3
##   continent first_gdp last_gdp
##   <fct>         <dbl>    <dbl>
## 1 Africa         241.   21951.
## 2 Americas      1202.   42952.
## 3 Asia           331   113523.
## 4 Europe         974.   49357.
## 5 Oceania      10040.   34435.
```

4.  Measures of counts: `n(x)` (all rows), `sum(!is.na(x))` (only non-missing rows) = `n_distinct(x)`


```r
gapminder %>%
  group_by(continent) %>%
  summarise(ns = n())
```

```
## # A tibble: 5 x 2
##   continent    ns
##   <fct>     <int>
## 1 Africa      624
## 2 Americas    300
## 3 Asia        396
## 4 Europe      360
## 5 Oceania      24
```

5.  Counts and proportions of logical values: `sum(condition about x)` (the number of TRUEs in x), `mean(condition about x)` (the proportion of TRUEs in x)


```r
gapminder %>%
  group_by(continent) %>%
  summarise(rich_countries = mean(gdpPercap > 20000))
```

```
## # A tibble: 5 x 2
##   continent rich_countries
##   <fct>              <dbl>
## 1 Africa           0.00481
## 2 Americas         0.05   
## 3 Asia             0.111  
## 4 Europe           0.261  
## 5 Oceania          0.333
```

**Additional tips**

Also, check out window functions such as `cumsum()` and `lag()`. Window functions are a variant of aggregate functions that take a vector as input then return a vector of the same length as an output. 


```r
vec <- c(1:10)

# Typical aggregate function
sum(vec) # The output length is one
```

```
## [1] 55
```

```r
# Window function
cumsum(vec) # The output length is ten
```

```
##  [1]  1  3  6 10 15 21 28 36 45 55
```

```r
# Let's compare them side-by-side
compare(
  sum(vec),
  cumsum(vec)
)
```

```
## `old`: 55                         
## `new`:  1 3 6 10 15 21 28 36 45 55
```

### Joining

Relational data = multiple tables of data

![Relational data example](https://d33wubrfki0l68.cloudfront.net/245292d1ea724f6c3fd8a92063dcd7bfb9758d02/5751b/diagrams/relational-nycflights.png)

**Key ideas**

- A **primary key** "uniquely identifies an observation in its table"


```r
# Example
planes$tailnum %>% head()
```

```
## [1] "N10156" "N102UW" "N103US" "N104UW" "N10575" "N105UW"
```
Verify primary key

`tailnum` should be unique. 

**Challenge**

What do you expect the outcome?


```r
planes %>%
  count(tailnum) %>%
  filter(n > 1)
```

```
## # A tibble: 0 x 2
## # ... with 2 variables: tailnum <chr>, n <int>
```
**Optional**

If a dataframe doesn't have a primary key, you can add one called a **surrogate** key.


```r
# Toy example
df <- tibble(
  x = c(1:3),
  y = c(4:6)
)

# Add a row_index column
df <- df %>% rowid_to_column("ID")
```

- A **foreign** key "uniquely identifies an observation in another table."


```r
flights$tailnum %>% head()
```

```
## [1] "N14228" "N24211" "N619AA" "N804JB" "N668DN" "N39463"
```
For joining, don't be distracted by other details and focus on KEYS!

#### Mutating joins

> Add new variables to one data frame from matching observations in another"

Using a simple toy example is great because it is easy to see how things work in that much narrow context.

-   Toy example


```r
# Table 1
x <- tibble(
  key = c(1:4),
  val_x = c("x1", "x2", "x3", "x4")
)

# Table 2
y <- tibble(
  key = c(1:5),
  val_y = c("y1", "y2", "y3", "y4", "y5")
)
```

-   Inner Join

`inner_join()` keeps the matched values in both tables. If the left table is a subset of the right table, then `left_join()` is the same as `inner_join()`.

**Challenge**

What is going to be the shared keys?


```r
inner_join(x, y)
```

```
## Joining, by = "key"
```

```
## # A tibble: 4 x 3
##     key val_x val_y
##   <int> <chr> <chr>
## 1     1 x1    y1   
## 2     2 x2    y2   
## 3     3 x3    y3   
## 4     4 x4    y4
```

![Mutating joins](https://d33wubrfki0l68.cloudfront.net/aeab386461820b029b7e7606ccff1286f623bae1/ef0d4/diagrams/join-venn.png)

-   Left Join

`left_join()`, `right_join()` and `full_join()` are outer join functions. Unlike `inner_join()`, outer join functions keep observations that appear in at least one of the tables.

`left_join()` keeps only the matched observations in the right table.


```r
left_join(x, y)
```

```
## Joining, by = "key"
```

```
## # A tibble: 4 x 3
##     key val_x val_y
##   <int> <chr> <chr>
## 1     1 x1    y1   
## 2     2 x2    y2   
## 3     3 x3    y3   
## 4     4 x4    y4
```

-   Right Join

`right_join()` does the opposite. 


```r
right_join(x, y)
```

```
## Joining, by = "key"
```

```
## # A tibble: 5 x 3
##     key val_x val_y
##   <int> <chr> <chr>
## 1     1 x1    y1   
## 2     2 x2    y2   
## 3     3 x3    y3   
## 4     4 x4    y4   
## 5     5 <NA>  y5
```

-   Full Join

`full_join()` keeps the observations from both tables. If they were unmatched, then NAs were recoded in one of the two tables.


```r
full_join(x, y)
```

```
## Joining, by = "key"
```

```
## # A tibble: 5 x 3
##     key val_x val_y
##   <int> <chr> <chr>
## 1     1 x1    y1   
## 2     2 x2    y2   
## 3     3 x3    y3   
## 4     4 x4    y4   
## 5     5 <NA>  y5
```

#### Filtering joins

> Filter observations from one data frame based on whether they match an observation in the other table.

-   Semi Join

In SQL, this type of query is also called subqueries.

-   Filtering without joining


```r
# Create the list of the top 10 destinations
top_dest <- flights %>%
  count(dest, sort = TRUE) %>%
  top_n(10)
```

```
## Selecting by n
```

```r
# Filter
filtered <- flights %>%
  filter(dest %in% top_dest$dest)
```

-   Using semi join: only keep (INCLUDE) the rows that were matched between the two tables


```r
joined <- flights %>%
  semi_join(top_dest)
```

```
## Joining, by = "dest"
```

```r
head(filtered == joined)
```

```
##      year month  day dep_time sched_dep_time dep_delay arr_time sched_arr_time
## [1,] TRUE  TRUE TRUE     TRUE           TRUE      TRUE     TRUE           TRUE
## [2,] TRUE  TRUE TRUE     TRUE           TRUE      TRUE     TRUE           TRUE
## [3,] TRUE  TRUE TRUE     TRUE           TRUE      TRUE     TRUE           TRUE
## [4,] TRUE  TRUE TRUE     TRUE           TRUE      TRUE     TRUE           TRUE
## [5,] TRUE  TRUE TRUE     TRUE           TRUE      TRUE     TRUE           TRUE
## [6,] TRUE  TRUE TRUE     TRUE           TRUE      TRUE     TRUE           TRUE
##      arr_delay carrier flight tailnum origin dest air_time distance hour minute
## [1,]      TRUE    TRUE   TRUE    TRUE   TRUE TRUE     TRUE     TRUE TRUE   TRUE
## [2,]      TRUE    TRUE   TRUE    TRUE   TRUE TRUE     TRUE     TRUE TRUE   TRUE
## [3,]      TRUE    TRUE   TRUE    TRUE   TRUE TRUE     TRUE     TRUE TRUE   TRUE
## [4,]      TRUE    TRUE   TRUE    TRUE   TRUE TRUE     TRUE     TRUE TRUE   TRUE
## [5,]      TRUE    TRUE   TRUE    TRUE   TRUE TRUE     TRUE     TRUE TRUE   TRUE
## [6,]      TRUE    TRUE   TRUE    TRUE   TRUE TRUE     TRUE     TRUE TRUE   TRUE
##      time_hour
## [1,]      TRUE
## [2,]      TRUE
## [3,]      TRUE
## [4,]      TRUE
## [5,]      TRUE
## [6,]      TRUE
```

-   Anti Join

`anti_join()` does the opposite. Exclude the rows that were matched between the two tables. A great technique to filter stopwords when you do computational text analysis.


```r
flights %>%
  anti_join(planes, by = "tailnum") %>%
  count(tailnum, sort = TRUE)
```

```
## # A tibble: 722 x 2
##    tailnum     n
##    <chr>   <int>
##  1 <NA>     2512
##  2 N725MQ    575
##  3 N722MQ    513
##  4 N723MQ    507
##  5 N713MQ    483
##  6 N735MQ    396
##  7 N0EGMQ    371
##  8 N534MQ    364
##  9 N542MQ    363
## 10 N531MQ    349
## # ... with 712 more rows
```

## Modeling (broom)

### Nesting

#### nest

The following example comes from [R for Data Science](https://r4ds.had.co.nz/many-models.html) by Garrett Grolemund and Hadley Wickham.

-   How can you run multiple models simultaneously? Using a nested data frame.

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/rz3_FDVt9eg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p> Hadley Wickham: Managing many models with R </p>
```

-   **Grouped data: each row = an observation**

-   **Nested data: each row = a group**

**Challenge**

In the following example, why did we use `country` and `continent` for nesting variables?


```r
nested <- gapminder %>%
  group_by(country, continent) %>%
  nest()

head(nested)
```

```
## # A tibble: 6 x 3
## # Groups:   country, continent [6]
##   country     continent data             
##   <fct>       <fct>     <list>           
## 1 Afghanistan Asia      <tibble [12 x 4]>
## 2 Albania     Europe    <tibble [12 x 4]>
## 3 Algeria     Africa    <tibble [12 x 4]>
## 4 Angola      Africa    <tibble [12 x 4]>
## 5 Argentina   Americas  <tibble [12 x 4]>
## 6 Australia   Oceania   <tibble [12 x 4]>
```

```r
nested$data %>% pluck(1)
```

```
## # A tibble: 12 x 4
##     year lifeExp      pop gdpPercap
##    <int>   <dbl>    <int>     <dbl>
##  1  1952    28.8  8425333      779.
##  2  1957    30.3  9240934      821.
##  3  1962    32.0 10267083      853.
##  4  1967    34.0 11537966      836.
##  5  1972    36.1 13079460      740.
##  6  1977    38.4 14880372      786.
##  7  1982    39.9 12881816      978.
##  8  1987    40.8 13867957      852.
##  9  1992    41.7 16317921      649.
## 10  1997    41.8 22227415      635.
## 11  2002    42.1 25268405      727.
## 12  2007    43.8 31889923      975.
```

-   Custom function


```r
lm_model <- function(df) {
  lm(lifeExp ~ year, data = df)
}
```

-   Apply function to the nested data


```r
# Apply m_model to the nested data

nested <- nested %>%
  mutate(models = map(data, lm_model)) # Add the list object as a new column

head(nested)
```

```
## # A tibble: 6 x 4
## # Groups:   country, continent [6]
##   country     continent data              models
##   <fct>       <fct>     <list>            <list>
## 1 Afghanistan Asia      <tibble [12 x 4]> <lm>  
## 2 Albania     Europe    <tibble [12 x 4]> <lm>  
## 3 Algeria     Africa    <tibble [12 x 4]> <lm>  
## 4 Angola      Africa    <tibble [12 x 4]> <lm>  
## 5 Argentina   Americas  <tibble [12 x 4]> <lm>  
## 6 Australia   Oceania   <tibble [12 x 4]> <lm>
```

S3 is part of R's object-oriented systems. If you need further information, check out [this section](http://adv-r.had.co.nz/S3.html) in Hadley's Advanced R.

#### unnest

- glance() 

`glance()` function from `broom` package inspects the quality of a statistical model.

**Additional tips**

-   `broom::glance(model)`: for evaluating model quality and/or complexity
-   `broom::tidy(model)`: for extracting each coefficient in the model (the estimates + its variability)
-   `broom::augment(model, data)`: for getting extra values (residuals, and influence statistics). A convenient tool in case if you want to plot fitted values and raw data together. 

![Broom: Converting Statistical Models to Tidy Data Frames by David Robinson](https://www.youtube.com/watch?v=7VGPUBWGv6g&ab_channel=Work-Bench)


```r
glanced <- nested %>%
  mutate(glance = map(models, broom::glance))

# Pluck the first item on the list 
glanced$glance %>% pluck(1)
```

```
## # A tibble: 1 x 12
##   r.squared adj.r.squared sigma statistic      p.value    df logLik   AIC   BIC
##       <dbl>         <dbl> <dbl>     <dbl>        <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1     0.948         0.942  1.22      181. 0.0000000984     1  -18.3  42.7  44.1
## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>
```

```r
# Pull p.value 
glanced$glance %>% pluck(1) %>% pull(p.value)
```

```
##        value 
## 9.835213e-08
```

`unnest()` unpacks the list objects stored in the `glanced` column


```r
glanced %>%
  unnest(glance) %>%
  arrange(r.squared) 
```

```
## # A tibble: 142 x 16
## # Groups:   country, continent [142]
##    country    continent data      models r.squared adj.r.squared sigma statistic
##    <fct>      <fct>     <list>    <list>     <dbl>         <dbl> <dbl>     <dbl>
##  1 Rwanda     Africa    <tibble ~ <lm>      0.0172      -0.0811   6.56     0.175
##  2 Botswana   Africa    <tibble ~ <lm>      0.0340      -0.0626   6.11     0.352
##  3 Zimbabwe   Africa    <tibble ~ <lm>      0.0562      -0.0381   7.21     0.596
##  4 Zambia     Africa    <tibble ~ <lm>      0.0598      -0.0342   4.53     0.636
##  5 Swaziland  Africa    <tibble ~ <lm>      0.0682      -0.0250   6.64     0.732
##  6 Lesotho    Africa    <tibble ~ <lm>      0.0849      -0.00666  5.93     0.927
##  7 Cote d'Iv~ Africa    <tibble ~ <lm>      0.283        0.212    3.93     3.95 
##  8 South Afr~ Africa    <tibble ~ <lm>      0.312        0.244    4.74     4.54 
##  9 Uganda     Africa    <tibble ~ <lm>      0.342        0.276    3.19     5.20 
## 10 Congo, De~ Africa    <tibble ~ <lm>      0.348        0.283    2.43     5.34 
## # ... with 132 more rows, and 8 more variables: p.value <dbl>, df <dbl>,
## #   logLik <dbl>, AIC <dbl>, BIC <dbl>, deviance <dbl>, df.residual <int>,
## #   nobs <int>
```

```r
glanced %>%
  unnest(glance) %>%
  ggplot(aes(continent, r.squared)) +
  geom_jitter(width = 0.5)
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-167-1.pdf)<!-- --> 

- tidy() 


```r
nested <- gapminder %>%
  group_by(continent) %>%
  nest()

nested <- nested %>%
  mutate(models = map(data, ~lm(lifeExp ~ year + country, data = .))) 

tidied <- nested %>%
  mutate(tidied = map(models, broom::tidy))

model_out <- tidied %>%
  unnest(tidied) %>%
  mutate(term = str_replace(term, "country", "")) %>%
  select(continent, term, estimate, p.value) %>%
  mutate(p_threshold = ifelse(p.value < 0.05, 1, 0))

model_out %>% filter(p_threshold == 1) %>% pull(term) %>% unique()
```

```
##   [1] "(Intercept)"              "year"                    
##   [3] "Bahrain"                  "Bangladesh"              
##   [5] "Cambodia"                 "China"                   
##   [7] "Hong Kong, China"         "India"                   
##   [9] "Indonesia"                "Iran"                    
##  [11] "Iraq"                     "Israel"                  
##  [13] "Japan"                    "Jordan"                  
##  [15] "Korea, Dem. Rep."         "Korea, Rep."             
##  [17] "Kuwait"                   "Lebanon"                 
##  [19] "Malaysia"                 "Mongolia"                
##  [21] "Myanmar"                  "Nepal"                   
##  [23] "Oman"                     "Pakistan"                
##  [25] "Philippines"              "Saudi Arabia"            
##  [27] "Singapore"                "Sri Lanka"               
##  [29] "Syria"                    "Taiwan"                  
##  [31] "Thailand"                 "Vietnam"                 
##  [33] "West Bank and Gaza"       "Yemen, Rep."             
##  [35] "Austria"                  "Belgium"                 
##  [37] "Croatia"                  "Czech Republic"          
##  [39] "Denmark"                  "Finland"                 
##  [41] "France"                   "Germany"                 
##  [43] "Greece"                   "Iceland"                 
##  [45] "Ireland"                  "Italy"                   
##  [47] "Montenegro"               "Netherlands"             
##  [49] "Norway"                   "Poland"                  
##  [51] "Portugal"                 "Slovak Republic"         
##  [53] "Slovenia"                 "Spain"                   
##  [55] "Sweden"                   "Switzerland"             
##  [57] "Turkey"                   "United Kingdom"          
##  [59] "Angola"                   "Benin"                   
##  [61] "Botswana"                 "Burkina Faso"            
##  [63] "Burundi"                  "Cameroon"                
##  [65] "Central African Republic" "Chad"                    
##  [67] "Comoros"                  "Congo, Dem. Rep."        
##  [69] "Congo, Rep."              "Cote d'Ivoire"           
##  [71] "Djibouti"                 "Equatorial Guinea"       
##  [73] "Eritrea"                  "Ethiopia"                
##  [75] "Gabon"                    "Gambia"                  
##  [77] "Ghana"                    "Guinea"                  
##  [79] "Guinea-Bissau"            "Kenya"                   
##  [81] "Lesotho"                  "Liberia"                 
##  [83] "Madagascar"               "Malawi"                  
##  [85] "Mali"                     "Mauritania"              
##  [87] "Mauritius"                "Mozambique"              
##  [89] "Namibia"                  "Niger"                   
##  [91] "Nigeria"                  "Reunion"                 
##  [93] "Rwanda"                   "Senegal"                 
##  [95] "Sierra Leone"             "Somalia"                 
##  [97] "South Africa"             "Sudan"                   
##  [99] "Swaziland"                "Tanzania"                
## [101] "Togo"                     "Uganda"                  
## [103] "Zambia"                   "Zimbabwe"                
## [105] "Bolivia"                  "Brazil"                  
## [107] "Canada"                   "Colombia"                
## [109] "Dominican Republic"       "Ecuador"                 
## [111] "El Salvador"              "Guatemala"               
## [113] "Haiti"                    "Honduras"                
## [115] "Mexico"                   "Nicaragua"               
## [117] "Paraguay"                 "Peru"                    
## [119] "Puerto Rico"              "Trinidad and Tobago"     
## [121] "United States"            "Venezuela"               
## [123] "New Zealand"
```

```r
model_out %>% filter(p_threshold == 0) %>% pull(term) %>% unique()
```

```
##  [1] "Bosnia and Herzegovina" "Bulgaria"               "Hungary"               
##  [4] "Romania"                "Serbia"                 "Egypt"                 
##  [7] "Libya"                  "Morocco"                "Sao Tome and Principe" 
## [10] "Tunisia"                "Chile"                  "Costa Rica"            
## [13] "Cuba"                   "Jamaica"                "Panama"                
## [16] "Uruguay"
```


### Mapping

We tasted a little bit about how `map()` function works. Let's dig into it more in-depth as this family of functions is useful. For more information, see Rebecca Barter's excellent tutorial on the `purrr` package. In her words, this is "the tidyverse's answer to apply functions for iteration". `map()` function can take a vector (of any type), a list, and a dataframe for input.


```r
multiply <- function(x) {
  x * x
}

df <- list(
  first_obs = rnorm(7, 1, sd = 1),
  second_obs = rnorm(7, 2, sd = 2)
) # normal distribution
```

**Challenge**

Try `map_df(.x = df, .f = multiply)` and tell me what's the difference between the output you got and what you saw earlier.

If you want to know more about the power and joy of functional programming in R (e.g., `purrr::map()`), then please take ["How to Automate Repeated Things in R"](https://github.com/dlab-berkeley/R-functional-programming) workshop.

### Hypothesis testing 

Statistical inference: does the effect/difference in observed data occur by chance?

Null hypothesis: everything was random 
Alternative hypothesis: everything was not random. Note that this does not mean that a particular factor influenced the outcome of interest. Statistical inference != Causal inference (causes and effects)

$Y = X_{1} + X_{2} + X_{3} \epsilon$

[`infer`](https://github.com/tidymodels/infer) is for tidyverse-friendly statistical inference. 

**Workflow**

1. `specify()` specify a formula 
2. `hypothesize()` declare the null hypothesis 
3. `generate()` generate data based on the null hypothesis 
4. `calculate()` calculate a distribution of statistics from the generated data to form the null distribution 


![From infer package](https://raw.githubusercontent.com/tidymodels/infer/master/figs/ht-diagram.png)


```r
gapminder <- gapminder %>%
  mutate(log_pop = log(pop))

ggplot(aes(x = log_pop, y = lifeExp), data = gapminder) +
  geom_point() +
  geom_smooth(method = "lm")
```

```
## `geom_smooth()` using formula 'y ~ x'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-170-1.pdf)<!-- --> 

```r
# Calculate the observed statistic: Observed slopes 
observed_slopes <- gapminder %>%
  # specify(formula = lifeExp ~ log_pop) %>% 
  specify(formula = lifeExp ~ log_pop) %>%
  calculate(stat = "slope")

# Generate the null distribution: Null slopes 
null_slopes <- gapminder %>%
  # Specify a formula
  specify(formula = lifeExp ~ log_pop) %>%
  # Hypothesize (point estimation)
  hypothesize(null = "point", mu = 0) %>%
  # Generate sampling distributions (bootstrapping)
  generate(reps = 1000, type = "bootstrap") %>%
  # Calculate statistics 
  calculate(stat = "slope") 

# Return data 
null_slopes %>%
  # p-value is just the probability that observed pattern could arise if the null hypothesis was true 
  # In social science convention, if alpha is below 0.005 (note: this is totally arbitrary), then the observed distribution is statistically significant.
  get_p_value(obs_stat = observed_slopes, 
              direction = "both")
```

```
## # A tibble: 1 x 1
##   p_value
##     <dbl>
## 1   0.972
```

```r
# Visualize output 
visualize(null_slopes) +
  shade_p_value(obs_stat = observed_slopes, 
                direction = "both")
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-170-2.pdf)<!-- --> 

### Mixed models 

This part heavily draws on [Gelman and Hill](http://www.stat.columbia.edu/~gelman/arm/) (2007), Michael Clark's [Mixed Models with R](https://m-clark.github.io/mixed-models-with-R/), and Basel R Bootcamp's [Statistics with R: Mixed Models](https://therbootcamp.github.io/SwR_2019Apr/_sessions/MixedModels/MixedModels_practical.html). For a quick review on mixed models, I recommend Xavier et al.'s ["A brief introduction to mixed effects modelling and multi-model inference in ecology"](https://peerj.com/articles/4794/) (2018).

Why random effects model/mixed effects model?

Fixed effects model assumes that groups are independent of each other and sharing common residuals (same slope for fitted covariates). Limiting to a common slope can inflate Type I and Type II errors.  


```r
pacman::p_load(# Necessary  
               lme4, 
               broom.mixed, 
               # Optional 
               merTools,
               glmmTMB, 
               modelr, 
               nlme, 
               sjstats)
```


```r
# Base LM model 
lm_out <- lm(lifeExp ~ pop + continent, 
             data = gapminder)

# Mixed effects 
re_out <- lmer(lifeExp ~ pop + # Fixed effects
                # Random effects 
                # (design matrix|group_variables)
                # (1|group_var) = random intercept 
                # (1 + var | group_var) = random slope + random intercept 
               (1|continent),
               data = gapminder, # Data 
               REML = FALSE) # Default computation engine is restricted maximal likelihood; the other option is maximum likelihood estimation 
```

```
## Warning: Some predictor variables are on very different scales: consider
## rescaling
```

```r
#re_out2 <- lmer(lifeExp ~ pop + # Fixed effects
                # Random effects 
                # (design matrix|group_variables)
                # (1|group_var) = random intercept 
                # (1 + var | group_var) = random slope + random intercept 
 #              (country|continent),
  #             data = gapminder, # Data 
   #            REML = FALSE) # Default computation engine is restricted maximal likelihood; the other option is maximum likelihood estimation 

summary(re_out)
```

```
## Linear mixed model fit by maximum likelihood  ['lmerMod']
## Formula: lifeExp ~ pop + (1 | continent)
##    Data: gapminder
## 
##      AIC      BIC   logLik deviance df.resid 
##  12441.4  12463.1  -6216.7  12433.4     1700 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.3584 -0.5915  0.0344  0.6585  2.9926 
## 
## Random effects:
##  Groups    Name        Variance Std.Dev.
##  continent (Intercept) 82.02    9.056   
##  Residual              85.01    9.220   
## Number of obs: 1704, groups:  continent, 5
## 
## Fixed effects:
##              Estimate Std. Error t value
## (Intercept) 6.375e+01  4.072e+00  15.658
## pop         4.504e-09  2.174e-09   2.072
## 
## Correlation of Fixed Effects:
##     (Intr)
## pop -0.015
## fit warnings:
## Some predictor variables are on very different scales: consider rescaling
```

```r
nlme::fixef(re_out) %>% as_tibble()
```

```
## # A tibble: 2 x 1
##     value
##     <dbl>
## 1 6.38e+1
## 2 4.50e-9
```

```r
nlme::ranef(re_out) %>% as_tibble()
```

```
## # A tibble: 5 x 5
##   grpvar    term        grp      condval condsd
##   <chr>     <fct>       <fct>      <dbl>  <dbl>
## 1 continent (Intercept) Africa   -14.9    0.369
## 2 continent (Intercept) Americas   0.791  0.531
## 3 continent (Intercept) Asia      -4.03   0.463
## 4 continent (Intercept) Europe     8.05   0.485
## 5 continent (Intercept) Oceania   10.1    1.84
```

```r
lm_out %>% 
  broom::tidy() %>%
  filter(term == "pop") %>%
  pull(estimate)
```

```
## [1] 4.515688e-09
```

```r
re_out %>%
  broom.mixed::tidy() %>%
  filter(term == "pop") %>%
  pull(estimate)
```

```
## [1] 4.503537e-09
```

### Design Anaysis (optional)

DeclareDesign provides a collection of packages (`fabricatr`, `randomizr`, `estimatr`) that are very useful for those interested in testing the strength of research design. DeclareDesign also helps share your research design along with your code and data. 


```r
pacman::p_load(DeclareDesign, #  
               fabricatr, # Fabricate mock (fake) data  
               randomizr, # Random sampling and assignment 
               estimatr, # Fast estimation tools (IV, etc) 
               DesignLibrary) # Research design library 
```

Model-Inquire-Data Strategy-Answer Strategy (MIDA) by Graeme Blair, Jasper Cooper, Alex Coppock, and Macartan Humphreys ([APSR 2019](https://declaredesign.org/declare.pdf)). The following instructions draw on the vignette available at [the package homepage](https://declaredesign.org/mida/). Also, take a look at [DeclareDesign cheatsheet](https://github.com/rstudio/cheatsheets/blob/master/declaredesign.pdf).

1. Setup 

* Model: speculation of how the world works (variables plus their relationships)


```r
population <- declare_population(N = 1000, 
                                 noise = rnorm(N))

population # class 
```

```
## declare_population(N = 1000, noise = rnorm(N))
```

```r
population() %>% head() # instance 
```

```
##     ID      noise
## 1 0001  0.5952464
## 2 0002  0.5847477
## 3 0003  0.9645900
## 4 0004  0.3194326
## 5 0005 -1.2011572
## 6 0006 -1.7892308
```



```r
# Note that Y_Z_0 and Y_Z_1 are argument names. 
potential_outcomes <- declare_potential_outcomes(Y_Z_0 = 0, # Control group 
                                                 Y_Z_1 = 1 + noise) # Treatment group 
```

* Inquiry: a description of the distributions of the variables (estimand = something we desire to know)

You can add other estimators such as Conditional Average Treatment Effect (CATE).


```r
estimand_ate <- declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0))
```

```
## Warning: 'declare_estimand' is deprecated.
## Use 'declare_inquiry' instead.
## See help("Deprecated")
```

* Data strategy: a description of sampling (or case selection) + intervention strategy  


```r
sampling <- declare_sampling(n = 250, legacy = TRUE) # Sampling 250 units 
assignment <- declare_assignment(m = 50, legacy = TRUE) # Assign 50 units 

# If you don't do this, you will be missing Y 
reveal_Y <- declare_reveal(Y, Z)
```

* Answer strategy: a description of how to use data to answer a question 


```r
estimator_ate <- declare_estimator(Y ~ Z, 
                                   estimand = estimand_ate,
                                   model = difference_in_means)
```

* Design 


```r
design <- population + potential_outcomes + estimand_ate + sampling + assignment + reveal_Y + estimator_ate

# This should work. Otherwise, something is wrong with your code.
design
```

```
## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.
```

```
## 
## Design Summary
## 
## Step 1 (population): declare_population(N = 1000, noise = rnorm(N)) ------------
## 
## N = 1000 
## 
## Added variable: ID 
##  N_missing N_unique     class
##          0     1000 character
## 
## Added variable: noise 
##    min median  mean  max   sd N_missing N_unique
##  -3.85  -0.07 -0.04 3.36 1.02         0     1000
## 
## Step 2 (potential outcomes): declare_potential_outcomes(Y_Z_0 = 0, Y_Z_1 = 1 + noise) 
## 
## Added variable: Y_Z_0 
##     0
##  1000
##  1.00
## 
## Added variable: Y_Z_1 
##    min median mean  max   sd N_missing N_unique
##  -2.85   0.93 0.96 4.36 1.02         0     1000
## 
## Step 3 (inquiry): declare_inquiry(ATE = ..1) -----------------------------------
## 
## A single draw of the inquiry:
##  inquiry  estimand
##      ATE 0.9600409
## 
## Step 4 (sampling): declare_sampling(n = 250, legacy = TRUE) --------------------
## 
## N = 250 (750 subtracted) 
## 
## Added variable: S_inclusion_prob 
##  0.25
##   250
##  1.00
## 
## Altered variable: ID 
##   Before: 
##  N_missing N_unique     class
##          0     1000 character
## 
##   After:
##  N_missing N_unique     class
##          0      250 character
## 
## Altered variable: noise 
##   Before: 
##    min median  mean  max   sd N_missing N_unique
##  -3.85  -0.07 -0.04 3.36 1.02         0     1000
## 
##   After:
##   min median  mean  max   sd N_missing N_unique
##  -3.6  -0.08 -0.03 2.83 1.06         0      250
## 
## Altered variable: Y_Z_0 
##   Before: 
##     0
##  1000
##  1.00
## 
##   After:
##     0
##   250
##  1.00
## 
## Altered variable: Y_Z_1 
##   Before: 
##    min median mean  max   sd N_missing N_unique
##  -2.85   0.93 0.96 4.36 1.02         0     1000
## 
##   After:
##   min median mean  max   sd N_missing N_unique
##  -2.6   0.92 0.97 3.83 1.06         0      250
## 
## Step 5 (assignment): declare_assignment(m = 50, legacy = TRUE) -----------------
## 
## Added variable: Z 
##     0    1
##   200   50
##  0.80 0.20
## 
## Added variable: Z_cond_prob 
##   0.2  0.8
##    50  200
##  0.20 0.80
## 
## Step 6 (reveal): declare_reveal(Y, Z) ------------------------------------------
## 
## Added variable: Y 
##    min median mean  max   sd N_missing N_unique
##  -1.44      0  0.2 3.08 0.59         0       51
## 
## Step 7 (estimator): declare_estimator(Y ~ Z, estimand = estimand_ate, model = difference_in_means) 
## 
## Formula: Y ~ Z 
## 
## Model:	difference_in_means 
## 
## A single draw of the estimator:
##  estimator term estimate std.error statistic      p.value  conf.low conf.high
##  estimator    Z 1.010462 0.1370808  7.371286 1.768003e-09 0.7349878  1.285936
##  df outcome inquiry
##  49       Y     ATE
```

2. Applications 

* Simulating data 


```r
fake_data <- draw_data(design)

head(fake_data)
```

```
##     ID      noise Y_Z_0      Y_Z_1 S_inclusion_prob Z Z_cond_prob          Y
## 1 0001 -0.2533829     0  0.7466171             0.25 1         0.2  0.7466171
## 2 0002  1.2077610     0  2.2077610             0.25 0         0.8  0.0000000
## 3 0009 -0.5574354     0  0.4425646             0.25 0         0.8  0.0000000
## 4 0010  1.2574286     0  2.2574286             0.25 1         0.2  2.2574286
## 5 0011 -0.5511836     0  0.4488164             0.25 0         0.8  0.0000000
## 6 0016 -1.1025132     0 -0.1025132             0.25 1         0.2 -0.1025132
```

* Estimation 


```r
estimates <- draw_estimates(design)
```

```
## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.
```

```r
estimates
```

```
##   estimator term estimate std.error statistic      p.value  conf.low conf.high
## 1 estimator    Z 1.194527 0.1361679   8.77246 1.290575e-11 0.9208878  1.468167
##   df outcome inquiry
## 1 49       Y     ATE
```

* Diagnosis 

Diagnosis is made using a Monte Carlo approach (=simulating many times using bootstrapped samples).


```r
diagnosis <- diagnose_design(design, 
                             sims = 1000, 
                             bootstrap_sims = 500)
```

```
## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.

## Warning: The argument 'estimand = ' is deprecated. Please use 'inquiry = '
## instead.
```

```r
diagnosis
```

```
## 
## Research design diagnosis based on 1000 simulations. Diagnosand estimates with bootstrapped standard errors in parentheses (500 replicates).
## 
##  Design Inquiry Estimator Term N Sims   Bias   RMSE  Power Coverage
##  design     ATE estimator    Z   1000  -0.00   0.13   1.00     0.96
##                                       (0.00) (0.00) (0.00)   (0.01)
##  Mean Estimate SD Estimate Mean Se Type S Rate Mean Estimand
##           1.00        0.14    0.14        0.00          1.00
##         (0.00)      (0.00)  (0.00)      (0.00)        (0.00)
```

```r
# Very weakly biased 
# Well powered. Power = 1 - Type II error (False Negative Rate). Therefore, higher statistical power means a lower false-negative rate. 
# Coverage (standard errors) is fine. 95% of the time right answers lie in the coverage. 
```

* Shortcuts 

Doing the power analysis for a three-arm experiment.


```r
three_arm <- multi_arm_designer(N = 1000, m = 3, 
                   outcome_means = c(0, 0.1, 0.2))

diagnose_design(three_arm)
```

```
## 
## Research design diagnosis based on 500 simulations. Diagnosand estimates with bootstrapped standard errors in parentheses (100 replicates).
## 
##     Design   Inquiry       Estimator N Sims   Bias   RMSE  Power Coverage
##  three_arm ate_Y_2_1 DIM (Z_2 - Z_1)    500   0.00   0.07   0.26     0.97
##                                             (0.00) (0.00) (0.02)   (0.01)
##  three_arm ate_Y_3_1 DIM (Z_3 - Z_1)    500   0.00   0.07   0.75     0.96
##                                             (0.00) (0.00) (0.02)   (0.01)
##  three_arm ate_Y_3_2 DIM (Z_3 - Z_2)    500   0.00   0.08   0.26     0.96
##                                             (0.00) (0.00) (0.02)   (0.01)
##  Mean Estimate SD Estimate Mean Se Type S Rate Mean Estimand
##           0.10        0.07    0.08        0.00          0.10
##         (0.00)      (0.00)  (0.00)      (0.00)        (0.00)
##           0.20        0.07    0.08        0.00          0.20
##         (0.00)      (0.00)  (0.00)      (0.00)        (0.00)
##           0.10        0.08    0.08        0.00          0.10
##         (0.00)      (0.00)  (0.00)      (0.00)        (0.00)
```

**Additional tips**

Experimenters! Consider writing and registering a pre-analysis before running your experiment. Here are tools that can help to create a pre-registration so easily. The following information comes from David Broockman's [very helpful Twitter thread](https://twitter.com/dbroockman/status/1350897814499336192). 

1. Write code using fake data. If you are using , you can generate test responses using the platform: https://www.qualtrics.com/support/survey-platform/survey-module/survey-tools/generating-test-responses/

2. Register the pre-analysis using [ASPREDICTED](https://aspredicted.org/), "a platform that makes it easy for researchers to pre-register their studies, and easy for others to read and evaluate those pre-registrations." It creates an anonymized PDF file filled with the answers you provided and a blinded link.  

3. Upload the anonymized code and the PDF to a new project in [osf.io](https://osf.io/) and describe your pre-analysis briefly. 

## Visualizing (ggplot2)

- The following material is adapted from Kieran Healy's excellent book (2019) on [data visualization](https://socviz.co/) and Hadley Wickham's equally excellent book on [ggplot2](https://ggplot2-book.org/). For more theoretical discussions, I recommend you to read [The Grammar of Graphics](https://link.springer.com/book/10.1007%2F0-387-28695-0) by Leland Wilkinson.

- Why should we care about data visualization? More precisely, why should we learn the grammar of statistical graphics?
- Sometimes, pictures are better tools than words in 1) exploring, 2) understanding, and 3) explaining data.

### Motivation 

[Anscombe](https://en.wikipedia.org/wiki/Frank_Anscombe)'s quarter comprises four datasets, which are so alike in terms of their descriptive statistics but quite different when presented graphically.


```r
# Set theme
theme_set(theme_minimal())
```


```r
# Data
anscombe
```

```
##    x1 x2 x3 x4    y1   y2    y3    y4
## 1  10 10 10  8  8.04 9.14  7.46  6.58
## 2   8  8  8  8  6.95 8.14  6.77  5.76
## 3  13 13 13  8  7.58 8.74 12.74  7.71
## 4   9  9  9  8  8.81 8.77  7.11  8.84
## 5  11 11 11  8  8.33 9.26  7.81  8.47
## 6  14 14 14  8  9.96 8.10  8.84  7.04
## 7   6  6  6  8  7.24 6.13  6.08  5.25
## 8   4  4  4 19  4.26 3.10  5.39 12.50
## 9  12 12 12  8 10.84 9.13  8.15  5.56
## 10  7  7  7  8  4.82 7.26  6.42  7.91
## 11  5  5  5  8  5.68 4.74  5.73  6.89
```


```r
# Correlation
cor(anscombe)[c(1:4), c(5:8)]
```

```
##            y1         y2         y3         y4
## x1  0.8164205  0.8162365  0.8162867 -0.3140467
## x2  0.8164205  0.8162365  0.8162867 -0.3140467
## x3  0.8164205  0.8162365  0.8162867 -0.3140467
## x4 -0.5290927 -0.7184365 -0.3446610  0.8165214
```


```r
# gather and select
anscombe_processed <- anscombe %>%
  gather(x_name, x_value, x1:x4) %>%
  gather(y_name, y_value, y1:y4)

# plot
anscombe_processed %>%
  ggplot(aes(x = x_value, y = y_value)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  facet_grid(x_name ~ y_name) +
  theme_bw() +
  labs(
    x = "X values",
    y = "Y values",
    title = "Anscombe's quartet"
  )
```

```
## `geom_smooth()` using formula 'y ~ x'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-187-1.pdf)<!-- --> 

### The grammar of graphics 

- the grammar of graphics 

    - data
    - aesthetic attributes (color, shape, size)
    - geometric objects (points, lines, bars)
    - stats (summary stats)
    - scales (map values in the data space)
    - coord (data coordinates)
    - facet (facetting specifications)
    
No worries about new terms. We're going to learn them by actually plotting. 

- Workflow: 

    1. Tidy data 
    2. Mapping 
    3. Geom 
    4. Cor_ordinates and scales 
    5. Labels and guides
    6. Themes
    7. Save files 

### mapping and geom

- `aes` (aesthetic mappings or aesthetics) tells which variables (x, y) in your data should be represented by which visual elements (color, shape, size) in the plot.

- `geom_` tells the type of plot you are going to use 

### basic aes (x , y)


```r
p <- ggplot(
  data = gapminder,
  mapping = aes(x = gdpPercap, y = lifeExp)
) # ggplot or R in general takes positional arguments too. So, you don't need to name data, mapping each time you use ggplot2.

p
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-188-1.pdf)<!-- --> 

```r
p + geom_point()
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-188-2.pdf)<!-- --> 

```r
p + geom_point() + geom_smooth() # geom_smooth has calculated a smoothed line;
```

```
## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-188-3.pdf)<!-- --> 

```r
# the shaded area is the standard error for the line
```

### Univariate distribution

- `geom_histogram()`: For the probability distribution of a continuous variable. Bins divide the entire range of values into a series of intervals (see [the Wiki entry](https://en.wikipedia.org/wiki/Histogram)). 
- `geom_density()`: Also for the probability distribution of a continuous variable. It calculates a [kernel density estimate](https://en.wikipedia.org/wiki/Kernel_density_estimation) of the underlying distribution. 

#### Histogram 


```r
data(midwest) # load midwest dataset

midwest
```

```
## # A tibble: 437 x 28
##      PID county  state  area poptotal popdensity popwhite popblack popamerindian
##    <int> <chr>   <chr> <dbl>    <int>      <dbl>    <int>    <int>         <int>
##  1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98
##  2   562 ALEXAN~ IL    0.014    10626       759      7054     3496            19
##  3   563 BOND    IL    0.022    14991       681.    14477      429            35
##  4   564 BOONE   IL    0.017    30806      1812.    29344      127            46
##  5   565 BROWN   IL    0.018     5836       324.     5264      547            14
##  6   566 BUREAU  IL    0.05     35688       714.    35157       50            65
##  7   567 CALHOUN IL    0.017     5322       313.     5298        1             8
##  8   568 CARROLL IL    0.027    16805       622.    16519      111            30
##  9   569 CASS    IL    0.024    13437       560.    13384       16             8
## 10   570 CHAMPA~ IL    0.058   173025      2983.   146506    16559           331
## # ... with 427 more rows, and 19 more variables: popasian <int>,
## #   popother <int>, percwhite <dbl>, percblack <dbl>, percamerindan <dbl>,
## #   percasian <dbl>, percother <dbl>, popadults <int>, perchsd <dbl>,
## #   percollege <dbl>, percprof <dbl>, poppovertyknown <int>,
## #   percpovertyknown <dbl>, percbelowpoverty <dbl>, percchildbelowpovert <dbl>,
## #   percadultpoverty <dbl>, percelderlypoverty <dbl>, inmetro <int>,
## #   category <chr>
```


```r
midwest %>%
  ggplot(aes(x = area)) +
  geom_point() # not working.
```


```r
midwest %>%
  ggplot(aes(x = area)) +
  geom_histogram() # stat_bin argument picks up 30 bins (or "bucket") by default.
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-191-1.pdf)<!-- --> 

```r
midwest %>%
  ggplot(aes(x = area)) +
  geom_histogram(bins = 10) # only 10 bins.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-191-2.pdf)<!-- --> 

```r
ggplot(
  data = subset(midwest, state %in% c("OH", "IN")),
  mapping = aes(x = percollege, fill = state)
) +
  geom_histogram(alpha = 0.7, bins = 20) +
  scale_fill_viridis_d()
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-191-3.pdf)<!-- --> 

#### Density 


```r
midwest %>%
  ggplot(aes(x = area, fill = state, color = state)) +
  geom_density(alpha = 0.3) +
  scale_color_viridis_d() +
  scale_fill_viridis_d()
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-192-1.pdf)<!-- --> 

### Advanced aes (size, color)

- There's also `fill` argument (mostly used in `geom_bar()`). Color `aes` affects the appearance of lines and points, fill is for the filled areas of bars, polygons, and in some cases, the interior of a smoother's standard error ribbon.

- The property size/color/fill represents... 


```r
ggplot(
  data = gapminder,
  mapping = aes(
    x = gdpPercap, y = lifeExp,
    size = pop
  )
) +
  geom_point()
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-193-1.pdf)<!-- --> 


```r
ggplot(
  data = gapminder,
  mapping = aes(
    x = gdpPercap, y = lifeExp,
    size = pop,
    color = continent
  )
) +
  geom_point() +
  scale_color_viridis_d()
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-194-1.pdf)<!-- --> 


```r
# try red instead of "red"
ggplot(
  data = gapminder,
  mapping = aes(
    x = gdpPercap, y = lifeExp,
    size = pop,
    color = "red"
  )
) +
  geom_point()
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-195-1.pdf)<!-- --> 

Aesthetics also can be mapped per Geom. 


```r
p + geom_point() +
  geom_smooth()
```

```
## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-196-1.pdf)<!-- --> 

```r
p + geom_point(alpha = 0.3) + # alpha controls transparency
  geom_smooth(color = "red", se = FALSE, size = 2)
```

```
## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-196-2.pdf)<!-- --> 

```r
p + geom_point(alpha = 0.3) + # alpha controls transparency
  geom_smooth(color = "red", se = FALSE, size = 2, method = "lm")
```

```
## `geom_smooth()` using formula 'y ~ x'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-196-3.pdf)<!-- --> 


```r
ggplot(
  data = gapminder,
  mapping = aes(
    x = gdpPercap, y = lifeExp,
    color = continent
  )
) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "red") +
  labs(
    x = "log GDP",
    y = "Life Expectancy",
    title = "A Gapminder Plot",
    subtitle = "Data points are country-years",
    caption = "Source: Gapminder"
  )
```

```
## `geom_smooth()` using formula 'y ~ x'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-197-1.pdf)<!-- --> 

```r
ggplot(
  data = gapminder,
  mapping = aes(
    x = gdpPercap, y = lifeExp,
    color = continent,
    fill = continent
  )
) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "red") +
  labs(
    x = "log GDP",
    y = "Life Expectancy",
    title = "A Gapminder Plot",
    subtitle = "Data points are country-years",
    caption = "Source: Gapminder"
  ) +
  scale_color_viridis_d() +
  scale_fill_viridis_d()
```

```
## `geom_smooth()` using formula 'y ~ x'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-197-2.pdf)<!-- --> 

### Co-ordinates and scales 


```r
p + geom_point() +
  coord_flip() # coord_type
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-198-1.pdf)<!-- --> 

The data is heavily bunched up against the left side. 

```r
p + geom_point() # without scaling
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-199-1.pdf)<!-- --> 

```r
p + geom_point() +
  scale_x_log10() # scales the axis of a plot to a log 10 basis
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-199-2.pdf)<!-- --> 

```r
p + geom_point() +
  geom_smooth(method = "lm") +
  scale_x_log10()
```

```
## `geom_smooth()` using formula 'y ~ x'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-199-3.pdf)<!-- --> 


### Labels and guides 

`scales` package has some useful premade formatting functions. You can either load scales or just grab the function you need from the library using `scales::` 


```r
p + geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "red") +
  scale_x_log10(labels = scales::dollar) +
  labs(
    x = "log GDP",
    y = "Life Expectancy",
    title = "A Gapminder Plot",
    subtitle = "Data points are country-years",
    caption = "Source: Gapminder"
  )
```

```
## `geom_smooth()` using formula 'y ~ x'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-200-1.pdf)<!-- --> 

6. Themes

```r
p + geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "red") +
  scale_x_log10(labels = scales::dollar) +
  labs(
    x = "log GDP",
    y = "Life Expectancy",
    title = "A Gapminder Plot",
    subtitle = "Data points are country-years",
    caption = "Source: Gapminder"
  ) +
  theme_economist()
```

```
## `geom_smooth()` using formula 'y ~ x'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-201-1.pdf)<!-- --> 

### ggsave 


```r
figure_example <- p + geom_point(alpha = 0.3) +
  geom_smooth(method = "gam", color = "red") +
  scale_x_log10(labels = scales::dollar) +
  labs(
    x = "log GDP",
    y = "Life Expectancy",
    title = "A Gapminder Plot",
    subtitle = "Data points are country-years",
    caption = "Source: Gapminder"
  ) +
  theme_economist()

ggsave(figure_example, here("outputs", "figure_example.png"))
```

### Many plots 

Basic ideas:

- Grouping: tell `ggplot2` about the structure of your data 
- Facetting: break up your data into pieces for a plot 

#### Grouping

- Can you guess what's wrong?


```r
p <- ggplot(gapminder, aes(x = year, y = gdpPercap))

p + geom_point()
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-203-1.pdf)<!-- --> 

```r
p + geom_line()
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-203-2.pdf)<!-- --> 

`geom_line` joins up all the lines for each particular year in the order they appear in the dataset. `ggplot2` does not know the yearly observations in your data are grouped by country. 

Note that you need grouping when the grouping information you need to tell is not built into the mapped variables (like continent).


```r
gapminder
```

```
## # A tibble: 1,704 x 7
##    country     continent  year lifeExp      pop gdpPercap log_pop
##    <fct>       <fct>     <int>   <dbl>    <int>     <dbl>   <dbl>
##  1 Afghanistan Asia       1952    28.8  8425333      779.    15.9
##  2 Afghanistan Asia       1957    30.3  9240934      821.    16.0
##  3 Afghanistan Asia       1962    32.0 10267083      853.    16.1
##  4 Afghanistan Asia       1967    34.0 11537966      836.    16.3
##  5 Afghanistan Asia       1972    36.1 13079460      740.    16.4
##  6 Afghanistan Asia       1977    38.4 14880372      786.    16.5
##  7 Afghanistan Asia       1982    39.9 12881816      978.    16.4
##  8 Afghanistan Asia       1987    40.8 13867957      852.    16.4
##  9 Afghanistan Asia       1992    41.7 16317921      649.    16.6
## 10 Afghanistan Asia       1997    41.8 22227415      635.    16.9
## # ... with 1,694 more rows
```

#### Facetting 

Facetting is to make small multiples. 

- `facet_wrap`: based on a single categorical variable like `facet_wrap(~single_categorical_variable)`. Your panels will be laid out in order and then wrapped into a grid.

- `facet_grid`: when you want to cross-classify some data by two categorical variables like `facet_grid(one_cat_variable ~ two_cat_variable)`. 


```r
p <- ggplot(gapminder, aes(x = year, y = gdpPercap))

p + geom_line(aes(group = country)) # group by, # The outlier is Kuwait.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-205-1.pdf)<!-- --> 

```r
p + geom_line(aes(group = country)) + facet_wrap(~continent) # facetting
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-205-2.pdf)<!-- --> 

```r
p + geom_line(aes(group = country), color = "gray70") +
  geom_smooth(size = 1.1, method = "loess", se = FALSE) +
  scale_y_log10(labels = scales::dollar) +
  facet_wrap(~continent, ncol = 5) + # for single categorical variable; for multiple categorical variables use facet_grid()
  labs(
    x = "Year",
    y = "GDP per capita",
    title = "GDP per capita on Five continents"
  ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```
## `geom_smooth()` using formula 'y ~ x'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-205-3.pdf)<!-- --> 


```r
p + geom_line(aes(group = country), color = "gray70") +
  geom_smooth(size = 1.1, method = "loess", se = FALSE) +
  scale_y_log10(labels = scales::dollar) +
  facet_grid(~continent) + # for single categorical variable; for multiple categorical variables use facet_grid()
  labs(
    x = "Year",
    y = "GDP per capita",
    title = "GDP per capita on Five continents"
  ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```
## `geom_smooth()` using formula 'y ~ x'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-206-1.pdf)<!-- --> 


### Transforming

- Transforming: perform some calculations on or summarize your data before producing the plot 

#### Use pipes to summarize data

Also, we experiment bar charts here. By default, `geom_bar` [uses](https://www.rdocumentation.org/packages/ggplot2/versions/1.0.1/topics/geom_bar) stat = "bins", which makes the height of each bar equal to the number of cases in each group. If you have a y column, then you should use `stat = "identity"` argument. Alternatively, you can use `geom_col()`.


```r
gapminder_formatted <- gapminder %>%
  group_by(continent, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  )
```

```
## `summarise()` has grouped output by 'continent'. You can override using the `.groups` argument.
```

```r
ggplot(data = gapminder_formatted, aes(x = year, y = lifeExp_mean, color = continent)) +
  geom_point() +
  labs(
    x = "Year",
    y = "Life expectancy",
    title = "Life expectancy on Five continents"
  )
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-207-1.pdf)<!-- --> 

```r
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = year, y = lifeExp_mean, color = country)) +
  geom_point() +
  labs(
    x = "Year",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  )
```

```
## `summarise()` has grouped output by 'country'. You can override using the `.groups` argument.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-207-2.pdf)<!-- --> 


```r
# geom point
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = year, y = lifeExp_mean)) +
  geom_point() +
  labs(
    x = "Year",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  ) +
  facet_wrap(~country)
```

```
## `summarise()` has grouped output by 'country'. You can override using the `.groups` argument.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-208-1.pdf)<!-- --> 

```r
# geom bar
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = year, y = lifeExp_mean)) +
  geom_bar(stat = "identity") +
  labs(
    x = "Year",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  ) +
  facet_wrap(~country)
```

```
## `summarise()` has grouped output by 'country'. You can override using the `.groups` argument.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-208-2.pdf)<!-- --> 

```r
# no facet
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = year, y = lifeExp_mean, fill = country)) +
  geom_bar(stat = "identity") + # even if you not stack, still the plot looks messy or you can use geom_col()
  labs(
    x = "Year",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  )
```

```
## `summarise()` has grouped output by 'country'. You can override using the `.groups` argument.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-208-3.pdf)<!-- --> 


```r
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = country, y = lifeExp_mean)) +
  geom_boxplot() +
  labs(
    x = "Country",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  ) +
  coord_flip()
```

```
## `summarise()` has grouped output by 'country'. You can override using the `.groups` argument.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-209-1.pdf)<!-- --> 


```r
# without ordering
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = reorder(country, lifeExp_mean), y = lifeExp_mean)) +
  geom_boxplot() +
  labs(
    x = "Country",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  ) +
  coord_flip()
```

```
## `summarise()` has grouped output by 'country'. You can override using the `.groups` argument.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-210-1.pdf)<!-- --> 

```r
# reorder
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = reorder(country, -lifeExp_mean), y = lifeExp_mean)) +
  geom_boxplot() +
  labs(
    x = "Country",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  ) +
  coord_flip()
```

```
## `summarise()` has grouped output by 'country'. You can override using the `.groups` argument.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-210-2.pdf)<!-- --> 

#### Plotting text


```r
gapminder %>%
  filter(continent == "Asia" | continent == "Americas") %>%
  group_by(continent, country) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = gdp_mean, y = lifeExp_mean)) +
  geom_point() +
  geom_text(aes(label = country)) +
  scale_x_log10() +
  facet_grid(~continent)
```

```
## `summarise()` has grouped output by 'continent'. You can override using the `.groups` argument.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-211-1.pdf)<!-- --> 


```r
# with label
gapminder %>%
  filter(continent == "Asia" | continent == "Americas") %>%
  group_by(continent, country) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = gdp_mean, y = lifeExp_mean)) +
  geom_point() +
  geom_label(aes(label = country)) +
  scale_x_log10() +
  facet_grid(~continent)
```

```
## `summarise()` has grouped output by 'continent'. You can override using the `.groups` argument.
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-212-1.pdf)<!-- --> 


```r
# no overlaps
gapminder %>%
  filter(continent == "Asia" | continent == "Americas") %>%
  group_by(continent, country) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = gdp_mean, y = lifeExp_mean)) +
  geom_point() +
  geom_text_repel(aes(label = country)) + # there's also geom_label_repel
  scale_x_log10() +
  facet_grid(~continent)
```

```
## `summarise()` has grouped output by 'continent'. You can override using the `.groups` argument.
```

```
## Warning: ggrepel: 6 unlabeled data points (too many overlaps). Consider
## increasing max.overlaps
```

```
## Warning: ggrepel: 2 unlabeled data points (too many overlaps). Consider
## increasing max.overlaps
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-213-1.pdf)<!-- --> 

### Ploting models 

In plotting models, we extensively use David Robinson's [broom package](https://cran.r-project.org/web/packages/broom/vignettes/broom.html) in R. The idea is to transform model outputs (i.e., predictions and estimations) into tidy objects so that we can easily combine, separate, and visualize these elements. 

#### Plotting several fits at the same time


```r
model_colors <- RColorBrewer::brewer.pal(3, "Set1") # select three qualitatively different colors from a larger palette.

gapminder %>%
  ggplot(aes(x = log(gdpPercap), y = lifeExp)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = "lm", aes(color = "OLS", fill = "OLS")) +
  geom_smooth(
    method = "lm", formula = y ~ splines::bs(x, df = 3),
    aes(color = "Cubic Spline", fill = "Cubic Spline")
  ) +
  geom_smooth(method = "loess", aes(color = "LOESS", fill = "LOESS")) +
  theme(legend.position = "top") +
  scale_color_manual(name = "Models", values = model_colors) +
  scale_fill_manual(name = "Models", values = model_colors)
```

```
## `geom_smooth()` using formula 'y ~ x'
## `geom_smooth()` using formula 'y ~ x'
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-214-1.pdf)<!-- --> 

#### Extracting model outcomes 


```r
# regression model
out <- lm(
  formula = lifeExp ~ gdpPercap + pop + continent,
  data = gapminder
)
```

`tidy()` is a method in the `broom` package. It "constructs a dataframe that summarizes the model's statistical findings". As the description states, tidy is a function that can be used for various models. For instance, a tidy can extract following information from a regression model.

- `Term`: a term being estimated 
- `p.value`
- `statistic`: a test statistic used to compute p-value
- `estimate` 
- `conf.low`: the low end of a confidence interval 
- `conf.high`: the high end of a confidence interval
- `df`: degrees of freedom

**Challenge**

Try `glance(out)`, what did you get from these commands? If you're curious, you can try `?glance`.

The followings are to show your degree of confidence.

##### Coefficients


```r
# estimates
out_comp <- tidy(out)

p <- out_comp %>%
  ggplot(aes(x = term, y = estimate))

p + geom_point() +
  coord_flip() +
  theme_bw()
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-216-1.pdf)<!-- --> 

##### Confidence intervals


```r
# plus confidence intervals
out_conf <- tidy(out, conf.int = TRUE)

# plotting coefficients using ggplot2 (pointrange)
out_conf %>%
  ggplot(aes(x = reorder(term, estimate), y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_pointrange() +
  coord_flip() +
  labs(x = "", y = "OLS Estimate") +
  theme_bw()
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-217-1.pdf)<!-- --> 

```r
# another way to do it (errorbar)
out_conf %>%
  ggplot(aes(x = estimate, y = reorder(term, estimate))) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) +
  labs(y = "", x = "OLS Estimate") +
  theme_bw()
```

![](03_tidy_data_files/figure-latex/unnamed-chunk-217-2.pdf)<!-- --> 

You can calculate marginal effects using the `margins` package. For the sake of time, I'm not covering that here.

<!--chapter:end:03_tidy_data.Rmd-->

# Automating repeated things {#functional_programming}



> Anything that can be automated should be automated. Do as little as possible by hand. Do as much as possible with functions. 
- Hadley Wickham

This chapter helps you to step up your R skills with functional programming. The `purrr` package provides easy-to-use tools to automate repeated things in your entire R workflow (e.g., wrangling, modeling, and visualization). The result is cleaner, faster, more readable, and extendable code.

![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSmywiiOutD0NPieYCKxaD2wN9Fbt2I3iS87A&usqp=CAU)

## Learning objectives

0.  How to use control flow in R using `if_`, `for loop`, and `apply` 
1.  How to use `map()` to automate workflow in a cleaner, faster, and more extendable way  
2.  How to use `map2()` and `pmap()` to avoid writing nested loops
3.  How to use `map()` and `glue()` to automate creating multiple plots
4.  How to use `reduce()` to automate joining multiple dataframes
5.  How to use `slowly()` and `future_` to make the automation process either slower or faster
6.  How to use `safely()` and `possibly()` to make error handling easier
7.  How to develop your data products (e.g., R packages, Shiny apps) 

## Setup 


```r
# Install packages
if (!require("pacman")) {
  install.packages("pacman")
}

pacman::p_load(
  tidyverse, # tidyverse pkgs including purrr
  bench, # performance test 
  tictoc, # performance test
  broom, # tidy modeling
  glue, # paste string and objects
  furrr, # parallel processing
  rvest, # web scraping
  devtools, # dev tools 
  usethis, # workflow     
  roxygen2, # documentation 
  testthat, # testing 
  patchwork) # arranging ggplots 
```

## Flow control {#flow}

* Control structures = putting logic in code to control flow (e.g., `if`, `else`, `for`, `while`, `repeat`, `break`, `next`)

* Almost all the conditional operators used in Python also work in R. The basic loop setup is also very similar, with some small syntax adjustments. 

* ```if()``` is a function whose arguments must be specified inside parentheses.

* ```else```, however, is a reserved operator that takes no arguments. Note that there is no ```elif``` option --- one simply writes ```else if()```.  

* Whereas operations to be executed after conditional evaluations in Python come after a ```:```, R operations must only be enclosed in curly brackets: ```{}```.  Furthermore, there is no requirement for indentation. 

### if (one condition) 


```r
x <- 5

if (x < 0) { # Condition 
  print("x is negative") # Do something 
}
```



```r
x <- -5

if (x < 0) {
  print("x is negative")
}
```

```
## [1] "x is negative"
```

### if + else (two conditions)


```r
x <- 5

if (x < 0) {
  print("x is negative")
} else{
  print("x is positive")
}
```

```
## [1] "x is positive"
```

### if + else if + else (three conditions)


```r
x <- 0

if (x < 0) { # Condition 
  print("x is negative") # Do something 

  } else if (x == 0) { 
  
    print("x is zero") # Do something else 

    } else {print("x is positive") # Do something else 

      }
```

```
## [1] "x is zero"
```

- In general, it's not a good idea to write nested code (lots of `else_if()` or `ifelse()`). It is not easy to read, debug, modulize, and extend. 
- Instead, write functions and, if necessary, use `if()` only. We'll come back to this later.

### Functions 

While functions are defined in Python using the ```def``` reserved operator, R sees functions as just another type of named object.  Thus, they require explicit assignment to an object.  This is done using the function ```function()```, which creates a function taking the arguments specified in parentheses.  

function = input + computation (begin -> end) + output 


```r
simple.function <- function(x){
  print(x + 1)
}

simple.function(x = 2)
```

```
## [1] 3
```

```r
less.simple.function <- function(x, y){
  print(x - y + 1)
}

less.simple.function(x = 2, y = 10)
```

```
## [1] -7
```

Concerning returning function output, most of the same rules apply as with Python. Be sure to remember that ```return()``` will only process a single object, so multiple items must usually be returned as a list. Note that your ordering of the functions matters, too. 


```r
dumbfun <- function(x){
  return(x)
  print("This will never print :(")
}

dumbfun(x = "something")
```

```
## [1] "something"
```

```r
dumbfun <- function(x){
  print("Why did I print?")
  return(x)
}

dumbfun(x = "something")
```

```
## [1] "Why did I print?"
```

```
## [1] "something"
```

```r
dumbfun <- function(x,y){
  thing1 <- x
  thing2 <- y
  return(list(thing1, thing2))
}

dumbfun(x = "some text", y = "some data")
```

```
## [[1]]
## [1] "some text"
## 
## [[2]]
## [1] "some data"
```

```r
dumbfun(x = c(5,10,15), y = "some data")
```

```
## [[1]]
## [1]  5 10 15
## 
## [[2]]
## [1] "some data"
```

R functions also allow you to set default argument values:


```r
less.simple.function <- function(x, y = 0){
  print(x - y + 1)
}

less.simple.function(x = 2)
```

```
## [1] 3
```

```r
less.simple.function(x = 2, y = 10)
```

```
## [1] -7
```

Concerning specifying arguments, one can either use argument **position** specifications (i.e., the order) or argument **name** specifications.  The latter is strongly preferred, as it is straightforward to specify incorrect argument values accidentally.


```r
send <- function(message, recipient, cc=NULL, bcc=NULL){
  print(paste(message, recipient, sep = ", "))
  print(paste("CC:", cc, sep = " "))
  print(paste("BCC:", bcc, sep = " "))
}

send(message = "Hello", recipient = "World", cc = "Sun", bcc = "Jane")
```

```
## [1] "Hello, World"
## [1] "CC: Sun"
## [1] "BCC: Jane"
```

```r
send("Hello", "World", "Sun", "Jane")
```

```
## [1] "Hello, World"
## [1] "CC: Sun"
## [1] "BCC: Jane"
```

```r
send("Hello", "Sun", "Jane", "World")
```

```
## [1] "Hello, Sun"
## [1] "CC: Jane"
## [1] "BCC: World"
```

```r
send(message = "Hello", cc = "Sun", bcc = c("Jane", "Rochelle"), recipient = "World")
```

```
## [1] "Hello, World"
## [1] "CC: Sun"
## [1] "BCC: Jane"     "BCC: Rochelle"
```

Also, note that functions don't have what CS people called side-effects. Functions only define local variables = They don't change objects stored in the global environment. (Consider the difference between `<-` and `=` for assignments.) That's why you can use functions for reusable tasks since it does not interrupt other essential things in your system.

See [the following example](https://darrenjw.wordpress.com/2011/11/23/lexical-scope-and-function-closures-in-r/) from Wilkinson.


```r
a = 1 
b = 2

f <- function(x)
{
  a*x + b
}

f(2)
```

```
## [1] 4
```

```r
g <- function(x)
{
  a = 2
  b = 1
  f(x)
}

g(2) # a equals still 1 
```

```
## [1] 4
```

**Additional tips**

* Nonstandard evaluation 

Nonstandard evaluation is an advanced subject. If you feel overwhelmed, you are more than welcome to skip this. But if you are serious about R programming, this is something you want to check out. For a deeper understanding of this issue, I recommend reading [Ren Kun's very informative blog post](https://renkun.me/2014/12/03/tips-on-non-standard-evaluation-in-r/) carefully. 

This part draws on one of the [the dplyr package articles](https://dplyr.tidyverse.org/articles/programming.html.

In tidyverse, calling a variable with or without quotation mark (string or not) makes little difference because tidyeval is a non-standard evaluation. This flexibility runs into the following problem when it comes to programming. 


```r
# Using `mpg` instead of `mtcars$mpg` is called data masking.

mtcars %>% select(mpg)

mtcars %>% select("mpg")
```

Data and env-variables 


```r
# df = environment variable 
df <- data.frame(
  x = c(1:5),
  y = c(6:10)
  )

# x, y = data variables 
df$x
```

```
## [1] 1 2 3 4 5
```

```r
df$y
```

```
## [1]  6  7  8  9 10
```

- Problem 


```r
x <- NULL 

var_summary <- function(env_var, data_var){
 
   env_var %>%
    summarise(mean = mean(data_var))

}
```

You may expect that the output is mean = 2.5 ... but 

It's because the mean() function doesn't take `df$x` for data_var but `x`. It would be best if you linked x with the environment variable.


```r
var_summary(df, x)
```

```
## Warning in mean.default(data_var): argument is not numeric or logical: returning
## NA
```

```
##   mean
## 1   NA
```

This is how you can fix this. 



```r
# Solution
vs_fix <- function(env_var, data_var){
 
   env_var %>%
    summarise(mean = mean({{data_var}}))

}

# You can also do this. 
vs_fix_enhanced <- function(env_var, data_var){
 
   env_var %>%
    summarise("mean_{{data_var}}" := mean({{data_var}})) # If you use the glue package, this syntax is very intuitive.

}

vs_fix_enhanced(df, x)
```

```
##   mean_x
## 1      3
```

If you have a character vector input ... 


```r
mtcars_count <- mtcars %>%
  names() %>%
  purrr::map(~count(mtcars, .data[[.x]])) # We're going to learn about map in the rest of this session.

mtcars_count[[1]]
```

```
##     mpg n
## 1  10.4 2
## 2  13.3 1
## 3  14.3 1
## 4  14.7 1
## 5  15.0 1
## 6  15.2 2
## 7  15.5 1
## 8  15.8 1
## 9  16.4 1
## 10 17.3 1
## 11 17.8 1
## 12 18.1 1
## 13 18.7 1
## 14 19.2 2
## 15 19.7 1
## 16 21.0 2
## 17 21.4 2
## 18 21.5 1
## 19 22.8 2
## 20 24.4 1
## 21 26.0 1
## 22 27.3 1
## 23 30.4 2
## 24 32.4 1
## 25 33.9 1
```


### for loop 

![Concept map for a for loop. Source: https://teachtogether.tech/en/index.html#s:memory-concept-maps](https://teachtogether.tech/en/figures/for-loop.svg)

Loops in R also work the same way as in Python, with just a few adjustments.  First, recall that index positions in R start at 1.  Second, ```while()``` and ```for()``` are functions rather than reserved operators, meaning they must take arguments in parentheses.  Third, just like ```else```, the ```in``` operator *is* reserved and takes no arguments in parentheses.  Fourth, the conditional execution must appear between curly brackets.  Finally, indentation is meaningless, but each new operation must appear on a new line.

- `while()`: when we have no idea how many times loop needs to be executed.
- `for()`: when we know how many times loop needs to be executed. This is likely to be the loop you are going to use most frequently. 


```r
fruits <- c("apples", "oranges", "pears", "bananas")

# a while loop
i <- 1
while (i <= length(fruits)) {
  print(fruits[i])
  i <- i + 1
}
```

```
## [1] "apples"
## [1] "oranges"
## [1] "pears"
## [1] "bananas"
```

```r
# a for loop
for (i in 1:length(fruits)) {
  print(fruits[i])
}
```

```
## [1] "apples"
## [1] "oranges"
## [1] "pears"
## [1] "bananas"
```

### apply family 

While and for loops in R can be very slow. For this reason, R has many built-in iteration methods to speed up execution times. In many cases, packages will have "behind-the-scenes" ways to avoid `for loops`, but what if you need to write your function? 

A common method of getting around for loops is the **apply** family of functions. These take a data structure and a function and apply a function over all the object elements.


```r
fruit <- c("apple", "orange", "pear", "banana")

# make function that takes in only one element
make.plural <- function(x){
   plural <- paste(x, 's', sep = '') # sep is for collapse, so collpase ''
   return(plural)
}

make.plural('apple')
```

```
## [1] "apples"
```

* `apply()` : loop over the margins (1 = row, 2 = column) of an array 
* `lapply()` : loop over a list then returns a list 
* `sapply()` : loop over a list then returns a named vector 
* `tapply()`: loop over subsets of a vector 
* `mapply()`: multivariate version of `lapply()`. Use this if you have a function that takes in 2 or more arguments.



```r
# apply that function to every element
lapply(fruit, make.plural) # returns a list
```

```
## [[1]]
## [1] "apples"
## 
## [[2]]
## [1] "oranges"
## 
## [[3]]
## [1] "pears"
## 
## [[4]]
## [1] "bananas"
```

```r
sapply(fruit, make.plural) # returns a named vector
```

```
##     apple    orange      pear    banana 
##  "apples" "oranges"   "pears" "bananas"
```

```r
library(purrr) # load package
map(fruit, make.plural) # type consistent
```

```
## [[1]]
## [1] "apples"
## 
## [[2]]
## [1] "oranges"
## 
## [[3]]
## [1] "pears"
## 
## [[4]]
## [1] "bananas"
```


```r
# Why sapply is bad 

sapply(1:100, paste) # return character 
```

```
##   [1] "1"   "2"   "3"   "4"   "5"   "6"   "7"   "8"   "9"   "10"  "11"  "12" 
##  [13] "13"  "14"  "15"  "16"  "17"  "18"  "19"  "20"  "21"  "22"  "23"  "24" 
##  [25] "25"  "26"  "27"  "28"  "29"  "30"  "31"  "32"  "33"  "34"  "35"  "36" 
##  [37] "37"  "38"  "39"  "40"  "41"  "42"  "43"  "44"  "45"  "46"  "47"  "48" 
##  [49] "49"  "50"  "51"  "52"  "53"  "54"  "55"  "56"  "57"  "58"  "59"  "60" 
##  [61] "61"  "62"  "63"  "64"  "65"  "66"  "67"  "68"  "69"  "70"  "71"  "72" 
##  [73] "73"  "74"  "75"  "76"  "77"  "78"  "79"  "80"  "81"  "82"  "83"  "84" 
##  [85] "85"  "86"  "87"  "88"  "89"  "90"  "91"  "92"  "93"  "94"  "95"  "96" 
##  [97] "97"  "98"  "99"  "100"
```

```r
sapply(integer(), paste) # return list!
```

```
## list()
```

```r
library(purrr)
map(1:100, paste) # return list
```

```
## [[1]]
## [1] "1"
## 
## [[2]]
## [1] "2"
## 
## [[3]]
## [1] "3"
## 
## [[4]]
## [1] "4"
## 
## [[5]]
## [1] "5"
## 
## [[6]]
## [1] "6"
## 
## [[7]]
## [1] "7"
## 
## [[8]]
## [1] "8"
## 
## [[9]]
## [1] "9"
## 
## [[10]]
## [1] "10"
## 
## [[11]]
## [1] "11"
## 
## [[12]]
## [1] "12"
## 
## [[13]]
## [1] "13"
## 
## [[14]]
## [1] "14"
## 
## [[15]]
## [1] "15"
## 
## [[16]]
## [1] "16"
## 
## [[17]]
## [1] "17"
## 
## [[18]]
## [1] "18"
## 
## [[19]]
## [1] "19"
## 
## [[20]]
## [1] "20"
## 
## [[21]]
## [1] "21"
## 
## [[22]]
## [1] "22"
## 
## [[23]]
## [1] "23"
## 
## [[24]]
## [1] "24"
## 
## [[25]]
## [1] "25"
## 
## [[26]]
## [1] "26"
## 
## [[27]]
## [1] "27"
## 
## [[28]]
## [1] "28"
## 
## [[29]]
## [1] "29"
## 
## [[30]]
## [1] "30"
## 
## [[31]]
## [1] "31"
## 
## [[32]]
## [1] "32"
## 
## [[33]]
## [1] "33"
## 
## [[34]]
## [1] "34"
## 
## [[35]]
## [1] "35"
## 
## [[36]]
## [1] "36"
## 
## [[37]]
## [1] "37"
## 
## [[38]]
## [1] "38"
## 
## [[39]]
## [1] "39"
## 
## [[40]]
## [1] "40"
## 
## [[41]]
## [1] "41"
## 
## [[42]]
## [1] "42"
## 
## [[43]]
## [1] "43"
## 
## [[44]]
## [1] "44"
## 
## [[45]]
## [1] "45"
## 
## [[46]]
## [1] "46"
## 
## [[47]]
## [1] "47"
## 
## [[48]]
## [1] "48"
## 
## [[49]]
## [1] "49"
## 
## [[50]]
## [1] "50"
## 
## [[51]]
## [1] "51"
## 
## [[52]]
## [1] "52"
## 
## [[53]]
## [1] "53"
## 
## [[54]]
## [1] "54"
## 
## [[55]]
## [1] "55"
## 
## [[56]]
## [1] "56"
## 
## [[57]]
## [1] "57"
## 
## [[58]]
## [1] "58"
## 
## [[59]]
## [1] "59"
## 
## [[60]]
## [1] "60"
## 
## [[61]]
## [1] "61"
## 
## [[62]]
## [1] "62"
## 
## [[63]]
## [1] "63"
## 
## [[64]]
## [1] "64"
## 
## [[65]]
## [1] "65"
## 
## [[66]]
## [1] "66"
## 
## [[67]]
## [1] "67"
## 
## [[68]]
## [1] "68"
## 
## [[69]]
## [1] "69"
## 
## [[70]]
## [1] "70"
## 
## [[71]]
## [1] "71"
## 
## [[72]]
## [1] "72"
## 
## [[73]]
## [1] "73"
## 
## [[74]]
## [1] "74"
## 
## [[75]]
## [1] "75"
## 
## [[76]]
## [1] "76"
## 
## [[77]]
## [1] "77"
## 
## [[78]]
## [1] "78"
## 
## [[79]]
## [1] "79"
## 
## [[80]]
## [1] "80"
## 
## [[81]]
## [1] "81"
## 
## [[82]]
## [1] "82"
## 
## [[83]]
## [1] "83"
## 
## [[84]]
## [1] "84"
## 
## [[85]]
## [1] "85"
## 
## [[86]]
## [1] "86"
## 
## [[87]]
## [1] "87"
## 
## [[88]]
## [1] "88"
## 
## [[89]]
## [1] "89"
## 
## [[90]]
## [1] "90"
## 
## [[91]]
## [1] "91"
## 
## [[92]]
## [1] "92"
## 
## [[93]]
## [1] "93"
## 
## [[94]]
## [1] "94"
## 
## [[95]]
## [1] "95"
## 
## [[96]]
## [1] "96"
## 
## [[97]]
## [1] "97"
## 
## [[98]]
## [1] "98"
## 
## [[99]]
## [1] "99"
## 
## [[100]]
## [1] "100"
```

```r
map(integer(), paste) # return list
```

```
## list()
```

## purrr {#purrr}

### Why map? 

#### Objectives 

- How to use `purrr` to automate workflow in a cleaner, faster, and more extendable way

#### Copy-and-paste programming 

> Copy-and-paste programming, sometimes referred to as just pasting, is the production of highly repetitive computer programming code, as produced by copy and paste operations. It is primarily a pejorative term; those who use the term are often implying a lack of programming competence. It may also be the result of technology limitations (e.g., an insufficiently expressive development environment) as subroutines or libraries would normally be used instead. However, there are occasions when copy-and-paste programming is considered acceptable or necessary, such as for boilerplate, loop unrolling (when not supported automatically by the compiler), or certain programming idioms, and it is supported by some source code editors in the form of snippets. - Wikipedia 

- The following exercise was inspired by [Wickham's example](http://adv-r.had.co.nz/Functional-programming.html).

- Let's imagine `df` is a survey dataset. 

    - `a, b, c, d` = Survey questions 

    - `-99`: non-responses 
    
    - Your goal: replace `-99` with `NA` 
    

```r
# Data

set.seed(1234) # for reproducibility

df <- tibble(
  "a" = sample(c(-99, 1:3), size = 5, replace = TRUE),
  "b" = sample(c(-99, 1:3), size = 5, replace = TRUE),
  "c" = sample(c(-99, 1:3), size = 5, replace = TRUE),
  "d" = sample(c(-99, 1:3), size = 5, replace = TRUE)
)
```


```r
# Copy and paste
df$a[df$a == -99] <- NA
df$b[df$b == -99] <- NA
df$c[df$c == -99] <- NA
df$d[df$d == -99] <- NA

df
```

```
## # A tibble: 5 x 4
##       a     b     c     d
##   <dbl> <dbl> <dbl> <dbl>
## 1     3     3     3     1
## 2     3     2     3     1
## 3     1    NA     1     2
## 4     1    NA     2     1
## 5    NA     1     1     3
```

- **Challenge**. Explain why this solution is not very efficient (Hint: If `df$a[df$a == -99] <- NA` has an error, how will you fix it? A solution is not scalable if it's not automatable.

#### Using a function 

- Let's recall what's function in R: `input + computation + output` 

- If you write a function, you gain efficiency because you don't need to copy and paste the computation part. 

`
function(input){
  
  computation 
  
  return(output)
}
`


```r
# Function

fix_missing <- function(x) {
  x[x == -99] <- NA
  x
}

# Apply function to each column (vector)

df$a <- fix_missing(df$a)
df$b <- fix_missing(df$b)
df$c <- fix_missing(df$c)
df$d <- fix_missing(df$d)

df
```

```
## # A tibble: 5 x 4
##       a     b     c     d
##   <dbl> <dbl> <dbl> <dbl>
## 1     3     3     3     1
## 2     3     2     3     1
## 3     1    NA     1     2
## 4     1    NA     2     1
## 5    NA     1     1     3
```

- **Challenge** Why is using function more efficient than 100% copying and pasting? Can you think about a way we can automate the process?

- Many options for automation in R: `for loop`, `apply` family, etc. 

- Here's a tidy solution that comes from the `purrr` package.

- The power and joy of one-liner. 


```r
df <- purrr::map_df(df, fix_missing)

df
```

```
## # A tibble: 5 x 4
##       a     b     c     d
##   <dbl> <dbl> <dbl> <dbl>
## 1     3     3     3     1
## 2     3     2     3     1
## 3     1    NA     1     2
## 4     1    NA     2     1
## 5    NA     1     1     3
```

`map()` is a [higher-order function](https://en.wikipedia.org/wiki/Map_(higher-order_function)) that applies a given function to each element of a list/vector. 

![This is how map() works. It's easier to understand with a picture.](https://d33wubrfki0l68.cloudfront.net/f0494d020aa517ae7b1011cea4c4a9f21702df8b/2577b/diagrams/functionals/map.png)

    - Input: Takes a vector/list. 
    
    - Computation: Calls the function once for each element of the vector 
  
    - Output: Returns in a list or whatever data format you prefer (e.g., `_df helper: dataframe`)

- **Challenge** If you run the code below, what will be the data type of the output?


```r
map(df, fix_missing)
```

```
## $a
## [1]  3  3  1  1 NA
## 
## $b
## [1]  3  2 NA NA  1
## 
## $c
## [1] 3 3 1 2 1
## 
## $d
## [1] 1 1 2 1 3
```

- Why `map()` is a good alternative to `for loop`. 
```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/bzUmK0Y07ck" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p>The Joy of Functional Programming (for Data Science) - Hadley Wickham</p>
```


```r
# Built-in data
data("airquality")

tic()

# Placeholder
out1 <- vector("double", ncol(airquality))

# Sequence variable
for (i in seq_along(airquality)) { 

  # Assign an iteration result to each element of the placeholder list 
  out1[[i]] <- mean(airquality[[i]], na.rm = TRUE)
}

toc()
```

```
## 0.007 sec elapsed
```

`map` is faster because it applies function to the items on the list/vector in parallel. Also, using `map_dbl` reduces an extra step you need to take. Hint: `map_dbl(x, mean, na.rm = TRUE)` = `vapply(x, mean, na.rm = TRUE, FUN.VALUE = double(1))`
 


```r
tic()
out1 <- airquality %>% map_dbl(mean, na.rm = TRUE)
toc()
```

```
## 0.002 sec elapsed
```

- In short, `map()` is more readable, faster, and easily extendable with other data science tasks (e.g., wrangling, modeling, and visualization) using `%>%`. 

- Final point: Why not base R `apply` family? 

- Short answer: `purrr::map()` is simpler to write. 

**Additional tips**

Performance testing (profiling) is an important part of programming. `tictoc()` measures the time needed to run a target function for once. If you want a more robust measure of timing as well as information on memory (**speed** and **space** both matter for performance testing), consider using the [`bench` package](https://github.com/r-lib/bench) that is designed for high precision timing of R expressions. 



```r
map_mark <- bench::mark(

  out1 <- airquality %>% map_dbl(mean, na.rm = TRUE)

  )

map_mark
```

```
## # A tibble: 1 x 6
##   expression                                              min   median `itr/sec`
##   <bch:expr>                                         <bch:tm> <bch:tm>     <dbl>
## 1 out1 <- airquality %>% map_dbl(mean, na.rm = TRUE)   54.1us   76.1us    11932.
## # ... with 2 more variables: mem_alloc <bch:byt>, gc/sec <dbl>
```

#### Applications 

1. Many models

- One popular application of `map()` is to run regression models (or whatever model you want to run) on list-columns. No more copying and pasting for running many regression models on subgroups!


```r
# Have you ever tried this?
lm_A <- lm(y ~ x, subset(data, subgroup == "group_A"))
lm_B <- lm(y ~ x, subset(data, subgroup == "group_B"))
lm_C <- lm(y ~ x, subset(data, subgroup == "group_C"))
lm_D <- lm(y ~ x, subset(data, subgroup == "group_D"))
lm_E <- lm(y ~ x, subset(data, subgroup == "group_E"))
```

- For more information on this technique, read the Many Models subchapter of the [R for Data Science](https://r4ds.had.co.nz/many-models.html#creating-list-columns).


```r
# Function
lm_model <- function(df) {
  lm(Temp ~ Ozone, data = df)
}

# Map
models <- airquality %>%
  group_by(Month) %>%
  nest() %>% # Create list-columns
  mutate(ols = map(data, lm_model)) # Map
models$ols[1]
```

```
## [[1]]
## 
## Call:
## lm(formula = Temp ~ Ozone, data = df)
## 
## Coefficients:
## (Intercept)        Ozone  
##     62.8842       0.1629
```

```r
# Add tidying
tidy_lm_model <- purrr::compose( # compose multiple functions
  broom::tidy, # convert lm objects into tidy tibbles
  lm_model
)

tidied_models <- airquality %>%
  group_by(Month) %>%
  nest() %>% # Create list-columns
  mutate(ols = map(data, tidy_lm_model))

tidied_models$ols[1]
```

```
## [[1]]
## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)   62.9      1.61       39.2  2.88e-23
## 2 Ozone          0.163    0.0500      3.26 3.31e- 3
```

2. Simulations 

A good friend of `map()` function is `rerun()` function. This combination is really useful for simulations. Consider the following example. 

* Base R approach 


```r
set.seed(1234)

small_n <- 100 ; k <- 1000 ; mu <- 500 ; sigma <- 20 

y_list <- rep(list(NA), k)

for (i in seq(k)) {
        
    y_list[[i]] <- rnorm(small_n, mu, sigma)
        
}

y_means <- unlist(lapply(y_list, mean))

qplot(y_means) +
   geom_vline(xintercept = 500, linetype = "dotted", color = "red")
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

![](04_functional_programming_files/figure-latex/unnamed-chunk-32-1.pdf)<!-- --> 

* rerun() + map()


```r
small_n <- 100 ; k <- 1000; mu <- 500 ; sigma <- 20 

y_tidy <- rerun(k, rnorm(small_n, mu, sigma)) 

y_means_tidy <- map_dbl(y_tidy, mean)

# Visualize 
(qplot(y_means) +
   geom_vline(xintercept = 500, linetype = "dotted", color = "red")) +
(qplot(y_means_tidy) +
   geom_vline(xintercept = 500, linetype = "dotted", color = "red"))
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

![](04_functional_programming_files/figure-latex/unnamed-chunk-33-1.pdf)<!-- --> 

## Automote 2 or 2+ tasks {#map2}

### Objectives 

- Learning how to use `map2()` and `pmap()` to avoid writing nested loops.

### Problem 

- Problem: How can you create something like the below?

[1] "University =  Berkeley | Department =  waterbenders"

[1] "University =  Berkeley | Department =  earthbenders"

[1] "University =  Berkeley | Department =  firebenders"

[1] "University =  Berkeley | Department =  airbenders"

[1] "University =  Stanford | Department =  waterbenders"

[1] "University =  Stanford | Department =  earthbenders"

[1] "University =  Stanford | Department =  firebenders"

[1] "University =  Stanford | Department =  airbenders"

- The most manual way: You can copy and paste eight times.


```r
paste("University = Berkeley | Department = CS")
```

```
## [1] "University = Berkeley | Department = CS"
```

### For loop 

- A slightly more efficient way: using a for loop. 
- Think about which part of the statement is constant and which part varies ( = parameters).  
- Do we need a placeholder? No. We don't need a placeholder because we don't store the result of iterations.
    
- **Challenge**: How many parameters do you need to solve the problem below?
  

```r
# Outer loop

for (univ in c("Berkeley", "Stanford")) {

  # Inner loop

  for (dept in c("waterbenders", "earthbenders", "firebenders", "airbenders")) {
    print(paste("University = ", univ, "|", "Department = ", dept))
  }
}
```

```
## [1] "University =  Berkeley | Department =  waterbenders"
## [1] "University =  Berkeley | Department =  earthbenders"
## [1] "University =  Berkeley | Department =  firebenders"
## [1] "University =  Berkeley | Department =  airbenders"
## [1] "University =  Stanford | Department =  waterbenders"
## [1] "University =  Stanford | Department =  earthbenders"
## [1] "University =  Stanford | Department =  firebenders"
## [1] "University =  Stanford | Department =  airbenders"
```

- This is not bad, but ... `n` arguments -> `n-nested for loops`. As a scale of your problem grows, your code gets complicated.

> To become significantly more reliable, code must become more transparent. In particular, nested conditions and loops must be viewed with great suspicion. Complicated control flows confuse programmers. Messy code often hides bugs. — [Bjarne Stroustrup](https://en.wikipedia.org/wiki/Bjarne_Stroustrup)

### map2 & pmap

- Step 1: Define inputs and a function.

- **Challenge** Why are we using `rep()` to create input vectors? For instance, for `univ_list` why not just use `c("Berkeley", "Stanford")`?


```r
# Inputs (remember the length of these inputs should be identical)

univ_list <- rep(c("Berkeley", "Stanford"), 4)
dept_list <- rep(c("waterbenders", "earthbenders", "firebenders", "airbenders"), 2)

# Function

print_lists <- function(univ, dept) {
  print(paste(
    "University = ", univ, "|",
    "Department = ", dept
  ))
}

# Test

print_lists(univ_list[1], dept_list[1])
```

```
## [1] "University =  Berkeley | Department =  waterbenders"
```

- Step2: Using `map2()` or `pmap()`

![](https://dcl-prog.stanford.edu/images/map2.png)


```r
# 2 arguments
map2_output <- map2(univ_list, dept_list, print_lists)
```

```
## [1] "University =  Berkeley | Department =  waterbenders"
## [1] "University =  Stanford | Department =  earthbenders"
## [1] "University =  Berkeley | Department =  firebenders"
## [1] "University =  Stanford | Department =  airbenders"
## [1] "University =  Berkeley | Department =  waterbenders"
## [1] "University =  Stanford | Department =  earthbenders"
## [1] "University =  Berkeley | Department =  firebenders"
## [1] "University =  Stanford | Department =  airbenders"
```

![](https://d33wubrfki0l68.cloudfront.net/e426c5755e2e65bdcc073d387775db79791f32fd/92902/diagrams/functionals/pmap.png)


```r
# 3+ arguments
pmap_output <- pmap(list(univ_list, dept_list), print_lists)
```

```
## [1] "University =  Berkeley | Department =  waterbenders"
## [1] "University =  Stanford | Department =  earthbenders"
## [1] "University =  Berkeley | Department =  firebenders"
## [1] "University =  Stanford | Department =  airbenders"
## [1] "University =  Berkeley | Department =  waterbenders"
## [1] "University =  Stanford | Department =  earthbenders"
## [1] "University =  Berkeley | Department =  firebenders"
## [1] "University =  Stanford | Department =  airbenders"
```

- **Challenge** Have you noticed that we used a slightly different input for `pmap()` compared to `map()` or `map2()`? What is the difference?

## Automate plotting {#glue}

### Objective 

- Learning how to use `map()` and `glue()` to automate creating multiple plots

### Problem 

- Making the following data visualization process more efficient. 


```r
data("airquality")

airquality %>%
  ggplot(aes(x = Ozone, y = Solar.R)) +
  geom_point() +
  labs(
    title = "Relationship between Ozone and Solar.R",
    y = "Solar.R"
  )
```

```
## Warning: Removed 42 rows containing missing values (geom_point).
```

![](04_functional_programming_files/figure-latex/unnamed-chunk-39-1.pdf)<!-- --> 

```r
airquality %>%
  ggplot(aes(x = Ozone, y = Wind)) +
  geom_point() +
  labs(
    title = "Relationship between Ozone and Wind",
    y = "Wind"
  )
```

```
## Warning: Removed 37 rows containing missing values (geom_point).
```

![](04_functional_programming_files/figure-latex/unnamed-chunk-39-2.pdf)<!-- --> 

```r
airquality %>%
  ggplot(aes(x = Ozone, y = Temp)) +
  geom_point() +
  labs(
    title = "Relationship between Ozone and Temp",
    y = "Temp"
  )
```

```
## Warning: Removed 37 rows containing missing values (geom_point).
```

![](04_functional_programming_files/figure-latex/unnamed-chunk-39-3.pdf)<!-- --> 

### Solution 

- Learn how `glue()` works. 

- `glue()` combines strings and objects and it works simpler and faster than `paste()` or `sprintif()`. 


```r
names <- c("Jae", "Aniket", "Avery")

fields <- c("Political Science", "Law", "Public Health")

glue("{names} studies {fields}.")
```

```
## Jae studies Political Science.
## Aniket studies Law.
## Avery studies Public Health.
```

- So, our next step is to combine `glue()` and `map()`. 

- Let's first think about writing a function that includes `glue()`.

- **Challenge**
How can you create the character vector of column names? 

- **Challenge**
How can you make `ggplot2()` take strings as x and y variable names? (Hint: Type `?aes_string()`) 


```r
airquality %>%
  ggplot(aes_string(x = names(airquality)[1], y = names(airquality)[2])) +
  geom_point() +
  labs(
    title = glue("Relationship between Ozone and {names(airquality)[2]}"),
    y = glue("{names(airquality)[2]}")
  )
```

```
## Warning: Removed 42 rows containing missing values (geom_point).
```

![](04_functional_programming_files/figure-latex/unnamed-chunk-41-1.pdf)<!-- --> 

- The next step is to write an automatic plotting function. 

    - Note that in the function argument `i` (abstract) replaced 2 (specific): abstraction  


```r
create_point_plot <- function(i) {
  airquality %>%
    ggplot(aes_string(x = names(airquality)[1], y = names(airquality)[i])) +
    geom_point() +
    labs(
      title = glue("Relationship between Ozone and {names(airquality)[i]}"),
      y = glue("{names(airquality)[i]}")
    )
}
```

- The final step is to put the function in `map()`.


```r
map(2:ncol(airquality), create_point_plot)
```

```
## [[1]]
```

```
## Warning: Removed 42 rows containing missing values (geom_point).
```

![](04_functional_programming_files/figure-latex/unnamed-chunk-43-1.pdf)<!-- --> 

```
## 
## [[2]]
```

```
## Warning: Removed 37 rows containing missing values (geom_point).
```

![](04_functional_programming_files/figure-latex/unnamed-chunk-43-2.pdf)<!-- --> 

```
## 
## [[3]]
```

```
## Warning: Removed 37 rows containing missing values (geom_point).
```

![](04_functional_programming_files/figure-latex/unnamed-chunk-43-3.pdf)<!-- --> 

```
## 
## [[4]]
```

```
## Warning: Removed 37 rows containing missing values (geom_point).
```

![](04_functional_programming_files/figure-latex/unnamed-chunk-43-4.pdf)<!-- --> 

```
## 
## [[5]]
```

```
## Warning: Removed 37 rows containing missing values (geom_point).
```

![](04_functional_programming_files/figure-latex/unnamed-chunk-43-5.pdf)<!-- --> 

## Automate joining {#reduce}

### Objective 

- Learning how to use `reduce()` to automate row-binding multiple dataframes

### Problem 

- How can you make row-binding multiple dataframes more efficient?


```r
df1 <- tibble(
  x = sample(1:10, size = 3, replace = TRUE),
  y = sample(1:10, size = 3, replace = TRUE),
  z = sample(1:10, size = 3, replace = TRUE)
)

df2 <- tibble(
  x = sample(1:10, size = 3, replace = TRUE),
  y = sample(1:10, size = 3, replace = TRUE),
  z = sample(1:10, size = 3, replace = TRUE)
)

df3 <- tibble(
  x = sample(1:10, size = 3, replace = TRUE),
  y = sample(1:10, size = 3, replace = TRUE),
  z = sample(1:10, size = 3, replace = TRUE)
)
```

### Copy and paste


```r
first_bind <- bind_rows(df1, df2)

second_bind <- bind_rows(first_bind, df3)
```

- **Challenge**
Why is the above solution not efficient?

### reduce 

![How reduce() works.](https://d33wubrfki0l68.cloudfront.net/9c239e1227c69b7a2c9c2df234c21f3e1c74dd57/eec0e/diagrams/functionals/reduce.png)

    - Input: Takes a vector of length n
  
    - Computation: Calls a function with a pair of values at a time
  
    - Output: Returns a vector of length 1
    

```r
reduced <- reduce(list(df1, df2, df3), bind_rows)
```

## Make automation slower or faster {#speed}


```r
# Install packages 
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, # tidyverse pkgs including purrr
               tictoc, # performance test 
               furrr) # parallel processing  reproducibility 
```

### Objectives 

- Learning how to use `slowly()` and `future_` to make the automation process either slower or faster

### How to Make Automation Slower

- Scraping 50 pages from a website and you don't want to overload the server. How can you do that?

#### For loop 



#### Map 

- `walk()` works the same as `map()` but doesn't store its output. 



- If you're web scraping, one problem with this approach is it's too fast by human standards.


```r
tic("Scraping pages")
walk(1:10, function(x){message("Scraping page", x)}) # Anonymous function; I don't name the function 
```

```
## Scraping page1
```

```
## Scraping page2
```

```
## Scraping page3
```

```
## Scraping page4
```

```
## Scraping page5
```

```
## Scraping page6
```

```
## Scraping page7
```

```
## Scraping page8
```

```
## Scraping page9
```

```
## Scraping page10
```

```r
toc(log = TRUE) # save toc 
```

```
## Scraping pages: 0.004 sec elapsed
```

- If you want to make the function run slowly ... 

> slowly() takes a function and modifies it to wait a given amount of time between each call. - `purrr` package vignette 

- If a function is a verb, then a helper function is an adverb (modifying the behavior of the verb). 



### How to Make Automation Faster 

In a different situation, you want to make your function run faster. This is a common situation when you collect and analyze data a large-scale. You can solve this problem using parallel processing. A modern processor has a multi-core. You can divide tasks among these cores. R uses a single thread or only core. You can configure this default setting by the following code. For further information on the parallel processing in R (there are many other options), read [this review](https://yxue-me.com/post/2019-05-12-a-glossary-of-parallel-computing-packages-in-r-2019/).

- Parallel processing setup 

    - Step1: Determine the number of max workers (`availableCores()`)
    
    - Step2: Determine the parallel processing mode (`plan()`) 

We do `availableCores() - 1` to save some processing power for other programs.


```r
# Setup 
n_cores <- availableCores() - 1
n_cores # This number depends on your computer spec.
```

```
## system 
##      7
```


```r
plan(multiprocess, # multicore, if supported, otherwise multisession
     workers = n_cores) # the maximum number of workers
```

```
## Warning: Strategy 'multiprocess' is deprecated in future (>= 1.20.0). Instead,
## explicitly specify either 'multisession' or 'multicore'. In the current R
## session, 'multiprocess' equals 'multicore'.
```

**What's the difference between multisession and multicore?**

I skip technical explanations and only focus on their usages.

- multisession : fast, and relatively stable. It works across different OSs and also for RStudio.
- multicore :	faster, but unstable. It doesn't work for Windows/RStudio.







```r
tic.log(format = TRUE)
```

```
## [[1]]
## [1] "Scraping pages: 0.004 sec elapsed"
## 
## [[2]]
## [1] "scraping pages with deplay: 9.016 sec elapsed"
## 
## [[3]]
## [1] "averaging 100000 without parallel processing: 0.397 sec elapsed"
## 
## [[4]]
## [1] "averaging 100000 with parallel processing: 0.353 sec elapsed"
```

Because of the overhead cost (e.g., time spent communicating data between processing), parallel processing does not always increase performance. Use this technique either when the computation part is heavy or when you need to repeat the process a large number of times.  

## Make error handling easier {#robustness}

### Learning objective 

- Learning how to use `safely()` and `possibly()` to make error handling easier 
### Problem 

- **Challenge**

- Explain why we can't run `map(url_list, read_html)`


```r
url_list <- c(
  "https://en.wikipedia.org/wiki/University_of_California,_Berkeley",
  "https://en.wikipedia.org/wiki/Stanford_University",
  "https://en.wikipedia.org/wiki/Carnegie_Mellon_University",
  "https://DLAB"
)
```


```r
map(url_list, read_html)
```

- This is a straightforward problem, so it's easy to tell where the problem is. How can you make your error more informative? 

### Solution 

#### Try-catch 

- There are three kinds of messages you will run into if your code has an error based on the following functions.  

    - `stop()`: errors; Functions must stop. 
    - `warning()`: warnings; Functions may still work. Nonetheless, something is possibly messed up. 
    - `message()`: messages; Some actions happened. 
    
- The basic logic of `try-catch`, R's basic error handling function, works like the following. 


```r
tryCatch(
  {
    map(url_list, read_html)
  },
  warning = function(w) {
    "Warning"
  },
  error = function(e) {
    "Error"
  },
  finally = {
    "Message"
  }
)
```

```
## [1] "Error"
```

- Here's `purrr` version of the `try-catch` mechanism (evaluates code and assigns exception handlers). 

#### safely

**Outputs** 

- result: result or `NULL`
- error: `NULL` or `error` 


```r
map(url_list, safely(read_html))
```

```
## [[1]]
## [[1]]$result
## {html_document}
## <html class="client-nojs" lang="en" dir="ltr">
## [1] <head>\n<meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...
## [2] <body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject  ...
## 
## [[1]]$error
## NULL
## 
## 
## [[2]]
## [[2]]$result
## {html_document}
## <html class="client-nojs" lang="en" dir="ltr">
## [1] <head>\n<meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...
## [2] <body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject  ...
## 
## [[2]]$error
## NULL
## 
## 
## [[3]]
## [[3]]$result
## {html_document}
## <html class="client-nojs" lang="en" dir="ltr">
## [1] <head>\n<meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...
## [2] <body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject  ...
## 
## [[3]]$error
## NULL
## 
## 
## [[4]]
## [[4]]$result
## NULL
## 
## [[4]]$error
## <simpleError in open.connection(x, "rb"): Could not resolve host: DLAB>
```

- The easier way to solve this problem is just to avoid the error.


```r
map(url_list, safely(read_html)) %>%
  map("result") %>% 
  # = map(function(x) x[["result"]]) = map(~.x[["name"]])
  purrr::compact() # Remove empty elements
```

```
## [[1]]
## {html_document}
## <html class="client-nojs" lang="en" dir="ltr">
## [1] <head>\n<meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...
## [2] <body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject  ...
## 
## [[2]]
## {html_document}
## <html class="client-nojs" lang="en" dir="ltr">
## [1] <head>\n<meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...
## [2] <body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject  ...
## 
## [[3]]
## {html_document}
## <html class="client-nojs" lang="en" dir="ltr">
## [1] <head>\n<meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...
## [2] <body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject  ...
```

#### possibly 

What if the best way to solve the problem is not to ignore the error ... 


```r
# If error occurred, "The URL is broken." will be stored in that element(s).
out <- map(
  url_list,
  possibly(read_html,
    otherwise = "The URL is broken."
  )
)

# Let's find the broken URL.
url_list[out[seq(out)] == "The URL is broken."]
```

```
## [1] "https://DLAB"
```

<!--chapter:end:04_functional_programming.Rmd-->

# Developing data products {#products}



> A data product is the production output from a statistical analysis. - [Brian Caffo](https://sites.google.com/view/bcaffo/home)

## Developing R packages 

Why developing R packages? 

1. Reuse your code 
2. Automate your workflow 
3. Help others (be part of an open-source development community)

### Workflow 

1. Create a GitHub repo 
2. Clone the GitHub repo 
3. Make the cloned repo R package project using `usethis::create_package(here())` 
4. Write code in `\R`
5. Document code in `\man` (automated by `roxygen2` package)
  - `devtools::document()` 
6. Check dependencies in `NAMESPACE`
  - `devtools::update()` updates the documentation (if you made changes) 
  - `devtools::check()` to see whether your package is ready to be submitted to CRAN
7. Build a package (for more information, read [this section](http://r-pkgs.had.co.nz/package.html) in Hadley's R package development book)
  - `devtools::build()` 
8. (Optional) Test (`devtools::test()`), teach in `\vignettes`, and add data in `\data`
9. Distribute the package either via CRAN or GitHub (don't forget to make sure your repo is public.)

![](http://r-pkgs.had.co.nz/diagrams/package-files.png)

It's time to learn five R code states: source, bundled, binary, installed, and in-memory. 

If you're using an R package, you're only concerned of the last two states: `install.packages("pkg")` and `library(pkg)` If you're developing an R package, you first write source code (`*.R`), bundle it (compressed file like `*.tar.gz`; done by `devtools::build()`), then make it binary (`devtools::build(binary = TRUE)`; This is how a package is stored in CRAN/GitHub, etc.).

### Required Components

The 4 required components are necessary to build and distribute a minimally viable R package. The other steps are optional.

- Package 
  - `\R`: R functions 
  - `\man`: function documentations 
  - DESCRIPTION: provides meta data about the package (e.g., author)
  - LICENSE
    - GNU, MIT, etc.
  - NAMESPACE: package dependencies (to make your package self-contained)
  - README (optional)
  
1. Setup (**DESCRIPTION**)

I assume that you've already created and cloned a git repo. Move to your cloned repo file path in the file system.


```r
# This function creates DESCRIPTION file 
usethis::create_package(here())

# License the package 
# You can use the MIT license by typing devtools::use_mit_license("author name"). The function produces MIT license-related files (LICENSE, LICENSE.md).
use_mit_license("Jae Yeon Kim")

# Add news (optional) 
# Helps track changes 
use_news_md() 
```

2. Write code (**R**)

If you want to turn your R markdown file into R script use `knitr::purl(input = "x.Rmd",
output = "x.R"). The [fusen package](https://thinkr-open.github.io/fusen/) helps to develop an R package based on R markdown files. 


```r
usethis::use_r("rbind_mutate")
```


```r
#' Add two numbers
#'
#' @param x A number
#' @param y A number
#' @return The sum of x and y 
#' @export

add <- function(x, y){
  
  x + y
  
}
```

If you used a function from other packages, you need to reference it in the following way: `#' @importFrom <package> <function>`

Many of us, use `%>%` operator. If you want to add this to your documentation, do `usethis::use_pipe()`.

3. Document (**man**)

This documentation is for the function manual. 


```r
# Document 
# The function creates documentation related files (NAMESPACE, function_name.rd)
devtools::document()

# Check; updates the documentation; builds and checks the package 
devtools::check()
```

4. Organize (**NAMESPACE**)

This documentation is for [namespace](https://en.wikipedia.org/wiki/Namespace). 


```r
usethis::use_package("dplyr")
```

### Optional Components  

1. Test (**test**)

Although I said optional, automated unit testing is not option, when you're writing a complex package. Testing will you save tons of time and energy.

- Setup 


```r
usethis::use_testthat()

usethis::use_test("rbind_mutate")
```

- Testing 


```r
# Make changes 

# Load functions 
devtools::load_all()

# Test 
devtools::test()
```

2. Add data (**data**)


```r
x <- "Jae"
y <- "Sun"
z <- "Jane"

usethis::use_data(x, y, z, overwrite = TRUE)
```

3. Teach (**vignetts**)


```r
usethis::use_vignette("rbind_mutate")
```

```r
title: "Vignette title"
author: "Vignette author"
date: "2021-12-13"
output: rmarkdown::html_vignette
vignette: blah blah
``` 

- You can build a package website using `pkgdown`


```r
# install.packages("pkgdown")
usethis::use_pkgdown()
pkgdown::build_site()
```

- A package site includes information on METADATA, Function references, Articles, News, etc. 

### Building an R package 

- CMD (in the terminal)

You can run R commands in the terminal using R CMD.



- devtools 


```r
# Build 
devtools::build()

# Install 
devtools::install()
```

### Distributing an R package 


```r
# Version update 
usethis::use_version()

# Spell check
usethis::use_spell_check()
```

1. [CRAN (The Comprehensive R Archive Network)](https://cran.r-project.org/)
  - R package submission should comply with [the CRAN Repository Policy](https://cran.r-project.org/)

2. GitHub 
  - Push everything to the Git repository (you can do it using command-line interface or RStudio).



  - Don't forget that your repository should be `public`.
  
  - I highly recommend connecting GitHub with SSH. For more information, visit [this link](https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh).
  


**Additional tips**

Sometimes, you get the following error: "Undefined global functions or variables" If you experience this problem, save the following script as `globals.r.`


```r
utils::globalVariables(c("<undefined variable name1>", "<undefined variable name2>", "<undefinedvariable name3"))
```

```
## [1] "<undefined variable name1>" "<undefined variable name2>"
## [3] "<undefinedvariable name3"
```

## Developing Shiny apps

[Shiny](https://shiny.rstudio.com/) is a "framework for creating web applications using R code" ([Wickham 2021](https://mastering-shiny.org/)). You can create a [dashboard](https://rstudio.github.io/shinydashboard/) or an [interactive map](https://rviews.rstudio.com/2019/10/09/building-interactive-world-maps-in-shiny/) without knowing anything about HTML, CSS, or JavaScript. Developing a shiny app helps people with little technical expertise learn from your data analysis intuitively and interactively.

To learn more about Shiny applications, see [the Winners of the 2nd Annual Shiny Contest](https://blog.rstudio.com/2020/07/13/winners-of-the-2nd-shiny-contest/) hosted by RStudio.

```{=html}

<iframe width="560" height="315" src="https://www.youtube.com/embed/Wy3TY0gOmJw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p>Shiny in production: Principles, practices, and tools - Joe Cheng</p>

```

```{=html}

<iframe src="https://vac-lshtm.shinyapps.io/ncov_tracker/?_ga=2.240702211.1091983227.1603295793-100003412.1602392815" style="border: 1px solid #AAA; width: 800px; height: 700px"></iframe>

<p>COVID-19 tracker by Edward Parker</p>

```

### Workflow 

The workflow follows what Hadley Wickham recommended in his book on mastering shiny. 

1. Install libraries 

```r
install.packages("shiny")
```

2. Create app directory and file 

Add an `app.R` file.

The key objective here is defining your UI (User interface; how the app looks; front-end = INPUT) (defined in object `ui`) and server (how the app works; back-end = OUTPUT) (defined in object `server`). Shiny uses **reactive programming**. If you change inputs on the user side, outputs will be automatically updated on the server end.

If you're creating a complex app, you can achieve the same goal with two files: `ui.R` and `server.R`.

### app.r 


- Front-end


```r
# Load packages 
# Do not use install.packages(), pacman::p_load(), or library() if you intend to deploy the app using shinyapps.io 

require("wordcloud2")
require("shiny")
require("shinydashboard")
require("colourpicker")
```



```r
# Load data 

df <- read.csv(url("https://github.com/jaeyk/covid19antiasian/raw/master/processed_data/hash_counts.csv"))[,-1]
```

`fluidPage()`: provides the layout for the UI

`sliderInput()`: one of the input controls (e.g., `selectInput()`, `textInput()`, `numericInput()`)

`wordcloud2Output()` one of the output controls (e.g., `tableOutput()`)


```r
# Defines the user interface; how the app looks

ui <- fluidPage(
  
    # Application title 
    titlePanel("Word Cloud on the Hashtags of the Tweets related to COVID-19 & Asian|Chinese|Wuhan"),
  
    h4(tags$a(href = "https://jaeyk.github.io/", "Developer: Jae Yeon Kim")),
            
    sidebarLayout(
      
      # Sidebar with sliders 
      sidebarPanel(
        sliderInput("size", # Input ID: input$size 
                    "Font size:",
                    min = 1, max = 10,
                    value = 2)
      ),
    
    mainPanel(
          
          wordcloud2Output("cloud"),
        
        )
    
    )
)
```

- Back-end


```r
server <- function(input, output, session) {
  
  output$cloud <- renderWordcloud2({ 
    
    wordcloud2(df, 
               size = input$size, 
               color = "random-dark") 
    
    })

  }
```

- Build a shiny app 


```r
shinyApp(ui = ui, server = server)
```

### Deployment 

- Deploy to [the shinyapps.io cloud](https://www.shinyapps.io/?_ga=2.5503866.871102833.1602978469-100003412.1602392815) 


```r
# Install packages 
install.packages("rsconnect")
library(rsconnect)

# Setup 
rsconnect::setAccountInfo(name = "<Account name>", 
                          token = "<Token>",
                          secret = "<Secret>")

rsconnect::deployApp(appNames = "<App name>")
```

### References 

[Mastering Shiny](https://mastering-shiny.org/) by Hadley Wickham. For newbies. 

[Shiny Documents](https://bookdown.org/yihui/rmarkdown/shiny-documents.html) by Yihui Xie

[Engineering Production-Grade Shiny Apps](https://engineering-shiny.org/) by Colin Fay, Sébastien Rochette, Vincent Guyader, Cervan Girard.

[Building Shiny Apps](https://stat545.com/shiny-tutorial.html) by Dean Attali.

## Other useful data products 

- Automating data reports using rmarkdown (called [parameterized reports](https://rmarkdown.rstudio.com/developer_parameterized_reports.html%23parameter_types%2F))
- Automating R presentation using [slidify](http://slidify.org/index.html)
- Creating interactive web apps using [leaflet](https://rstudio.github.io/leaflet/) 

<!--chapter:end:05_data_product_development.Rmd-->

# Semi-structured data {#semi_structured_data}



## Setup 


```r
# Install packages 
if (!require("pacman")) install.packages("pacman")

pacman::p_load(tidyverse, # tidyverse pkgs including purrr
               furrr, # parallel processing 
               tictoc, # performance test  
               tcltk, # GUI for choosing a dir path 
               tidyjson, # tidying JSON files 
               XML, # parsing XML
               rvest, # parsing HTML
               jsonlite, # downloading JSON file from web
               glue, # pasting string and objects
               xopen, # opepn URLs in browser 
               urltools, # regex and url parsing 
               here) # computational reproducibility

## Install the current development version from GitHub
devtools::install_github("jaeyk/tidytweetjson", dependencies = TRUE) ; library(tidytweetjson)
```

```
## Skipping install of 'tidytweetjson' from a github remote, the SHA1 (9a00ec8a) has not changed since last install.
##   Use `force = TRUE` to force installation
```

## Objectives

-   Automating the process of turning semi-structured data (input) into structured data (output)

## What is semi-structured data?

> Semi-structured data is a form of structured data that does not obey the tabular structure of data models associated with relational databases or other forms of data tables, but nonetheless contains tags or other markers to separate semantic elements and enforce hierarchies of records and fields within the data. Therefore, it is also known as a self-describing structure. - [Wikipedia](https://en.wikipedia.org/wiki/Semi-structured_data#:~:text=Semi%2Dstructured%20data%20is%20a,and%20fields%20within%20the%20data.)

-   Examples: HTML (e.g., websites), XML (e.g., government data), JSON (e.g., social media API)

Below is how JSON (tweet) looks like. 


- A tree-like structure 

- Keys and values (key: value) 
 
{
  "created_at": "Thu Apr 06 15:24:15 +0000 2017",
  "id_str": "850006245121695744",
  "text": "1\/ Today we\u2019re sharing our vision for the future of the Twitter API platform!\nhttps:\/\/t.co\/XweGngmxlP",
  "user": {
    "id": 2244994945,
    "name": "Twitter Dev",
    "screen_name": "TwitterDev",
    "location": "Internet",
    "url": "https:\/\/dev.twitter.com\/",
    "description": "Your official source for Twitter Platform news, updates & events. Need technical help? Visit https:\/\/twittercommunity.com\/ \u2328\ufe0f #TapIntoTwitter"
  }
}

-   Why should we care about semi-structured data?

    -   Because this is what the data frontier looks like: \# of unstructured data \> \# of semi-structured data \> \# of structured data
    -   There are easy and fast ways to turn semi-structured data into structured data (ideally in a tidy format) using R, Python, and command-line tools. See my own examples ([tidyethnicnews](https://github.com/jaeyk/tidyethnicnews) and [tidytweetjson](https://github.com/jaeyk/tidytweetjson)).

## Workflow

1.  Import/connect to a semi-structured file using `rvest,` `jsonlite,` `xml2,` `pdftools,` `tidyjson`, etc.

2.  Define target elements in a single file and extract them

-   [`readr`](https://readr.tidyverse.org/) package providers `parse_` functions that are useful for vector parsing.

-   [`stringr`](https://stringr.tidyverse.org/) package for string manipulations (e.g., using regular expressions in a tidy way). Quite useful for parsing PDF files (see [this example](https://themockup.blog/posts/2020-04-03-beer-and-pdftools-a-vignette/)).

-   [`rvest`](https://github.com/tidyverse/rvest) package for parsing HTML (R equivalent to `beautiful soup` in Python)

-   [`tidyjson`](https://github.com/sailthru/tidyjson) package for parsing JSON data

3.  Create a list of files (in this case URLs) to parse

4.  Write a parsing function

5.  Automate parsing process

## HTML/CSS: web scraping

Let's go back to the example we covered in the earlier chapter of the book. 


```r
url_list <- c(
  "https://en.wikipedia.org/wiki/University_of_California,_Berkeley",
  "https://en.wikipedia.org/wiki/Stanford_University",
  "https://en.wikipedia.org/wiki/Carnegie_Mellon_University",
  "https://DLAB"
)
```

* Step 1: Inspection 

Examine the Berkeley website so that we could identify a node that indicates the school's motto. If you're using Chrome, draw your interest elements, then `right click > inspect > copy full xpath.`


```r
url <- "https://en.wikipedia.org/wiki/University_of_California,_Berkeley"

download.file(url, destfile = "scraped_page.html", quiet = TRUE)

target <- read_html("scraped_page.html")

# If you want character vector output
target %>%
  html_nodes(xpath = "/html/body/div[3]/div[3]/div[5]/div[1]/table[1]") %>%
  html_text() 

# If you want table output 
target %>%
  html_nodes(xpath = "/html/body/div[3]/div[3]/div[5]/div[1]/table[1]") %>%
  html_table()
```

* Step 2: Write a function 

I highly recommend writing your function working slowly by wrapping the function with [`slowly()`](https://purrr.tidyverse.org/reference/insistently.html).


```r
get_table_from_wiki <- function(url){
  
  download.file(url, destfile = "scraped_page.html", quiet = TRUE)

  target <- read_html("scraped_page.html")
  
  table <- target %>%
    html_nodes(xpath = "/html/body/div[3]/div[3]/div[5]/div[1]/table[1]") %>%
    html_table() 
  
  return(table)
}
```

* Step 3: Test


```r
get_table_from_wiki(url_list[[2]])
```

* Step 4: Automation 


```r
map(url_list, get_table_from_wiki)
```

* Step 5: Error handling 


```r
map(url_lists, safely(get_table_from_wiki)) %>%
  map("result") %>% 
  # = map(function(x) x[["result"]]) = map(~.x[["name"]])
  purrr::compact() # Remove empty elements
```


```r
# If error occurred, "The URL is broken." will be stored in that element(s).
out <- map(
  url_list,
  possibly(get_table_from_wiki,
    otherwise = "The URL is broken."
  )
)
```

## XML/JSON: government database/social media scraping

### Governemnt database (XML) 

The following tax return data example comes from the U.S. Internal Revenue Service (IRS) Amazon database. [This PDf file](https://www.irs.gov/pub/irs-pdf/f990.pdf) shows what the original document looks like.

**Workflow**

1. Get the XML link and parse it
2. Go to the root of the XML document 
3. Identify a specific node you care about 
4. Get values related to that node 

![XML DOM (Document Object Model). Source: https://www.w3schools.com](https://www.w3schools.com/xml/nodetree.gif)

Step1: Get an XML document link


```r
xml_link <- c("http://s3.amazonaws.com/irs-form-990/201910919349301206_public.xml")
```

Step 2: Get page and parse the XML document. 


```r
xml_root <- xml_link %>%
  # Get page and parse xml 
  xmlTreeParse() %>%
  # Get root
  xmlRoot()

# Data output: list 
typeof(xml_root) 
```

```
## [1] "list"
```

```r
# Two elements. Our target is the second one.
summary(xml_root)
```

```
##              Length Class   Mode
## ReturnHeader 11     XMLNode list
## ReturnData    6     XMLNode list
```

Step 3: Get nodes 

We grab the mission statement of this org from its tax report (990). `//` is an [XPath syntax](https://www.w3schools.com/xml/xpath_syntax.asp) that helps to "select nodes in the document from the current node that matches the selection no matter where they are."


```r
xml_root %>%
  purrr::pluck(2) %>% # Second element (Return Data)
  getNodeSet("//MissionDesc") # Mission statement 
```

```
## [[1]]
## <MissionDesc>DISTRIBUTION OF LITERATURE, MUSIC, AND OTHER RELATED RESOURCES WHICH COMPLIMENT LITERATURE; SUPPORT OF MINISTRIES.</MissionDesc>
```

Step 4: Get values 


```r
xml_root %>%
  purrr::pluck(2) %>% # Second element (Return Data)
  getNodeSet("//MissionDesc") %>% # Mission statement 
  xmlValue()
```

```
## [1] "DISTRIBUTION OF LITERATURE, MUSIC, AND OTHER RELATED RESOURCES WHICH COMPLIMENT LITERATURE; SUPPORT OF MINISTRIES."
```

### Social media API (JSON)

#### Objectives

-   Learning what kind of social media data are accessible through application programming interfaces (APIs)

**Review question**

In the previous session, we learned the difference between semi-structured data and structured data. Can anyone tell us the difference between them?

#### The big picture for digital data collection

1.  Input: semi-structured data

2.  Output: structured data

3.  Process:

    -   Getting **target data** from a remote server

        -   The target data is usually massive (\>10 G.B.) by the traditional social science standard.

    -   Parsing the target data your laptop/database

        -   Laptop (sample-parse): Downsamle the large target data and parse it on your laptop. This is just one option to [deal with big data in R](https://rviews.rstudio.com/2019/07/17/3-big-data-strategies-for-r/). It's a simple strategy as it doesn't require storing target data in your database.

    -   Database (push-parse): Push the large target data to a database, then explore, select, and filter it. If you were interested in using this option, check out my [SQL for R Users](https://github.com/dlab-berkeley/sql-for-r-users) workshop.

![Sample-Parse. From RStudio.](https://rviews.rstudio.com/post/2019-07-01-3-big-data-paradigms-for-r_files/sample_model.png)

![Push-Parse. From RStudio.](https://rviews.rstudio.com/post/2019-07-01-3-big-data-paradigms-for-r_files/push_data.png)

-   But what exactly is this target data?

    -   When you scrape websites, you mostly deal with HTML (defines a structure of a website), CSS (its style), and JavaScript (its dynamic interactions).

    -   When you access social media data through API, you deal with either XML or JSON (major formats for storing and transporting data; they are light and flexible).

    -   XML and JSON have tree-like (nested; a root and branches) structures and keys and values (or elements and attributes).

    -   If HTML, CSS, and JavaScript are storefronts, then XML and JSON are warehouses.

![By Andreas Praefcke (Own work), via Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/9/97/Automatisches_Kleinteilelager.jpg)

#### Opportunities and challenges for parsing social media data

This explanation draws on Pablo Barbara's [LSE social media workshop slides](http://pablobarbera.com/social-media-workshop/social-media-slides.pdf).

**Basic information**

-   What is an API?: An interface (you can think of it as something akin to a restaurant menu. API parameters are API menu items.)

    -   [REST](https://en.wikipedia.org/wiki/Representational_state_transfer) (Representational state transfer) API: static information (e.g., user profiles, list of followers and friends)

    -   [Streaming](https://blog.axway.com/amplify/api-management/streaming-apis#:~:text=Streaming%20APIs%20are%20used%20to,a%20subset%20of%20Streaming%20APIS.) API: dynamic information (e.g, new tweets)

**Why should we care?** 

- API is the new data frontier. [ProgrammableWeb](https://www.programmableweb.com/apis/directory) shows that there are more than 24,046 APIs as of April 1, 2021.

  - Big and streaming (real-time) data 
  
  - High-dimensional data (e.g., text, image, video, etc.)
  
  - Lots of analytic opportunities (e.g., time-series, network, spatial analysis)
  
- Also, this type of data has many limitations (external validity, algorithmic bias, etc).

- Think about taking the API + approach (i.e., API not replacing but augmenting traditional data collection)

**How API works** 

Request (you form a request URL) <-> Response (API responses to your request by sending you data usually in JSON format)

![](https://mk0appinventiv4394ey.kinstacdn.com/wp-content/uploads/sites/1/2018/05/What-are-APIs-Learn-How-API-Works.jpg)

**API Statuses**

1. Twitter 

-   Twitter API is still widely accessible ([v2](https://developer.twitter.com/en/docs/twitter-api/early-access) 


  - In January 2021, Twitter introduced the [academic Twitter API](https://developer.twitter.com/en/solutions/academic-research) that allows generous access to Twitter's historical data for academic researchers 

    - Many R packages exist for the Twitter API: [rtweet](https://cran.r-project.org/web/packages/rtweet/rtweet.pdf) (REST + streaming), [tweetscores](https://github.com/pablobarbera/twitter_ideology/tree/master/pkg/tweetscores) (REST), [streamR](https://github.com/pablobarbera/streamR) (streaming)

    - Some notable limitations. If Twitter users don't share their tweets' locations (e.g., GPS), you can't collect them. 
    
> Twitter data is unique from data shared by most other social platforms because it reflects information that users *choose* to share publicly. Our API platform provides broad access to public Twitter data that users have chosen to share with the world. - Twitter Help Center

-   What does this policy mean? If Twitter users don't share their tweets' locations (e.g., GPS), you can't collect them. You can get around this problem to identify a user's location based on their self-reported profile. 

2. Other APIs

The following comments draw on Alexandra Siegel's talk on "Collecting and Analyzing Social Media Data" given at Montréal Methods Workshops. 

- [Facebook API](https://developers.facebook.com/) access has become constrained since the 2016 U.S. election.  

  - Exception: [Social Science One](https://socialscience.one/blog/unprecedented-facebook-urls-dataset-now-available-research-through-social-science-one).

  - Also, check out [Crowdtangle](https://www.crowdtangle.com/) for collecting public FB page data 
  
  - Using FB ads is still a popular method, especially among scholars studying developing countries. 
  
- [YouTube API](https://developers.google.com/youtube/v3): generous access + (computer-generated) transcript in many languages 

  - Documentation on [captions](https://developers.google.com/youtube/v3/docs/captions) from YouTube
  
- [Instragram API](https://www.instagram.com/developer/): Data from public accounts are available. 

- [Reddit API](https://www.reddit.com/dev/api/): Well-annotated text data suitable for machine learning 

**Upside**

-   Legal and well-documented.

Web scraping (Wild Wild West) \<\> API (Big Gated Garden)

-   You have legal but limited access to (growing) big data that can be divided into text, image, and video and transformed into cross-sectional (geocodes), longitudinal (timestamps), and historical event data (hashtags). See Zachary C. Steinert-Threlkeld's [2020 APSA Short Course Generating Event Data From Social Media](https://github.com/ZacharyST/APSA2020_EventDataFromSocialMedia).

-   Social media data are also well-organized, managed, and curated data. It's easy to navigate because XML and JSON have keys and values. If you find keys, you will find observations you look for.

**Downside**

1.  Rate-limited.

2.  If you want to access more and various data than those available, you need to pay for premium access.

### Next steps

- We are going to learn how to access and collect data using Twitter and New York Times API. We are going to learn this in two ways: (1) using plug-and-play packages (both using RStudio and the terminal) and (2) getting API data from scratch (`httr,` `jsonlite`).

- Before everything else, first, sign up for the Twitter developer account. If you want to know how to sign up for a new Twitter developer account and access Twitter API, see Steinert-Threlkeld's [APSA workshop slides](https://github.com/ZacharyST/APSA2020_EventDataFromSocialMedia/blob/master/Presentation/02_AccessTwitter.pdf).


### rtweet 

The `rtweet` examples draw from [Chris Bail's tutorial](https://cbail.github.io/SICSS_APIs_markdown.html). 

#### Setup 

The first thing you need to do is set up.

Assuming that you already signed up for a Twitter developer account 


```r
app_name <- "YOUR APP NAME"
consumer_key <- "YOUR CONSUMER KEY"
consumer_secret <- "YOUR CONSUMER SECRET"

rtweet::create_token(app = app_name, 
                     consumer_key = consumer_key, 
                     consumer_secret = consumer_secret)
```

#### Search API

Using **search API**; This API returns a collection of Tweets mentioning a particular query.


```r
# Install and load rtweet 
if (!require(pacman)) {install.packages("pacman")}
pacman::p_load(rtweet)
```


```r
# The past 6-9 days 
rt <- search_tweets(q = "#stopasianhate", n = 1000, include_rts = FALSE)

# The longer term 
# search_fullarchive() premium service

head(rt$text)
```

Can you guess what would be the class type of rt?


```r
class(rt)
```

What would be the number of rows?


```r
nrow(rt)
```

#### Time series analysis 

- Time series analysis 


```r
pacman::p_load(ggplot2, ggthemes, rtweet)

ts_plot(rt, "3 hours") +
  ggthemes::theme_fivethirtyeight() +
  labs(title = "Frequency of Tweets about StopAsianHate from the Past Day",
       subtitle = "Tweet counts aggregated using three-hour intervals",
       source = "Twitter's Search API via rtweet")
```

#### Geographical analysis

- Geographical analysis


```r
pacman::p_load(maps)

geocoded <- lat_lng(rt)

maps::map("state", lwd = .25) # lwd = line type 
with(geocoded, points(lng, lat))
```

### Hydrating

#### Objectives

-   Learning how hydrating works
-   Learning how to use [Twarc](https://github.com/DocNow/twarc) to communicate with Twitter's API

**Review question**

What are the main two types of Twitter's API?

#### Hydrating: An Alternative Way to Collect Historical Twitter Data

-   You can collect Twitter data using Twitter's API, or you can hydrate Tweet IDs collected by other researchers. This is an excellent resource to collect historical Twitter data.

-   [Covid-19 Twitter chatter dataset for scientic use](http://www.panacealab.org/covid19/) by Panacealab

-   [Women's March Dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/5ZVMOR) by Littman and Park

-   Harvard Dataverse has many dehydrated Tweet IDs that could be of interest to social scientists.

![Dehydrated Tweet IDs](https://github.com/jaeyk/digital_data_collection_workshop/raw/master/misc/dehydrated_tweets.png)

#### Twarc: one solution to (almost) all Twitter's API problems

-   Why Twarc?

    -   A command-line tool and Python library that works for almost every Twitter API-related problem.

    -   It's really well-documented, tested, and maintained.

        -   [Twarc documentation](https://scholarslab.github.io/learn-twarc/06-twarc-command-basics) covers basic commands.
        -   [Tward-cloud documentation](https://twarc-cloud.readthedocs.io/_/downloads/en/stable/pdf/) explains how to collect data from Twitter's API using Twarc running in [Amazon Web Services](https://aws.amazon.com/) (AWS).

    -   Twarc was developed as part of the [Documenting the Now](https://www.docnow.io/) project, which was funded by the Mellon Foundation.

![One ring that rules them all.](https://vignette.wikia.nocookie.net/lotr/images/8/8b/DOiAi2WUEAE3A1Y.0.jpg/revision/latest/scale-to-width-down/699?cb=20200305221819)

-   There's no reason to be afraid of using a command-line tool and Python library, even though you primarily use R. It's easy to embed [Python code](https://bookdown.org/yihui/rmarkdown/language-engines.html#python) and [shell scripts](https://bookdown.org/yihui/rmarkdown/language-engines.html#shell-scripts) in R Markdown.

-   Even though you don't know how to write Python code or shell scripts, it's handy to learn how to integrate them into your R workflow.

-   I assume that you have already installed [Python 3](https://www.python.org/download/releases/3.0/).


```bash
pip3 install twarc
```

##### Applications

The following examples are created by [the University of Virginia library](http://digitalcollecting.lib.virginia.edu/toolkit/docs/social-media/twarc-commands/).

###### Search

-   Download pre-existing tweets (7-day window) matching certain conditions

-   In command-line, `>` = Create a file

-   I recommend running the following commands in the terminal because it's more stable than doing so in R Markdown.

![You can type commands in the Terminal in R Studio.](https://github.com/jaeyk/digital_data_collection_workshop/raw/master/misc/terminal.png)


```bash
# Key word 
twarc search blacklivesmatter > blm_tweets.jsonl
```


```bash
# Hashtag 
twarc search '#blacklivesmatter' > blm_tweets_hash.jsonl
```


```bash
# Hashtag + Language 
twarc search '#blacklivesmatter' --lang en > blm_tweets_hash.jsonl
```

-   It is really important to **save these tweets into a `jsonl` format;** `jsonl` extension refers to JSON **Lines** files. This structure is useful for splitting JSON data into smaller chunks if it is too large.

###### Filter

-   Download tweets meeting certain conditions as they happen.


```bash
# Key word
twarc filter blacklivesmatter > blm_tweets.jsonl
```

###### Sample

-   Use Twitter's random sample of recent tweets.


```bash
twarc sample > tweets.jsonl 
```

###### Hydrate

-   Tweet I.D.s -\> Tweets


```bash
twarc hydrate tweet_ids.txt > tweets.jsonl 
```

###### Dehydrate

-   Hydrate \<\> Dehydrate
-   Tweets -\> Tweet I.D.s


```bash
twarc dehydrate tweets.jsonl > tweet_ids.txt
```

**Challenge**

1.  Collect tweets that contain some keywords of your choice using `twarc search` and save them as `tweets.jsonl`.

2.  Using `less` command in the terminal, inspect `twarc.log.`

3.  Using `less` command in the terminal, inspect `tweets.json.`

### Parsing JSON

#### Objectives

-   Learning chunk and pull strategy
-   Learning how `tidyjson` works
-   Learning how to apply `tidyjson` to tweets

#### Chunk and Pull

##### Problem

-   What if the size of the Twitter data you downloaded is too big (e.g., \>10 GB) to do complex wrangling in R?

##### Solution

![Chunk and Pull. From Studio.](https://rviews.rstudio.com/post/2019-07-01-3-big-data-paradigms-for-r_files/chunk_pull.png)

Step1: Split the large JSON file in small chunks.


```bash
#Divide the JSON file by 100 lines (tweets)

# Linux and Windows (in Bash)
$ split -100 search.jsonl

# macOS
$ gsplit -100 search.jsonl
```

-   After that, you will see several files appeared in the directory. Each of these files should have 100 tweets or fewer. All of these file names **should start with "x," as in "xaa."**

Step 2: Apply the parsing function to each chunk and pull all of these chunks together.


```r
# You need to choose a Tweet JSON file
filepath <- file.choose()

# Assign the parsed result to the `df` object
# 11.28 sec elapsed to parse 17,928 tweets 
tic()
df <- jsonl_to_df(filepath)
toc()
```


```r
# Setup 
n_cores <- availableCores() - 1

n_cores # This number depends on your computer spec.

plan(multiprocess, # multicore, if supported, otherwise multisession
     workers = n_cores) # the maximum number of workers

# You need to designate a directory path where you saved the list of JSON files.

# 9.385 sec elapsed to parse 17,928 tweets 

dirpath <- tcltk::tk_choose.dir()

tic()
df_all <- tidytweetjson::jsonl_to_df_all(dirpath)
toc()
```

##### tidyjson

The [`tidyjson`](https://cran.r-project.org/web/packages/tidyjson/vignettes/introduction-to-tidyjson.html) package helps to use tidyverse framework to JSON data.

-   toy example


```r
# JSON collection; nested structure + keys and values 
worldbank[1]
```

```
## [1] "{\"_id\":{\"$oid\":\"52b213b38594d8a2be17c780\"},\"boardapprovaldate\":\"2013-11-12T00:00:00Z\",\"closingdate\":\"2018-07-07T00:00:00Z\",\"countryshortname\":\"Ethiopia\",\"majorsector_percent\":[{\"Name\":\"Education\",\"Percent\":46},{\"Name\":\"Education\",\"Percent\":26},{\"Name\":\"Public Administration, Law, and Justice\",\"Percent\":16},{\"Name\":\"Education\",\"Percent\":12}],\"project_name\":\"Ethiopia General Education Quality Improvement Project II\",\"regionname\":\"Africa\",\"totalamt\":130000000}"
```

```r
# Check out keys (objects)
worldbank %>% 
  as.tbl_json() %>%
  gather_object() %>%
  filter(document.id == 1)
```

```
## # A tbl_json: 8 x 3 tibble with a "JSON" attribute
##   ..JSON                  document.id name               
##   <chr>                         <int> <chr>              
## 1 "{\"$oid\":\"52b213..."           1 _id                
## 2 "\"2013-11-12T00:..."             1 boardapprovaldate  
## 3 "\"2018-07-07T00:..."             1 closingdate        
## 4 "\"Ethiopia\""                    1 countryshortname   
## 5 "[{\"Name\":\"Educa..."           1 majorsector_percent
## 6 "\"Ethiopia Gener..."             1 project_name       
## 7 "\"Africa\""                      1 regionname         
## 8 "130000000"                       1 totalamt
```


```r
# Get the values associated with the keys 
worldbank %>% 
  as.tbl_json() %>% # Turn JSON into tbl_json object 
  enter_object("project_name") %>% # Enter the objects 
  append_values_string() %>% # Append the values 
  as_tibble() # To reduce the size of the file 
```

```
## # A tibble: 500 x 2
##    document.id string                                                           
##          <int> <chr>                                                            
##  1           1 Ethiopia General Education Quality Improvement Project II        
##  2           2 TN: DTF Social Protection Reforms Support                        
##  3           3 Tuvalu Aviation Investment Project - Additional Financing        
##  4           4 Gov't and Civil Society Organization Partnership                 
##  5           5 Second Private Sector Competitiveness and Economic Diversificati~
##  6           6 Additional Financing for Cash Transfers for Orphans and Vulnerab~
##  7           7 National Highways Interconnectivity Improvement Project          
##  8           8 China Renewable Energy Scale-Up Program Phase II                 
##  9           9 Rajasthan Road Sector Modernization Project                      
## 10          10 MA Accountability and Transparency DPL                           
## # ... with 490 more rows
```

-   The following example draws on my [tidytweetjson](https://github.com/jaeyk/tidytweetjson) R package. The package applies `tidyjson` to Tweets.

###### Individual file


```r
jsonl_to_df <- function(file_path){

# Save file name 

file_name <- strsplit(x = file_path, 
                     split = "[/]") 

file_name <- file_name[[1]][length(file_name[[1]])]

# Import a Tweet JSON file

listed <- read_json(file_path, format = c("jsonl"))

# IDs of the tweets with country codes

ccodes <- listed %>%
  enter_object("place") %>%
  enter_object("country_code") %>%
  append_values_string() %>%
  as_tibble() %>%
  rename("country_code" = "string")

# IDs of the tweets with location

locations <- listed %>%
  enter_object("user") %>%
  enter_object("location") %>%
  append_values_string() %>%
  as_tibble() %>%
  rename(location = "string")

# Extract other key elements from the JSON file

df <- listed %>%
  spread_values(
    id = jnumber("id"),
    created_at = jstring("created_at"),
    full_text = jstring("full_text"),
    retweet_count = jnumber("retweet_count"),
    favorite_count = jnumber("favorite_count"),
    user.followers_count = jnumber("user.followers_count"),
    user.friends_count = jnumber("user.friends_count")
  ) %>%
	  as_tibble

message(paste("Parsing", file_name, "done."))

# Full join
outcome <- full_join(ccodes, df) %>% full_join(locations)

# Or you can write this way: outcome <- reduce(list(df, ccodes, locations), full_join)

# Select
outcome %>% select(-c("document.id"))}
```

###### Many files

-   Set up parallel processing.


```r
n_cores <- availableCores() - 1

n_cores # This number depends on your computer spec.

plan(multiprocess, # multicore, if supported, otherwise multisession
     workers = n_cores) # the maximum number of workers
```

-   Parsing in parallel.

**Review**

There are at least three ways you can use function + `purrr::map().`


```r
squared <- function(x){
  x*2 
}

# Named function 
map(1:3, squared)

# Anonymous function 
map(1:3, function(x){ x *2 })

# Using formula; ~ = formula, .x = input 
map(1:3,~.x*2)
```


```r
# Create a list of file paths 
filename <- list.files(dir_path,
          pattern = '^x',
          full.names = TRUE)

df <- filename %>%

# Apply jsonl_to_df function to items on the list
future_map(~jsonl_to_df(.)) %>%

# Full join the list of dataframes
reduce(full_join,
       by = c("id",
              "location",
              "country_code",
              "created_at",
              "full_text",
              "retweet_count",
              "favorite_count",
              "user.followers_count",
              "user.friends_count"))

# Output
df
```

**rtweet and twarc**

- The main difference is using RStudio vs. the terminal. 

- The difference matters when your data size is large. Suppose the size of the Twitter data you downloaded is 10 GB. R/RStudio might have a hard time dealing with this size of data. Then, how can you wrangle this size of data in a complex way using R?

### Getting API data from scratch 

Load packages. For the connection interface, don't use `RCurl,` but I strongly recommend using `httr.` The following code examples draw from my R interface for the New York Times API called [`rnytapi`](https://jaeyk.github.io/rnytapi/).


```r
pacman::p_load(httr, jsonlite, purrr, glue)
```

#### Form REQUEST 


```r
get_request <- function(term, begin_date, end_date, key, page = 1) {

    out <- GET("http://api.nytimes.com/svc/search/v2/articlesearch.json",
        query = list('q' = term,
                     'begin_date' = begin_date,
                     'end_date' = end_date,
                     'api-key' = key,
                     'page' = page))

    return(out)

}
```

#### Extract data 


```r
get_content <- function(term, begin_date, end_date, key, page = 1) {

    message(glue("Scraping page {page}"))

    fromJSON(content(get_request(term, begin_date, end_date, key, page),
                     "text",
                encoding = "UTF-8"),
                simplifyDataFrame = TRUE, flatten = TRUE) %>% as.data.frame()

}
```

#### Automating iterations 


```r
extract_all <- function(term, begin_date, end_date, key) {

    request <- GET("http://api.nytimes.com/svc/search/v2/articlesearch.json",
                   query = list('q' = term,
                                'begin_date' = begin_date,
                                'end_date' = end_date,
                                'api-key' = key))

    max_pages <- (round(content(request)$response$meta$hits[1] / 10) - 1)

    message(glue("The total number of pages is {max_pages}"))

    iter <- 0:max_pages

    arg_list <- list(rep(term, times = length(iter)),
                     rep(begin_date, times = length(iter)),
                     rep(end_date, times = length(iter)),
                     rep(key, times = length(iter)),
                     iter
                     )

    out <- pmap_dfr(arg_list, slowly(get_content,
                                     # 6 seconds sleep is the default requirement.
                                     rate = rate_delay(
                                         pause = 6,
                                         max_times = 4000)))

    return(out)

    }
```

<!--chapter:end:06_semi_structured_data.Rmd-->

# High-dimensional data {#machine_learning}



## Overview 

- The rise of high-dimensional data. The new data frontiers in social sciences---text ([Gentzkow et al. 2019](https://web.stanford.edu/~gentzkow/research/text-as-data.pdf); [Grimmer and Stewart 2013](https://www.jstor.org/stable/pdf/24572662.pdf?casa_token=SQdSI4R_VdwAAAAA:4QiVLhCXqr9f0qNMM9U75EL5JbDxxnXxUxyIfDf0U8ZzQx9szc0xVqaU6DXG4nHyZiNkvcwGlgD6H0Lxj3y0ULHwgkf1MZt8-9TPVtkEH9I4AHgbTg)) and and image ([Joo and Steinert-Threlkeld 2018](https://arxiv.org/pdf/1810.01544))---are all high-dimensional data. 

    - 1000 common English words for 30-word tweets: $1000^{30}$ similar to N of atoms in the universe ([Gentzkow et al. 2019](https://web.stanford.edu/~gentzkow/research/text-as-data.pdf))

    - Belloni, Alexandre, Victor Chernozhukov, and Christian Hansen. ["High-dimensional methods and inference on structural and treatment effects."](https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.28.2.29) *Journal of Economic Perspectives 28*, no. 2 (2014): 29-50.

- The rise of the new approach: statistics + computer science = machine learning 

- Statistical inference 

    - $y$ <- some probability models (e.g., linear regression, logistic regression) <- $x$
       
    - $y$ = $X\beta$ + $\epsilon$
        
    - The goal is to estimate $\beta$

- Machine learning 

    - $y$ <- unknown <- $x$ 
    
    - $y$ <-> decision trees, neutral nets <-> $x$
        
    - For the main idea behind prediction modeling, see Breiman, Leo (Berkeley stat faculty who passed away in 2005). ["Statistical modeling: The two cultures (with comments and a rejoinder by the author)."](https://projecteuclid.org/euclid.ss/1009213726) *Statistical science* 16, no. 3 (2001): 199-231.
    
    - "The problem is to find an algorithm $f(x)$ such that for future $x$ in a test set, $f(x)$ will be a good predictor of $y$."
    
    - "There are **two cultures** in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a **given** **stochastic data model**. The other uses **algorithmic models** and treats the data mechanism as **unknown**."


- How ML differs from econometrics? 

- A review by Athey, Susan, and Guido W. Imbens. ["Machine learning methods that economists should know about."](https://www.annualreviews.org/doi/full/10.1146/annurev-economics-080217-053433) *Annual Review of Economics* 11 (2019): 685-725.
        
- Stat:
  
    - Specifying a target (i.e., an estimand)

    - Fitting a model to data using an objective function (e.g., the sum of squared errors)

    - Reporting point estimates (effect size) and standard errors (uncertainty)

    - Validation by yes-no using goodness-of-fit tests and residual examination

- ML: 

    - Developing algorithms (estimating *f(x)*)

    - Prediction power, not structural/causal parameters

    - Basically, high-dimensional data statistics (N < P)

    - The major problem is to avoid ["the curse of dimensionality"](https://en.wikipedia.org/wiki/Curse_of_dimensionality) ([too many features - > overfitting](https://towardsdatascience.com/the-curse-of-dimensionality-50dc6e49aa1e))

    - Validation: out-of-sample comparisons (cross-validation) not in-sample goodness-of-fit measures

    - So, it's curve-fitting, but the primary focus is unseen (test data), not seen data (training data)

- A quick review on ML lingos for those trained in econometrics 

    - Sample to estimate parameters = Training sample
  
    - Estimating the model = Being trained 
    
    - Regressors, covariates, or predictors = Features 
  
    - Regression parameters = weights 
  
    - Prediction problems = Supervised (some $y$ are known) + Unsupervised ($y$ unknown)
    
![How to teach machines. Based on [vas3k blog](https://vas3k.com/blog/machine_learning/). Many images in this chapter come from vas3k blog.](https://i.vas3k.ru/7w9.jpg)

![The main types of machine learning. Based on [vas3k blog](https://vas3k.com/blog/machine_learning/)](https://i.vas3k.ru/7vz.jpg)

![The map of the machine learning universe. Based on [vas3k blog](https://vas3k.com/blog/machine_learning/)](https://i.vas3k.ru/7vx.jpg)

![Classical machine learning. Based on [vas3k blog](https://vas3k.com/blog/machine_learning/)](https://i.vas3k.ru/7w1.jpg)

## Dataset  

- [Heart disease data from UCI](https://archive.ics.uci.edu/ml/datasets/heart+Disease)

- One of the popular datasets used in machine learning competitions 


```r
# Load packages

## CRAN packages
pacman::p_load(
  here,
  tidyverse,
  tidymodels,
  doParallel, # parallel processing
  patchwork, # arranging ggplots
  remotes,
  SuperLearner,
  vip,
  tidymodels,
  glmnet,
  xgboost,
  rpart,
  ranger,
  conflicted
)

remotes::install_github("ck37/ck37r")
```

```
## Skipping install of 'ck37r' from a github remote, the SHA1 (87085fff) has not changed since last install.
##   Use `force = TRUE` to force installation
```

```r
conflicted::conflict_prefer("filter", "dplyr")
```

```
## [conflicted] Will prefer dplyr::filter over any other package
```



```r
## Jae's custom functions
source(here("functions", "ml_utils.r"))

# Import the dataset

data_original <- read_csv(here("data", "heart.csv"))
```

```
## Rows: 303 Columns: 14
```

```
## -- Column specification -----------------------------------------------------------------------
## Delimiter: ","
## dbl (14): age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpea...
```

```
## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
```

```r
glimpse(data_original)
```

```
## Rows: 303
## Columns: 14
## $ age      <dbl> 63, 37, 41, 56, 57, 57, 56, 44, 52, 57, 54, 48, 49, 64, 58, 5~
## $ sex      <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1~
## $ cp       <dbl> 3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 3, 3, 2, 2, 3, 0, 3, 0~
## $ trestbps <dbl> 145, 130, 130, 120, 120, 140, 140, 120, 172, 150, 140, 130, 1~
## $ chol     <dbl> 233, 250, 204, 236, 354, 192, 294, 263, 199, 168, 239, 275, 2~
## $ fbs      <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0~
## $ restecg  <dbl> 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1~
## $ thalach  <dbl> 150, 187, 172, 178, 163, 148, 153, 173, 162, 174, 160, 139, 1~
## $ exang    <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0~
## $ oldpeak  <dbl> 2.3, 3.5, 1.4, 0.8, 0.6, 0.4, 1.3, 0.0, 0.5, 1.6, 1.2, 0.2, 0~
## $ slope    <dbl> 0, 0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 1~
## $ ca       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0~
## $ thal     <dbl> 1, 2, 2, 2, 2, 1, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3~
## $ target   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~
```

```r
# Createa a copy
data <- data_original

theme_set(theme_minimal())
```

## Workflow 

- 1. Preprocessing
- 2. Model building
- 3. Model fitting
- 4. Model evaluation
- 5. Model tuning
- 6. Prediction

## tidymodels 

- Like `tidyverse`, `tidymodels` is a collection of packages.

    - [`rsample`](https://rsample.tidymodels.org/): for data splitting 
    
    - [`recipes`](https://recipes.tidymodels.org/index.html): for pre-processing
    
    - [`parsnip`](https://www.tidyverse.org/blog/2018/11/parsnip-0-0-1/): for model building 
    
        - [`tune`](https://github.com/tidymodels/tune): hyperparameter tuning 
    
    - [`yardstick`](https://github.com/tidymodels/yardstick): for model evaluations 
    
    - [`workflows`](https://github.com/tidymodels/workflows): for bundling a pieplne that bundles together preprocessing, modeling, and post-processing requests 
    
- Why taking a tidyverse approach to machine learning?

- Benefits 

    - Readable code 
    
    - Reusable data structures 
    
    - Extendable code

![Tidymodels. From RStudio.](https://rviews.rstudio.com/post/2019-06-14-a-gentle-intro-to-tidymodels_files/figure-html/ds.png)

> tidymodels are an **integrated, modular, extensible** set of packages that implement a framework that facilitates creating predicative stochastic models. - Joseph Rickert@RStudio

- Currently, 238 models are [available](https://topepo.github.io/caret/available-models.html) 

- The following materials are based on [the machine learning with tidymodels workshop](https://github.com/dlab-berkeley/Machine-Learning-with-tidymodels) I developed for D-Lab. [The original workshop](https://github.com/dlab-berkeley/Machine-Learning-in-R) was designed by [Chris Kennedy](https://ck37.com/) and [Evan Muzzall](https://dlab.berkeley.edu/people/evan-muzzall.

## Pre-processing

- [`recipes`](https://recipes.tidymodels.org/index.html): for pre-processing

- [`textrecipes`](https://github.com/tidymodels/textrecipes) for text pre-processing

- Step 1: `recipe()` defines target and predictor variables (ingredients).

- Step 2: `step_*()` defines preprocessing steps to be taken (recipe).

    The preprocessing steps list draws on the vignette of the [`parsnip`](https://www.tidymodels.org/find/parsnip/) package.

    - dummy: Also called one-hot encoding

    - zero variance: Removing columns (or features) with a single unique value  

    - impute: Imputing missing values

    - decorrelate: Mitigating correlated predictors (e.g., principal component analysis)

    - normalize: Centering and/or scaling predictors (e.g., log scaling). Scaling matters because many algorithms (e.g., lasso) are scale-variant (except tree-based algorithms). Remind you that normalization (sensitive to outliers) = $\frac{X - X_{min}}{X_{max} - X_{min}}$ and standardization (not sensitive to outliers) = $\frac{X - \mu}{\sigma}$

    - transform: Making predictors symmetric 

- Step 3: `prep()` prepares a dataset to base each step on.

- Step 4: `bake()` applies the preprocessing steps to your datasets. 

In this course, we focus on two preprocessing tasks. 

- One-hot encoding (creating dummy/indicator variables)


```r
# Turn selected numeric variables into factor variables
data <- data %>%
  dplyr::mutate(across(c("sex", "ca", "cp", "slope", "thal"), as.factor))

glimpse(data)
```

```
## Rows: 303
## Columns: 14
## $ age      <dbl> 63, 37, 41, 56, 57, 57, 56, 44, 52, 57, 54, 48, 49, 64, 58, 5~
## $ sex      <fct> 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1~
## $ cp       <fct> 3, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 1, 3, 3, 2, 2, 3, 0, 3, 0~
## $ trestbps <dbl> 145, 130, 130, 120, 120, 140, 140, 120, 172, 150, 140, 130, 1~
## $ chol     <dbl> 233, 250, 204, 236, 354, 192, 294, 263, 199, 168, 239, 275, 2~
## $ fbs      <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0~
## $ restecg  <dbl> 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1~
## $ thalach  <dbl> 150, 187, 172, 178, 163, 148, 153, 173, 162, 174, 160, 139, 1~
## $ exang    <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0~
## $ oldpeak  <dbl> 2.3, 3.5, 1.4, 0.8, 0.6, 0.4, 1.3, 0.0, 0.5, 1.6, 1.2, 0.2, 0~
## $ slope    <fct> 0, 0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 1~
## $ ca       <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0~
## $ thal     <fct> 1, 2, 2, 2, 2, 1, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3~
## $ target   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~
```
- Imputation 


```r
# Check missing values

map_df(data, ~ is.na(.) %>% sum())
```

```
## # A tibble: 1 x 14
##     age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak slope
##   <int> <int> <int>    <int> <int> <int>   <int>   <int> <int>   <int> <int>
## 1     0     0     0        0     0     0       0       0     0       0     0
## # ... with 3 more variables: ca <int>, thal <int>, target <int>
```

```r
# Add missing values

data$oldpeak[sample(seq(data), size = 10)] <- NA

# Check missing values

# Check the number of missing values
data %>%
  map_df(~ is.na(.) %>% sum())
```

```
## # A tibble: 1 x 14
##     age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak slope
##   <int> <int> <int>    <int> <int> <int>   <int>   <int> <int>   <int> <int>
## 1     0     0     0        0     0     0       0       0     0      10     0
## # ... with 3 more variables: ca <int>, thal <int>, target <int>
```

```r
# Check the rate of missing values
data %>%
  map_df(~ is.na(.) %>% mean())
```

```
## # A tibble: 1 x 14
##     age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak slope
##   <dbl> <dbl> <dbl>    <dbl> <dbl> <dbl>   <dbl>   <dbl> <dbl>   <dbl> <dbl>
## 1     0     0     0        0     0     0       0       0     0  0.0330     0
## # ... with 3 more variables: ca <dbl>, thal <dbl>, target <dbl>
```
 
### Regression setup 

#### Outcome variable 


```r
# Continuous variable
data$age %>% class()
```

```
## [1] "numeric"
```
#### Data splitting using random sampling 


```r
# for reproducibility
set.seed(1234)

# split
split_reg <- initial_split(data, prop = 0.7)

# training set
raw_train_x_reg <- training(split_reg)

# test set
raw_test_x_reg <- testing(split_reg)
```

#### recipe 


```r
# Regression recipe
rec_reg <- raw_train_x_reg %>%
  # Define the outcome variable
  recipe(age ~ .) %>%
  # Median impute oldpeak column
  step_medianimpute(oldpeak) %>%
  # Expand "sex", "ca", "cp", "slope", and "thal" features out into dummy variables (indicators).
  step_dummy(c("sex", "ca", "cp", "slope", "thal"))
```

```
## Warning: `step_medianimpute()` was deprecated in recipes 0.1.16.
## Please use `step_impute_median()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.
```

```r
# Prepare a dataset to base each step on
prep_reg <- rec_reg %>% prep(retain = TRUE)
```


```r
# x features
train_x_reg <- juice(prep_reg, all_predictors())

test_x_reg <- bake(
  object = prep_reg,
  new_data = raw_test_x_reg, all_predictors()
)

# y variables
train_y_reg <- juice(prep_reg, all_outcomes())$age %>% as.numeric()
test_y_reg <- bake(prep_reg, raw_test_x_reg, all_outcomes())$age %>% as.numeric()

# Checks
names(train_x_reg) # Make sure there's no age variable!
```

```
##  [1] "trestbps" "chol"     "fbs"      "restecg"  "thalach"  "exang"   
##  [7] "oldpeak"  "target"   "sex_X1"   "ca_X1"    "ca_X2"    "ca_X3"   
## [13] "ca_X4"    "cp_X1"    "cp_X2"    "cp_X3"    "slope_X1" "slope_X2"
## [19] "thal_X1"  "thal_X2"  "thal_X3"
```

```r
class(train_y_reg) # Make sure this is a continuous variable!
```

```
## [1] "numeric"
```
- Note that other imputation methods are also available. 


```r
grep("impute", ls("package:recipes"), value = TRUE)
```

```
##  [1] "step_bagimpute"     "step_impute_bag"    "step_impute_knn"   
##  [4] "step_impute_linear" "step_impute_lower"  "step_impute_mean"  
##  [7] "step_impute_median" "step_impute_mode"   "step_impute_roll"  
## [10] "step_knnimpute"     "step_lowerimpute"   "step_meanimpute"   
## [13] "step_medianimpute"  "step_modeimpute"    "step_rollimpute"
```

- You can also create your own `step_` functions. For more information, see [tidymodels.org](https://www.tidymodels.org/learn/develop/recipes/).

### Classification setup 

#### Outcome variable 


```r
data$target %>% class()
```

```
## [1] "numeric"
```

```r
data$target <- as.factor(data$target)

data$target %>% class()
```

```
## [1] "factor"
```

#### Data splitting using stratified random sampling


```r
# split
split_class <- initial_split(data %>%
  mutate(target = as.factor(target)),
prop = 0.7,
strata = target
)

# training set
raw_train_x_class <- training(split_class)

# testing set
raw_test_x_class <- testing(split_class)
```

#### recipe 


```r
# Classification recipe
rec_class <- raw_train_x_class %>%
  # Define the outcome variable
  recipe(target ~ .) %>%
  # Median impute oldpeak column
  step_medianimpute(oldpeak) %>%
  # Expand "sex", "ca", "cp", "slope", and "thal" features out into dummy variables (indicators).
  step_normalize(age) %>%
  step_dummy(c("sex", "ca", "cp", "slope", "thal"))

# Prepare a dataset to base each step on
prep_class <- rec_class %>% prep(retain = TRUE)
```


```r
# x features
train_x_class <- juice(prep_class, all_predictors())
test_x_class <- bake(prep_class, raw_test_x_class, all_predictors())

# y variables
train_y_class <- juice(prep_class, all_outcomes())$target %>% as.factor()
test_y_class <- bake(prep_class, raw_test_x_class, all_outcomes())$target %>% as.factor()

# Checks
names(train_x_class) # Make sure there's no target variable!
```

```
##  [1] "age"      "trestbps" "chol"     "fbs"      "restecg"  "thalach" 
##  [7] "exang"    "oldpeak"  "sex_X1"   "ca_X1"    "ca_X2"    "ca_X3"   
## [13] "ca_X4"    "cp_X1"    "cp_X2"    "cp_X3"    "slope_X1" "slope_X2"
## [19] "thal_X1"  "thal_X2"  "thal_X3"
```

```r
class(train_y_class) # Make sure this is a factor variable!
```

```
## [1] "factor"
```

## Supervised learning

x -> f - > y (defined)

### OLS and Lasso

#### parsnip 

- Build models (`parsnip`)

1. Specify a model 
2. Specify an engine 
3. Specify a mode 


```r
# OLS spec
ols_spec <- linear_reg() %>% # Specify a model
  set_engine("lm") %>% # Specify an engine: lm, glmnet, stan, keras, spark
  set_mode("regression") # Declare a mode: regression or classification
```

![Source: http://ethen8181.github.io](http://ethen8181.github.io/machine-learning/regularization/images/lasso_ridge_coefficients.png)

Lasso is one of the regularization techniques along with ridge and elastic-net. 


```r
# Lasso spec
lasso_spec <- linear_reg(
  penalty = 0.1, # tuning hyperparameter
  mixture = 1
) %>% # 1 = lasso, 0 = ridge
  set_engine("glmnet") %>%
  set_mode("regression")

# If you don't understand parsnip arguments
lasso_spec %>% translate() # See the documentation
```

```
## Linear Regression Model Specification (regression)
## 
## Main Arguments:
##   penalty = 0.1
##   mixture = 1
## 
## Computational engine: glmnet 
## 
## Model fit template:
## glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), 
##     alpha = 1, family = "gaussian")
```

- Fit models 


```r
ols_fit <- ols_spec %>%
  fit_xy(x = train_x_reg, y = train_y_reg)
# fit(train_y_reg ~ ., train_x_reg) # When you data are not preprocessed

lasso_fit <- lasso_spec %>%
  fit_xy(x = train_x_reg, y = train_y_reg)
```

#### yardstick 

- Visualize model fits 


```r
map2(list(ols_fit, lasso_fit), c("OLS", "Lasso"), visualize_fit)
```

```
## [[1]]
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-19-1.pdf)<!-- --> 

```
## 
## [[2]]
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-19-2.pdf)<!-- --> 


```r
# Define performance metrics
metrics <- yardstick::metric_set(rmse, mae, rsq)

# Evaluate many models
evals <- purrr::map(list(ols_fit, lasso_fit), evaluate_reg) %>%
  reduce(bind_rows) %>%
  mutate(type = rep(c("OLS", "Lasso"), each = 3))

# Visualize the test results
evals %>%
  ggplot(aes(x = fct_reorder(type, .estimate), y = .estimate)) +
  geom_point() +
  labs(
    x = "Model",
    y = "Estimate"
  ) +
  facet_wrap(~ glue("{toupper(.metric)}"), scales = "free_y")
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-20-1.pdf)<!-- --> 
- For more information, read [Tidy Modeling with R](https://www.tmwr.org/) by Max Kuhn and Julia Silge.

#### tune 

**Hyper**parameters are parameters that control the learning process.

##### tune ingredients 

-   Search space for hyperparameters

1. Grid search: a grid of hyperparameters 

2. Random search: random sample points from a bounded domain

![](https://www.programmersought.com/images/523/7e44435f20fe514c11ca0d930af8547b.png)


```r
# tune() = placeholder

tune_spec <- linear_reg(
  penalty = tune(), # tuning hyperparameter
  mixture = 1
) %>% # 1 = lasso, 0 = ridge
  set_engine("glmnet") %>%
  set_mode("regression")

tune_spec
```

```
## Linear Regression Model Specification (regression)
## 
## Main Arguments:
##   penalty = tune()
##   mixture = 1
## 
## Computational engine: glmnet
```

```r
# penalty() searches 50 possible combinations

lambda_grid <- grid_regular(penalty(), levels = 50)
```

![Source: Kaggle](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F4788946%2F82b5a41b6693a313b246f02d79e972d5%2FK%20FOLD.png?generation=1608195745131795&alt=media)


```r
# 10-fold cross-validation

set.seed(1234) # for reproducibility

rec_folds <- vfold_cv(train_x_reg %>% bind_cols(tibble(age = train_y_reg)))
```

##### Add these elements to a workflow 


```r
# Workflow
rec_wf <- workflow() %>%
  add_model(tune_spec) %>%
  add_formula(age ~ .)
```


```r
# Tuning results
rec_res <- rec_wf %>%
  tune_grid(
    resamples = rec_folds,
    grid = lambda_grid
  )
```

##### Visualize 


```r
# Visualize

rec_res %>%
  collect_metrics() %>%
  ggplot(aes(penalty, mean, col = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.3
  ) +
  geom_line(size = 2) +
  scale_x_log10() +
  labs(x = "log(lambda)") +
  facet_wrap(~ glue("{toupper(.metric)}"),
    scales = "free",
    nrow = 2
  ) +
  theme(legend.position = "none")
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-25-1.pdf)<!-- --> 

##### Select 


```r
conflict_prefer("filter", "dplyr")
```

```
## [conflicted] Removing existing preference
```

```
## [conflicted] Will prefer dplyr::filter over any other package
```

```r
top_rmse <- show_best(rec_res, metric = "rmse")

best_rmse <- select_best(rec_res, metric = "rmse")

best_rmse
```

```
## # A tibble: 1 x 2
##   penalty .config              
##     <dbl> <chr>                
## 1   0.391 Preprocessor1_Model48
```

```r
glue('The RMSE of the intiail model is
     {evals %>%
  filter(type == "Lasso", .metric == "rmse") %>%
  select(.estimate) %>%
  round(2)}')
```

```
## The RMSE of the intiail model is
##    7.82
```

```r
glue('The RMSE of the tuned model is {rec_res %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  arrange(mean) %>%
  dplyr::slice(1) %>%
  select(mean) %>%
  round(2)}')
```

```
## The RMSE of the tuned model is 7.55
```

- Finalize your workflow and visualize [variable importance](https://koalaverse.github.io/vip/articles/vip.html)


```r
finalize_lasso <- rec_wf %>%
  finalize_workflow(best_rmse)

finalize_lasso %>%
  fit(train_x_reg %>% bind_cols(tibble(age = train_y_reg))) %>%
  pull_workflow_fit() %>%
  vip::vip()
```

```
## Warning: `pull_workflow_fit()` was deprecated in workflows 0.2.3.
## Please use `extract_fit_parsnip()` instead.
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-27-1.pdf)<!-- --> 

##### Test fit 

- Apply the tuned model to the test dataset 


```r
test_fit <- finalize_lasso %>%
  fit(test_x_reg %>% bind_cols(tibble(age = test_y_reg)))

evaluate_reg(test_fit)
```

```
## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   <chr>   <chr>          <dbl>
## 1 rmse    standard       7.06 
## 2 mae     standard       5.80 
## 3 rsq     standard       0.407
```

### Decision tree 

#### parsnip 

- Build a model 

1. Specify a model 
2. Specify an engine 
3. Specify a mode 


```r
# workflow
tree_wf <- workflow() %>% add_formula(target ~ .)

# spec
tree_spec <- decision_tree(

  # Mode
  mode = "classification",

  # Tuning hyperparameters
  cost_complexity = NULL,
  tree_depth = NULL
) %>%
  set_engine("rpart") # rpart, c5.0, spark

tree_wf <- tree_wf %>% add_model(tree_spec)
```

- Fit a model


```r
tree_fit <- tree_wf %>% fit(train_x_class %>% bind_cols(tibble(target = train_y_class)))
```

#### yardstick 

- Let's formally test prediction performance. 

1.  Confusion matrix

A confusion matrix is often used to describe the performance of a classification model. The below example is based on a binary classification model.

|                 | Predicted: YES      | Predicted: NO       |
|-----------------|---------------------|---------------------|
| **Actual: YES** | True positive (TP)  | False negative (FN) |
| **Actual: NO**  | False positive (FP) | True negative (TN)  |

2.  Metrics

-   `accuracy`: The proportion of the data predicted correctly ($\frac{TP + TN}{total}$). 1 - accuracy = misclassification rate.

-   `precision`: Positive predictive value. *When the model predicts yes, how correct is it?* ($\frac{TP}{TP + FP}$)

-   `recall` (sensitivity): True positive rate (e.g., healthy people healthy). *When the actual value is yes, how often does the model predict yes?* ($\frac{TP}{TP + FN}$)

-   `F-score`: A weighted average between precision and recall. 

-   `ROC Curve` (receiver operating characteristic curve): a plot that shows the relationship between true and false positive rates at different classification thresholds. y-axis indicates the true positive rate and x-axis indicates the false positive rate. What matters is the AUC (Area under the ROC Curve), which is a cumulative probability function of ranking a random "positive" - "negative" pair (for the probability of AUC, see [this blog post](https://www.alexejgossmann.com/auc/)).

![Source: Google Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/images/ROCCurve.svg)

-   To learn more about other metrics, check out the yardstick package [references](https://yardstick.tidymodels.org/reference/index.html).


```r
# Define performance metrics

metrics <- yardstick::metric_set(accuracy, precision, recall)

# Visualize

tree_fit_viz_metr <- visualize_class_eval(tree_fit)

tree_fit_viz_metr
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-31-1.pdf)<!-- --> 

```r
tree_fit_viz_mat <- visualize_class_conf(tree_fit)

tree_fit_viz_mat
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-31-2.pdf)<!-- --> 

#### tune 

##### tune ingredients 

Decisions trees tend to overfit. There are two things we need to consider to reduce this problem: how to split and when to stop a tree.

- **complexity parameter**: a high CP means a simple decision tree with few splits. 

- **tree_depth** 


```r
tune_spec <- decision_tree(
  cost_complexity = tune(), # how to split
  tree_depth = tune(), # when to stop
  mode = "classification"
) %>%
  set_engine("rpart")

tree_grid <- grid_regular(cost_complexity(),
  tree_depth(),
  levels = 5
) # 2 hyperparameters -> 5*5 = 25 combinations

tree_grid %>%
  count(tree_depth)
```

```
## # A tibble: 5 x 2
##   tree_depth     n
##        <int> <int>
## 1          1     5
## 2          4     5
## 3          8     5
## 4         11     5
## 5         15     5
```

```r
# 10-fold cross-validation

set.seed(1234) # for reproducibility

tree_folds <- vfold_cv(train_x_class %>% bind_cols(tibble(target = train_y_class)),
  strata = target
)
```

##### Add these elements to a workflow 


```r
# Update workflow
tree_wf <- tree_wf %>% update_model(tune_spec)

# Determine the number of cores
no_cores <- detectCores() - 1

# Initiate
cl <- makeCluster(no_cores)

registerDoParallel(cl)

# Tuning results
tree_res <- tree_wf %>%
  tune_grid(
    resamples = tree_folds,
    grid = tree_grid,
    metrics = metrics
  )
```

##### Visualize 

- The following plot draws on the [vignette](https://www.tidymodels.org/start/tuning/) of the tidymodels package. 


```r
tree_res %>%
  collect_metrics() %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, col = .metric)) +
  geom_point(size = 3) +
  # Subplots
  facet_wrap(~tree_depth,
    scales = "free",
    nrow = 2
  ) +
  # Log scale x
  scale_x_log10(labels = scales::label_number()) +
  # Discrete color scale
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0) +
  labs(
    x = "Cost complexity",
    col = "Tree depth",
    y = NULL
  ) +
  coord_flip()
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-34-1.pdf)<!-- --> 

##### Select 


```r
# Optimal hyperparameter
best_tree <- select_best(tree_res, "recall")

# Add the hyperparameter to the workflow
finalize_tree <- tree_wf %>%
  finalize_workflow(best_tree)
```


```r
tree_fit_tuned <- finalize_tree %>%
  fit(train_x_class %>% bind_cols(tibble(target = train_y_class)))

# Metrics
(tree_fit_viz_metr + labs(title = "Non-tuned")) / (visualize_class_eval(tree_fit_tuned) + labs(title = "Tuned"))
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-36-1.pdf)<!-- --> 

```r
# Confusion matrix
(tree_fit_viz_mat + labs(title = "Non-tuned")) / (visualize_class_conf(tree_fit_tuned) + labs(title = "Tuned"))
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-36-2.pdf)<!-- --> 

- Visualize variable importance 


```r
tree_fit_tuned %>%
  pull_workflow_fit() %>%
  vip::vip()
```

```
## Warning: `pull_workflow_fit()` was deprecated in workflows 0.2.3.
## Please use `extract_fit_parsnip()` instead.
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-37-1.pdf)<!-- --> 

##### Test fit

- Apply the tuned model to the test dataset 


```r
test_fit <- finalize_tree %>%
  fit(test_x_class %>% bind_cols(tibble(target = test_y_class)))

evaluate_class(test_fit)
```

```
## # A tibble: 3 x 3
##   .metric   .estimator .estimate
##   <chr>     <chr>          <dbl>
## 1 accuracy  binary         0.761
## 2 precision binary         0.778
## 3 recall    binary         0.667
```

In the next subsection, we will learn variants of ensemble models that improve decision tree models by putting models together.

### Bagging (Random forest)

Key idea applied across all ensemble models (bagging, boosting, and stacking): 
single learner -> N learners (N > 1) 

Many learners could perform better than a single learner as this approach reduces the **variance** of a single estimate and provides more stability.

Here we focus on the difference between bagging and boosting. In short, boosting may reduce bias while increasing variance. Bagging may reduce variance but has nothing to do with bias. For more information, please check out [What is the difference between Bagging and Boosting?](https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/) by aporras.

**bagging**

- Data: Training data will be randomly sampled with replacement (bootstrapping samples + drawing random **subsets** of features for training individual trees)

- Learning: Building models in parallel (independently)

- Prediction: Simple average of the estimated responses (majority vote system)


![From Sebastian Raschka's blog](https://sebastianraschka.com/images/faq/bagging-boosting-rf/bagging.png)


**boosting** 


- Data: Weighted training data will be random sampled

- Learning: Building models sequentially (mispredicted cases would receive more weights) 

- Prediction: Weighted average of the estimated responses 


![From Sebastian Raschka's blog](https://sebastianraschka.com/images/faq/bagging-boosting-rf/boosting.png)


#### parsnip 

- Build a model 

1. Specify a model 
2. Specify an engine 
3. Specify a mode 


```r
# workflow
rand_wf <- workflow() %>% add_formula(target ~ .)

# spec
rand_spec <- rand_forest(

  # Mode
  mode = "classification",

  # Tuning hyperparameters
  mtry = NULL, # The number of predictors to available for splitting at each node
  min_n = NULL, # The minimum number of data points needed to keep splitting nodes
  trees = 500
) %>% # The number of trees
  set_engine("ranger",
    # We want the importance of predictors to be assessed.
    seed = 1234,
    importance = "permutation"
  )

rand_wf <- rand_wf %>% add_model(rand_spec)
```

- Fit a model


```r
rand_fit <- rand_wf %>% fit(train_x_class %>% bind_cols(tibble(target = train_y_class)))
```

#### yardstick 


```r
# Define performance metrics
metrics <- yardstick::metric_set(accuracy, precision, recall)

rand_fit_viz_metr <- visualize_class_eval(rand_fit)

rand_fit_viz_metr
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-41-1.pdf)<!-- --> 

- Visualize the confusion matrix. 
  

```r
rand_fit_viz_mat <- visualize_class_conf(rand_fit)

rand_fit_viz_mat
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-42-1.pdf)<!-- --> 

#### tune 

##### tune ingredients 

We focus on the following two hyperparameters:

- `mtry`: The number of predictors available for splitting at each node.

- `min_n`: The minimum number of data points needed to keep splitting nodes. 


```r
tune_spec <-
  rand_forest(
    mode = "classification",

    # Tuning hyperparameters
    mtry = tune(),
    min_n = tune()
  ) %>%
  set_engine("ranger",
    seed = 1234,
    importance = "permutation"
  )

rand_grid <- grid_regular(mtry(range = c(1, 10)),
  min_n(range = c(2, 10)),
  levels = 5
)

rand_grid %>%
  count(min_n)
```

```
## # A tibble: 5 x 2
##   min_n     n
##   <int> <int>
## 1     2     5
## 2     4     5
## 3     6     5
## 4     8     5
## 5    10     5
```


```r
# 10-fold cross-validation

set.seed(1234) # for reproducibility

rand_folds <- vfold_cv(train_x_class %>% bind_cols(tibble(target = train_y_class)),
  strata = target
)
```

##### Add these elements to a workflow 


```r
# Update workflow
rand_wf <- rand_wf %>% update_model(tune_spec)

# Tuning results
rand_res <- rand_wf %>%
  tune_grid(
    resamples = rand_folds,
    grid = rand_grid,
    metrics = metrics
  )
```

##### Visualize 


```r
rand_res %>%
  collect_metrics() %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  # Line + Point plot
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  # Subplots
  facet_wrap(~.metric,
    scales = "free",
    nrow = 2
  ) +
  # Log scale x
  scale_x_log10(labels = scales::label_number()) +
  # Discrete color scale
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0) +
  labs(
    x = "The number of predictors to be sampled",
    col = "The minimum number of data points needed for splitting",
    y = NULL
  ) +
  theme(legend.position = "bottom")
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-46-1.pdf)<!-- --> 


```r
# Optimal hyperparameter
best_tree <- select_best(rand_res, "accuracy")

best_tree
```

```
## # A tibble: 1 x 3
##    mtry min_n .config              
##   <int> <int> <chr>                
## 1     1     4 Preprocessor1_Model06
```

```r
# Add the hyperparameter to the workflow
finalize_tree <- rand_wf %>%
  finalize_workflow(best_tree)
```


```r
rand_fit_tuned <- finalize_tree %>%
  fit(train_x_class %>% bind_cols(tibble(target = train_y_class)))

# Metrics
(rand_fit_viz_metr + labs(title = "Non-tuned")) / (visualize_class_eval(rand_fit_tuned) + labs(title = "Tuned"))
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-48-1.pdf)<!-- --> 

```r
# Confusion matrix
(rand_fit_viz_mat + labs(title = "Non-tuned")) / (visualize_class_conf(rand_fit_tuned) + labs(title = "Tuned"))
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-48-2.pdf)<!-- --> 

- Visualize variable importance 


```r
rand_fit_tuned %>%
  pull_workflow_fit() %>%
  vip::vip()
```

```
## Warning: `pull_workflow_fit()` was deprecated in workflows 0.2.3.
## Please use `extract_fit_parsnip()` instead.
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-49-1.pdf)<!-- --> 

##### Test fit

- Apply the tuned model to the test dataset 


```r
test_fit <- finalize_tree %>%
  fit(test_x_class %>%
    bind_cols(tibble(target = test_y_class)))

evaluate_class(test_fit)
```

```
## # A tibble: 3 x 3
##   .metric   .estimator .estimate
##   <chr>     <chr>          <dbl>
## 1 accuracy  binary         0.913
## 2 precision binary         0.905
## 3 recall    binary         0.905
```

### Boosting (XGboost)

#### parsnip 

- Build a model 

1. Specify a model 
2. Specify an engine 
3. Specify a mode 


```r
# workflow
xg_wf <- workflow() %>% add_formula(target ~ .)

# spec
xg_spec <- boost_tree(

  # Mode
  mode = "classification",

  # Tuning hyperparameters

  # The number of trees to fit, aka boosting iterations
  trees = c(100, 300, 500, 700, 900),
  # The depth of the decision tree (how many levels of splits).
  tree_depth = c(1, 6),
  # Learning rate: lower means the ensemble will adapt more slowly.
  learn_rate = c(0.0001, 0.01, 0.2),
  # Stop splitting a tree if we only have this many obs in a tree node.
  min_n = 10L
) %>%
  set_engine("xgboost")

xg_wf <- xg_wf %>% add_model(xg_spec)
```

- Fit a model


```r
xg_fit <- xg_wf %>% fit(train_x_class %>% bind_cols(tibble(target = train_y_class)))
```

```
## Warning in begin_iteration:end_iteration: numerical expression has 5 elements:
## only the first used
```

```
## [05:59:09] WARNING: amalgamation/../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
```

#### yardstick 


```r
metrics <- metric_set(
  yardstick::accuracy,
  yardstick::precision,
  yardstick::recall
)

evaluate_class(xg_fit)
```

```
## # A tibble: 3 x 3
##   .metric   .estimator .estimate
##   <chr>     <chr>          <dbl>
## 1 accuracy  binary         0.739
## 2 precision binary         0.705
## 3 recall    binary         0.738
```


```r
xg_fit_viz_metr <-
  visualize_class_eval(xg_fit)

xg_fit_viz_metr
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-54-1.pdf)<!-- --> 

- Visualize the confusion matrix. 
  

```r
xg_fit_viz_mat <-
  visualize_class_conf(xg_fit)

xg_fit_viz_mat
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-55-1.pdf)<!-- --> 

#### tune 

##### tune ingredients 

- We focus on the following hyperparameters: `trees,` `tree_depth,` `learn_rate,` `min_n,` `mtry,` `loss_reduction,` and `sample_size`


```r
tune_spec <-
  xg_spec <- boost_tree(

    # Mode
    mode = "classification",

    # Tuning hyperparameters

    # The number of trees to fit, aka boosting iterations
    trees = tune(),
    # The depth of the decision tree (how many levels of splits).
    tree_depth = tune(),
    # Learning rate: lower means the ensemble will adapt more slowly.
    learn_rate = tune(),
    # Stop splitting a tree if we only have this many obs in a tree node.
    min_n = tune(),
    loss_reduction = tune(),
    # The number of randomly selected hyperparameters
    mtry = tune(),
    # The size of the data set used for modeling within an iteration
    sample_size = tune()
  ) %>%
  set_engine("xgboost")

# Space-filling hyperparameter grids
xg_grid <- grid_latin_hypercube(
  trees(),
  tree_depth(),
  learn_rate(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), train_x_class),
  size = 30
)

# 10-fold cross-validation

set.seed(1234) # for reproducibility

xg_folds <- vfold_cv(train_x_class %>% bind_cols(tibble(target = train_y_class)),
  strata = target
)
```

##### Add these elements to a workflow 


```r
# Update workflow
xg_wf <- xg_wf %>% update_model(tune_spec)

# Tuning results
xg_res <- xg_wf %>%
  tune_grid(
    resamples = xg_folds,
    grid = xg_grid,
    control = control_grid(save_pred = TRUE)
  )
```

##### Visualize 


```r
conflict_prefer("filter", "dplyr")
```

```
## [conflicted] Removing existing preference
```

```
## [conflicted] Will prefer dplyr::filter over any other package
```

```r
xg_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  pivot_longer(mtry:sample_size,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(x = value, y = mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(
    y = "AUC",
    x = NULL
  )
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-58-1.pdf)<!-- --> 


```r
# Optimal hyperparameter
best_xg <- select_best(xg_res, "roc_auc")

best_xg
```

```
## # A tibble: 1 x 8
##    mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    
##   <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      
## 1    12  1361     3          7   0.000164    0.000000638       0.159 Preprocess~
```

```r
# Add the hyperparameter to the workflow
finalize_xg <- xg_wf %>%
  finalize_workflow(best_xg)
```


```r
xg_fit_tuned <- finalize_xg %>%
  fit(train_x_class %>% bind_cols(tibble(target = train_y_class)))
```

```
## [06:01:02] WARNING: amalgamation/../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
```

```r
# Metrics
(xg_fit_viz_metr + labs(title = "Non-tuned")) / (visualize_class_eval(xg_fit_tuned) + labs(title = "Tuned"))
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-60-1.pdf)<!-- --> 

```r
# Confusion matrix
(xg_fit_viz_mat + labs(title = "Non-tuned")) / (visualize_class_conf(xg_fit_tuned) + labs(title = "Tuned"))
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-60-2.pdf)<!-- --> 

- Visualize variable importance 


```r
xg_fit_tuned %>%
  pull_workflow_fit() %>%
  vip::vip()
```

```
## Warning: `pull_workflow_fit()` was deprecated in workflows 0.2.3.
## Please use `extract_fit_parsnip()` instead.
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-61-1.pdf)<!-- --> 

##### Test fit

- Apply the tuned model to the test dataset 


```r
test_fit <- finalize_xg %>%
  fit(test_x_class %>% bind_cols(tibble(target = test_y_class)))
```

```
## [06:01:04] WARNING: amalgamation/../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
```

```r
evaluate_class(test_fit)
```

```
## Warning: While computing binary `precision()`, no predicted events were detected (i.e. `true_positive + false_positive = 0`). 
## Precision is undefined in this case, and `NA` will be returned.
## Note that 42 true event(s) actually occured for the problematic event level, '0'.
```

```
## # A tibble: 3 x 3
##   .metric   .estimator .estimate
##   <chr>     <chr>          <dbl>
## 1 accuracy  binary         0.543
## 2 precision binary        NA    
## 3 recall    binary         0
```

### Stacking (SuperLearner)

This stacking part of the book heavily relies on [Chris Kennedy's notebook](https://github.com/dlab-berkeley/Machine-Learning-in-R/blob/master/07-ensembles.Rmd).

#### Overview

##### Stacking

Wolpert, D.H., 1992. [Stacked generalization](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.1533). *Neural networks*, 5(2), pp.241-259.

Breiman, L., 1996. [Stacked regressions]((https://statistics.berkeley.edu/sites/default/files/tech-reports/367.pdf). *Machine learning*, 24(1), pp.49-64.

##### SuperLearner 

The ["SuperLearner" R package](https://cran.r-project.org/web/packages/SuperLearner/index.html) is a method that simplifies ensemble learning by allowing you to simultaneously evaluate the cross-validated performance of multiple algorithms and/or a single algorithm with differently tuned hyperparameters. This is a generally advisable approach to machine learning instead of fitting single algorithms.

Let's see how the four classification algorithms you learned in this workshop (1-lasso, 2-decision tree, 3-random forest, and 4-gradient boosted trees) compare to each other and also to 5-binary logistic regression (`glm`) and the 6-mean of Y as a benchmark algorithm, in terms of their cross-validated error!

A "wrapper" is a short function that adapts an algorithm for the SuperLearner package. Check out the different algorithm wrappers offered by SuperLearner:

#### Choose algorithms


```r
# Review available models
SuperLearner::listWrappers()
```

```
## All prediction algorithm wrappers in SuperLearner:
```

```
##  [1] "SL.bartMachine"      "SL.bayesglm"         "SL.biglasso"        
##  [4] "SL.caret"            "SL.caret.rpart"      "SL.cforest"         
##  [7] "SL.earth"            "SL.extraTrees"       "SL.gam"             
## [10] "SL.gbm"              "SL.glm"              "SL.glm.interaction" 
## [13] "SL.glmnet"           "SL.ipredbagg"        "SL.kernelKnn"       
## [16] "SL.knn"              "SL.ksvm"             "SL.lda"             
## [19] "SL.leekasso"         "SL.lm"               "SL.loess"           
## [22] "SL.logreg"           "SL.mean"             "SL.nnet"            
## [25] "SL.nnls"             "SL.polymars"         "SL.qda"             
## [28] "SL.randomForest"     "SL.ranger"           "SL.ridge"           
## [31] "SL.rpart"            "SL.rpartPrune"       "SL.speedglm"        
## [34] "SL.speedlm"          "SL.step"             "SL.step.forward"    
## [37] "SL.step.interaction" "SL.stepAIC"          "SL.svm"             
## [40] "SL.template"         "SL.xgboost"
```

```
## 
## All screening algorithm wrappers in SuperLearner:
```

```
## [1] "All"
## [1] "screen.corP"           "screen.corRank"        "screen.glmnet"        
## [4] "screen.randomForest"   "screen.SIS"            "screen.template"      
## [7] "screen.ttest"          "write.screen.template"
```


```r
# Compile the algorithm wrappers to be used.
sl_lib <- c(
  "SL.mean", # Marginal mean of the outcome ()
  "SL.glmnet", # GLM with lasso/elasticnet regularization
  "SL.rpart", # Decision tree
  "SL.ranger", # Random forest
  "SL.xgboost"
) # Xgbboost
```

#### Fit model

Fit the ensemble!


```r
# This is a seed that is compatible with multicore parallel processing.
# See ?set.seed for more information.
set.seed(1, "L'Ecuyer-CMRG")

# This will take a few minutes to execute - take a look at the .html file to see the output!
cv_sl <- SuperLearner::CV.SuperLearner(
  Y = as.numeric(as.character(train_y_class)),
  X = train_x_class,
  family = binomial(),
  # For a real analysis we would use V = 10.
  cvControl = list(V = 5L, stratifyCV = TRUE),
  SL.library = sl_lib,
  verbose = FALSE
)
```

#### Risk

Risk is the average loss, and loss is how far off the prediction was for an individual observation. The lower the risk, the fewer errors the model makes in its prediction. SuperLearner's default loss metric is squared error $(y_{actual} - y_{predicted})^2$, so the risk is the mean-squared error (just like in ordinary least *squares* regression). View the summary, plot results, and compute the Area Under the ROC Curve (AUC)!

##### Summary 

* `Discrete SL` chooses the best single learner (in this case, `SL.glmnet` or `lasso`).
* `SuperLearner` takes a weighted average of the **models** using the coefficients (importance of each learner in the overall ensemble). Coefficient 0 means that learner is not used at all.
* `SL.mean_All` (the weighted mean of $Y$) is a benchmark algorithm (ignoring features). 


```r
summary(cv_sl)
```

```
## 
## Call:  
## SuperLearner::CV.SuperLearner(Y = as.numeric(as.character(train_y_class)),  
##     X = train_x_class, family = binomial(), SL.library = sl_lib, verbose = FALSE,  
##     cvControl = list(V = 5L, stratifyCV = TRUE)) 
## 
## Risk is based on: Mean Squared Error
## 
## All risk estimates are based on V =  5 
## 
##       Algorithm     Ave        se      Min     Max
##   Super Learner 0.11307 0.0135943 0.076082 0.14358
##     Discrete SL 0.11882 0.0145143 0.075035 0.16356
##     SL.mean_All 0.24798 0.0030968 0.247743 0.24895
##   SL.glmnet_All 0.10752 0.0136108 0.075035 0.14358
##    SL.rpart_All 0.16641 0.0197860 0.107553 0.22102
##   SL.ranger_All 0.12564 0.0119867 0.098114 0.16080
##  SL.xgboost_All 0.13175 0.0150618 0.100769 0.16356
```

##### Plot


```r
# Plot the cross-validated risk estimate with 95% CIs.

plot(cv_sl)
```

![](07_high_dimensional_data_files/figure-latex/cvsl_review-1.pdf)<!-- --> 

#### Compute AUC for all estimators

**ROC**

ROC: a ROC (receiver operating characteristic curve) plots the relationship between True Positive Rate (Y-axis) and FALSE Positive Rate (X-axis). 

![Area Under the ROC Curve](https://developers.google.com/machine-learning/crash-course/images/AUC.svg)

**AUC** 

AUC: Area Under the ROC Curve 

1 = perfect 

0.5 = no better than chance 


```r
ck37r::auc_table(cv_sl)
```

```
##                      auc         se  ci_lower  ci_upper      p-value
## SL.mean_All    0.5000000 0.06912305 0.3645213 0.6354787 5.679776e-10
## SL.rpart_All   0.8258238 0.03856396 0.7502398 0.9014078 6.846458e-03
## SL.xgboost_All 0.8787414 0.02482895 0.8300776 0.9274053 4.478633e-02
## DiscreteSL     0.9055606 0.02082866 0.8647372 0.9463841 2.308374e-01
## SL.ranger_All  0.9066819 0.02020172 0.8670873 0.9462766 2.408934e-01
## SuperLearner   0.9154005 0.01983443 0.8765257 0.9542752 3.909316e-01
## SL.glmnet_All  0.9208924 0.01935054 0.8829661 0.9588188 5.000000e-01
```

##### Plot the ROC curve for the best estimator (DiscretSL)


```r
ck37r::plot_roc(cv_sl)
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-68-1.pdf)<!-- --> 

##### Review weight distribution for the SuperLearner


```r
print(ck37r::cvsl_weights(cv_sl), row.names = FALSE)
```

```
##  # Learner    Mean      SD     Min     Max
##  1  glmnet 0.78681 0.22451 0.46528 1.00000
##  2 xgboost 0.13637 0.21077 0.00000 0.49934
##  3  ranger 0.06974 0.15594 0.00000 0.34870
##  4   rpart 0.00708 0.01582 0.00000 0.03538
##  5    mean 0.00000 0.00000 0.00000 0.00000
```

The general stacking approach is available in the tidymodels framework through [`stacks`](https://github.com/tidymodels/stacks) package (developmental stage). 

However, SuperLearner is currently not available in the tidymodels framework. If you'd like to, you can easily build and add a parsnip model. If you are interested in knowing more about it, please look at [this vignette](https://www.tidymodels.org/learn/develop/models/) of the tidymodels.

### Applications 

#### Bandit algorithm (optimizing an experiment)

#### Causal forest (estimating heterogeneous treatment effect)

## Unsupervised learning

x -> f - > y (not defined)

### Dimension reduction

![Projecting 2D-data to a line (PCA). From vas3k.com](https://i.stack.imgur.com/Q7HIP.gif)

#### Correlation analysis 

This dataset is a good problem for PCA as some features are highly correlated. 

Again, thin about what the dataset is about. The following data dictionary comes from [this site](http://rstudio-pubs-static.s3.amazonaws.com/24341_184a58191486470cab97acdbbfe78ed5.html).

* age - age in years
* sex - sex (1 = male; 0 = female)
* cp - chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 4 = asymptomatic)
* trestbps - resting blood pressure (in mm Hg on admission to the hospital)
* chol - serum cholestoral in mg/dl
* fbs - fasting blood sugar > 120 mg/dl (1 = true; 0 = false)
* restecg - resting electrocardiographic results (0 = normal; 1 = having ST-T; 2 = hypertrophy)
* thalach - maximum heart rate achieved
* exang - exercise induced angina (1 = yes; 0 = no)
* oldpeak - ST depression induced by exercise relative to rest
slope - the slope of the peak exercise ST segment (1 = upsloping; 2 = flat; 3 = downsloping)
* ca - number of major vessels (0-3) colored by flourosopy
* thal - 3 = normal; 6 = fixed defect; 7 = reversable defect
* num - the predicted attribute - diagnosis of heart disease (angiographic disease status) (Value 0 = < 50% diameter narrowing; Value 1 = > 50% diameter narrowing)


```r
data_original %>%
  select(-target) %>%
  corrr::correlate()
```

```
## 
## Correlation method: 'pearson'
## Missing treated using: 'pairwise.complete.obs'
```

```
## # A tibble: 13 x 14
##    term         age     sex      cp trestbps     chol      fbs restecg  thalach
##    <chr>      <dbl>   <dbl>   <dbl>    <dbl>    <dbl>    <dbl>   <dbl>    <dbl>
##  1 age      NA      -0.0984 -0.0687   0.279   0.214    0.121   -0.116  -0.399  
##  2 sex      -0.0984 NA      -0.0494  -0.0568 -0.198    0.0450  -0.0582 -0.0440 
##  3 cp       -0.0687 -0.0494 NA        0.0476 -0.0769   0.0944   0.0444  0.296  
##  4 trestbps  0.279  -0.0568  0.0476  NA       0.123    0.178   -0.114  -0.0467 
##  5 chol      0.214  -0.198  -0.0769   0.123  NA        0.0133  -0.151  -0.00994
##  6 fbs       0.121   0.0450  0.0944   0.178   0.0133  NA       -0.0842 -0.00857
##  7 restecg  -0.116  -0.0582  0.0444  -0.114  -0.151   -0.0842  NA       0.0441 
##  8 thalach  -0.399  -0.0440  0.296   -0.0467 -0.00994 -0.00857  0.0441 NA      
##  9 exang     0.0968  0.142  -0.394    0.0676  0.0670   0.0257  -0.0707 -0.379  
## 10 oldpeak   0.210   0.0961 -0.149    0.193   0.0540   0.00575 -0.0588 -0.344  
## 11 slope    -0.169  -0.0307  0.120   -0.121  -0.00404 -0.0599   0.0930  0.387  
## 12 ca        0.276   0.118  -0.181    0.101   0.0705   0.138   -0.0720 -0.213  
## 13 thal      0.0680  0.210  -0.162    0.0622  0.0988  -0.0320  -0.0120 -0.0964 
## # ... with 5 more variables: exang <dbl>, oldpeak <dbl>, slope <dbl>, ca <dbl>,
## #   thal <dbl>
```

#### Descriptive statistics 

Notice the scaling issues? PCA is not scale-invariant. So, we need to fix this problem.


```r
min_max <- list(
  min = ~ min(.x, na.rm = TRUE),
  max = ~ max(.x, na.rm = TRUE)
)

data_original %>%
  select(-target) %>%
  summarise(across(where(is.numeric), min_max))
```

```
## # A tibble: 1 x 26
##   age_min age_max sex_min sex_max cp_min cp_max trestbps_min trestbps_max
##     <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>        <dbl>        <dbl>
## 1      29      77       0       1      0      3           94          200
## # ... with 18 more variables: chol_min <dbl>, chol_max <dbl>, fbs_min <dbl>,
## #   fbs_max <dbl>, restecg_min <dbl>, restecg_max <dbl>, thalach_min <dbl>,
## #   thalach_max <dbl>, exang_min <dbl>, exang_max <dbl>, oldpeak_min <dbl>,
## #   oldpeak_max <dbl>, slope_min <dbl>, slope_max <dbl>, ca_min <dbl>,
## #   ca_max <dbl>, thal_min <dbl>, thal_max <dbl>
```

#### Preprocessing 

`recipe` is essential for preprocessing multiple features at once.


```r
pca_recipe <- recipe(~., data = data_original) %>%
  # Imputing NAs using mean
  step_meanimpute(all_predictors()) %>%
  # Normalize some numeric variables
  step_normalize(c("age", "trestbps", "chol", "thalach", "oldpeak"))
```

```
## Warning: `step_meanimpute()` was deprecated in recipes 0.1.16.
## Please use `step_impute_mean()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.
```

#### PCA analysis 


```r
pca_res <- pca_recipe %>%
  step_pca(all_predictors(),
    id = "pca"
  ) %>% # id argument identifies each PCA step
  prep()

pca_res %>%
  tidy(id = "pca")
```

```
## # A tibble: 196 x 4
##    terms        value component id   
##    <chr>        <dbl> <chr>     <chr>
##  1 age      -0.00101  PC1       pca  
##  2 sex       0.216    PC1       pca  
##  3 cp        0.321    PC1       pca  
##  4 trestbps  0.00118  PC1       pca  
##  5 chol     -0.000292 PC1       pca  
##  6 fbs       0.0468   PC1       pca  
##  7 restecg   0.166    PC1       pca  
##  8 thalach   0.0137   PC1       pca  
##  9 exang     0.0962   PC1       pca  
## 10 oldpeak  -0.00863  PC1       pca  
## # ... with 186 more rows
```

##### Screeplot


```r
# To avoid conflicts
conflict_prefer("filter", "dplyr")
```

```
## [conflicted] Removing existing preference
```

```
## [conflicted] Will prefer dplyr::filter over any other package
```

```r
conflict_prefer("select", "dplyr")
```

```
## [conflicted] Will prefer dplyr::select over any other package
```

```r
pca_recipe %>%
  step_pca(all_predictors(),
    id = "pca"
  ) %>% # id argument identifies each PCA step
  prep() %>%
  tidy(id = "pca", type = "variance") %>%
  filter(terms == "percent variance") %>%
  ggplot(aes(x = component, y = value)) +
  geom_col() +
  labs(
    x = "PCAs of heart disease",
    y = "% of variance",
    title = "Scree plot"
  )
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-74-1.pdf)<!-- --> 

##### View factor loadings 

Loadings are the covariances between the features and the principal components (=eigenvectors).


```r
pca_recipe %>%
  step_pca(all_predictors(),
    id = "pca"
  ) %>% # id argument identifies each PCA step
  prep() %>%
  tidy(id = "pca") %>%
  filter(component %in% c("PC1", "PC2")) %>%
  ggplot(aes(
    x = fct_reorder(terms, value), y = value,
    fill = component
  )) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(
    x = "Terms",
    y = "Contribtutions",
    fill = "PCAs"
  )
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-75-1.pdf)<!-- --> 

**The key lesson**

You can use these low-dimensional data to solve the curse of dimensionality problem. Compressing feature space via dimension reduction techniques is called feature extraction. PCA is one way of doing this.

### Topic modeling 

#### Setup 


```r
pacman::p_load(
  tidytext, # tidy text analysis
  glue, # paste string and objects
  stm, # structural topic modeling
  gutenbergr
) # toy datasets
```

#### Dataset 

The data munging process draws on [Julia Silge's blog post](https://juliasilge.com/blog/sherlock-holmes-stm/).


```r
sherlock_raw <- gutenberg_download(1661)
```

```
## Determining mirror for Project Gutenberg from http://www.gutenberg.org/robot/harvest
```

```
## Using mirror http://aleph.gutenberg.org
```

```r
sherlock <- sherlock_raw %>%
  # Mutate story using a conditional statement
  mutate(
    story = ifelse(str_detect(text, "ADVENTURE"), text, NA)
  ) %>%
  # Fill in missing values with next value
  tidyr::fill(story, .direction = "down") %>%
  # Filter
  dplyr::filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%
  # Factor
  mutate(story = factor(story, levels = unique(story)))

sherlock <- sherlock[, 2:3] # no id
```

#### Key ideas 

![Source: paperswithcode.com](https://paperswithcode.com/media/thumbnails/task/task-0000000179-fd3a1d11_fGQkZCJ.jpg)

-   Main papers: See [Latent Dirichlet Allocation](https://proceedings.neurips.cc/paper/2001/file/296472c9542ad4d4788d543508116cbc-Paper.pdf) by David M. Blei, Andrew Y. Ng and Michael I. Jordan (then all Berkeley) and this [follow-up paper](http://www.cse.cuhk.edu.hk/irwin.king/_media/presentations/latent_dirichlet_allocation.pdf) with the same title.

-   Topics as **distributions** of words ($\beta$ distribution)

-   Documents as **distributions** of topics ($\alpha$ distribution)

-   What distributions?

    -   Probability

    -   Multinominal

-   Words lie on a lower-dimensional space (dimension reduction akin to PCA)

-   Co-occurrence of words (clustering)

-   Bag of words (feature engineering)

    -   Upside: easy and fast (also working quite well)
    -   Downside: ignored grammatical structures and rich interactions among words (Alternative: word embeddings. Please check out [text2vec](http://text2vec.org/))

-   Documents are exchangeable (sequencing won't matter).

-   Topics are independent (uncorrelated). If you don't think this assumption holds, use Correlated Topics Models by [Blei and Lafferty (2007)](https://arxiv.org/pdf/0708.3601.pdf#:~:text=The%20correlated%20topic%20model%20(CTM)%20is%20a%20hierarchical%20model%20of,are%20document%2D%20specific%20random%20variables.).

#### Exploratory data analysis 


```r
sherlock_n <- sherlock %>%
  unnest_tokens(
    output = word,
    input = text
  ) %>%
  count(story, word, sort = TRUE)

sherlock_total_n <- sherlock_n %>%
  group_by(story) %>%
  summarise(total = sum(n))

sherlock_words <- sherlock_n %>%
  left_join(sherlock_total_n)
```

```
## Joining, by = "story"
```

```r
sherlock_words %>%
  mutate(freq = n / total) %>%
  group_by(story) %>%
  top_n(10) %>%
  ggplot(aes(
    x = fct_reorder(word, freq),
    y = freq,
    fill = story
  )) +
  geom_col() +
  coord_flip() +
  facet_wrap(~story,
    ncol = 2,
    scales = "free_y"
  ) +
  scale_fill_viridis_d() +
  labs(
    x = "",
    fill = "Story"
  ) +
  theme(legend.position = "bottom")
```

```
## Selecting by freq
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x,
## x$y, : conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x,
## x$y, : conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x,
## x$y, : conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

```
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x,
## x$y, : conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x,
## x$y, : conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x,
## x$y, : conversion failure on 'IX. THE ADVENTURE OF THE ENGINEER’S THUMB' in
## 'mbcsToSbcs': dot substituted for <99>
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-78-1.pdf)<!-- --> 

#### STM

[Structural Topic Modeling](https://www.structuraltopicmodel.com/) by Roberts, Stewart, and Tingley helps estimating how the proportions of topics vary by covariates. If you don't use covaraites, this approach is close to CTM. The other useful (and very recent) topic modeling package is Keyword Assisted Topic Models ([keyATM](https://keyatm.github.io/keyATM/)) by Shusei, Imai, and Sasaki.

Also, note that we didn't cover other important techniques in topic modeling such as dynamic and hierarchical topic modeling.

![](https://warin.ca/shiny/stm/images/fig02.png)

##### Turn text into document-term matrix

`stm` package has its preprocessing function.


```r
dtm <- textProcessor(
  documents = sherlock$text,
  metadata = sherlock,
  removestopwords = TRUE,
  verbose = FALSE
)
```

##### Tuning K

- K is the number of topics. 
- Let's try K = 5, 10, 15.


```r
test_res <- searchK(
  dtm$documents,
  dtm$vocab,
  K = c(5, 10, 15),
  prevalence = ~story,
  data = dtm$meta
)
```

```
## Beginning Spectral Initialization 
## 	 Calculating the gram matrix...
## 	 Finding anchor words...
##  	.....
## 	 Recovering initialization...
##  	..............................................
## Initialization complete.
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 1 (approx. per word bound = -7.627) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 2 (approx. per word bound = -7.512, relative change = 1.510e-02) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 3 (approx. per word bound = -7.419, relative change = 1.228e-02) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 4 (approx. per word bound = -7.381, relative change = 5.151e-03) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 5 (approx. per word bound = -7.365, relative change = 2.165e-03) 
## Topic 1: littl, man, see, hand, shall 
##  Topic 2: upon, holm, think, come, take 
##  Topic 3: said, will, just, know, word 
##  Topic 4: one, may, came, tell, ask 
##  Topic 5: time, sherlock, case, saw, face 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 6 (approx. per word bound = -7.358, relative change = 9.504e-04) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 7 (approx. per word bound = -7.355, relative change = 4.015e-04) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 8 (approx. per word bound = -7.354, relative change = 1.580e-04) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Model Converged 
## Beginning Spectral Initialization 
## 	 Calculating the gram matrix...
## 	 Finding anchor words...
##  	..........
## 	 Recovering initialization...
##  	..............................................
## Initialization complete.
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 1 (approx. per word bound = -7.699) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 2 (approx. per word bound = -7.499, relative change = 2.594e-02) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 3 (approx. per word bound = -7.373, relative change = 1.684e-02) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 4 (approx. per word bound = -7.287, relative change = 1.172e-02) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 5 (approx. per word bound = -7.257, relative change = 4.115e-03) 
## Topic 1: miss, littl, came, man, good 
##  Topic 2: said, might, sudden, hous, went 
##  Topic 3: upon, just, never, right, two 
##  Topic 4: upon, will, one, see, may 
##  Topic 5: sherlock, name, think, laugh, holm 
##  Topic 6: see, hard, night, cri, forward 
##  Topic 7: littl, stone, becam, whole, sure 
##  Topic 8: can, know, matter, now, say 
##  Topic 9: man, hand, knew, one, even 
##  Topic 10: holm, ask, sat, “pray, long 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 6 (approx. per word bound = -7.248, relative change = 1.256e-03) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 7 (approx. per word bound = -7.247, relative change = 9.258e-05) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Model Converged 
## Beginning Spectral Initialization 
## 	 Calculating the gram matrix...
## 	 Finding anchor words...
##  	...............
## 	 Recovering initialization...
##  	..............................................
## Initialization complete.
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 1 (approx. per word bound = -7.749) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 2 (approx. per word bound = -7.417, relative change = 4.283e-02) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 3 (approx. per word bound = -7.297, relative change = 1.624e-02) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 4 (approx. per word bound = -7.242, relative change = 7.558e-03) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 5 (approx. per word bound = -7.222, relative change = 2.745e-03) 
## Topic 1: think, holm, turn, now, “ye 
##  Topic 2: might, dress, hous, place, near 
##  Topic 3: know, without, now, “’s, money 
##  Topic 4: open, may, look, much, one 
##  Topic 5: hand, well, see, way, littl 
##  Topic 6: question, salesman, told, companion, close 
##  Topic 7: littl, told, feel, remark, quit 
##  Topic 8: can, matter, “oh, say, away 
##  Topic 9: will, shall, must, come, littl 
##  Topic 10: one, man, light, time, two 
##  Topic 11: upon, holm, miss, man, sherlock 
##  Topic 12: room, came, ask, just, hous 
##  Topic 13: may, tell, sir, find, help 
##  Topic 14: said, holm, believ, laugh, will 
##  Topic 15: littl, now, noth, day, saw 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 6 (approx. per word bound = -7.212, relative change = 1.382e-03) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 7 (approx. per word bound = -7.207, relative change = 5.993e-04) 
## ....................................................................................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 8 (approx. per word bound = -7.203, relative change = 5.851e-04) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Completing Iteration 9 (approx. per word bound = -7.202, relative change = 9.837e-05) 
## ....................................................................................................
## Completed E-Step (1 seconds). 
## Completed M-Step. 
## Model Converged
```

##### Evaludating models 

Several metrics assess topic models' performance: the held-out likelihood, residuals, semantic coherence, and exclusivity. Here we examine the relationship between semantic coherence and exclusivity to understand the trade-off involved in selecting K.

-   Semantic coherence: high probability words for a topic co-occur in documents

-   Exclusivity: key words of one topic are not likely to appear as key words in other topics.

> In Roberts et al 2014 we proposed using the Mimno et al 2011 semantic coherence metric for helping with topic model selection. We found that semantic coherence alone is relatively easy to achieve by having only a couple of topics which all are dominated by the most common words. Thus we also proposed an exclusivity measure.

> Our exclusivity measure includes some information on word frequency as well. It is based on the FREX labeling metric (calcfrex) with the weight set to .7 in favor of exclusivity by default.


```r
test_res$results %>%
  unnest(c(K, exclus, semcoh)) %>%
  select(K, exclus, semcoh) %>%
  mutate(K = as.factor(K)) %>%
  ggplot(aes(x = exclus, y = semcoh)) +
  geom_point() +
  geom_text(
    label = glue("K = {test_res$results$K}"),
    size = 5,
    color = "red",
    position = position_jitter(width = 0.05, height = 0.05)
  ) +
  labs(
    x = "Exclusivity",
    y = "Semantic coherence",
    title = "Exclusivity and semantic coherence"
  )
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-81-1.pdf)<!-- --> 

##### Finalize 


```r
final_stm <- stm(dtm$documents,
  dtm$vocab,
  K = 10, prevalence = ~story,
  max.em.its = 75,
  data = dtm$meta,
  init.type = "Spectral",
  seed = 1234567,
  verbose = FALSE
)
```

##### Explore the results 

- Using the `stm` package. 


```r
plot(final_stm)
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-83-1.pdf)<!-- --> 

- Using ggplot2 

In LDA distribution, $\alpha$ represents document-topic density and $\beta$ represents topic-word density. 


```r
# tidy
tidy_stm <- tidy(final_stm)

# top terms
tidy_stm %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  ggplot(aes(fct_reorder(term, beta), beta, fill = as.factor(topic))) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~topic, scales = "free_y") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_viridis_d()
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

```
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <e2>
```

```
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <80>
```

```
## Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :
## conversion failure on 'sir”' in 'mbcsToSbcs': dot substituted for <9d>
```

![](07_high_dimensional_data_files/figure-latex/unnamed-chunk-84-1.pdf)<!-- --> 

## References

### Books 

- *An Introduction to Statistical Learning - with Applications in R (2013)* by Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. Springer: New York. [Amazon](https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/1461471370) or [free PDF](http://www-bcf.usc.edu/~gareth/ISL/). 

- *Hands-On Machine Learning with R (2020)* by Bradley Boehmke & Brandon Greenwell. [CRC Press](https://www.routledge.com/Hands-On-Machine-Learning-with-R/Boehmke-Greenwell/p/book/9781138495685) or [Amazon](https://www.amazon.com/gp/product/1138495689?pf_rd_p=ab873d20-a0ca-439b-ac45-cd78f07a84d8&pf_rd_r=JBRX0ZJ1WFSR9T3JPTQE)

- *Applied Predictive Modeling (2013)* by Max Kuhn and Kjell Johnson. Springer: New York. [Amazon](https://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn/dp/1461468485?SubscriptionId=0ENGV10E9K9QDNSJ5C82&tag=apm0a-20&linkCode=xm2&camp=2025&creative=165953&creativeASIN=1461468485) 

- *Feature Engineering and Selection: A Practical Approach for Predictive Models (2019)* by Kjell Johnson and Max Kuhn. Taylor & Francis. [Amazon](http://www.feat.engineering/) or [free HTML](http://www.feat.engineering/). 
- *[Tidy Modeling with R](https://www.tmwr.org/) (2020)* by Max Kuhn and Julia Silge (work-in-progress)

### Lecture slides 

- [An introduction to supervised and unsupervised learning (2015)](https://www.nber.org/econometrics_minicourse_2015/nber_slides11.pdf) by Susan Athey and Guido Imbens 

- [Introduction Machine Learning with the Tidyverse](https://education.rstudio.com/blog/2020/02/conf20-intro-ml/) by Alison Hill

### Blog posts 

- ["Using the recipes package for easy pre-processing"](http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/) by Rebecca Barter

<!--chapter:end:07_high_dimensional_data.Rmd-->

# Big data {#big_data}



## Overview

- Big data problem: data is too big to fit into memory (=local environment).
- R reads data into random-access memory (RAM) at once and this object lives in memory entirely. So, if object.size > memory.size, the process will crash R. 
- Therefore, the key to deal with big data in R is reducing the size of data you want to bring into it.

**Techniques to deal with big data**

- Medium-sized file (1-2 GB)
   - Try to reduce the size of the file using slicing and dicing
   - Tools: 
      - R:`data.table::fread(file path, select = c("column 1", "column 2"))`. This command imports data faster than `read.csv()` does.
      - Command-line: [`csvkit`](https://csvkit.readthedocs.io/en/latest/) - a suite of command-line tools to and working with CSV 
- Large file (> 2-10 GB)
   - Put the data into a database and **ACCESS** it 
   - Explore the data and pull the objects of interest 
   
**Databases**

- Types of databases
   - Relational database = a **collection** of **tables** (fixed columns and rows): SQL is a staple tool to define, **query** (the focus of the workshop today), control, and manipulate this type of database
   - Non-relational database = a collection of documents (MongoDB), key-values (Redis and DyanoDB), wide-column stores (Cassandra and HBase), or graph (Neo4j and JanusGraph). Note that this type of database does not preclude SQL. NoSQL stands for ["not only SQL."](https://www.mongodb.com/nosql-explained)
  
**Relational database example**

![Relational Database. Source: MySQL Tutorial](https://sp.mysqltutorial.org/wp-content/uploads/2009/12/MySQL-Sample-Database-Schema.png)

## SQL

- Structured Query Language. Called SEQUEL and developed by IBM Corporation in the 1970s.

- Remains the standard language for a relational database management system.

- It's a DECLARATIVE language ([what to do > how to do](https://www.sqlite.org/queryplanner.html))
  - Database management systems figure an optimal way to execute a query (query optimization)
    
```sql
SELECT COLUMN FROM TABLE 
```

### Learning objectives 

* Embracing a new mindset: shifting from ownership (opening CSVs stored in your laptop) to access (accessing data stored in a database)

* Learning how to use R and SQL to access and query a database

### SQL and R

* SQL and R

SQL           | R
------------- | --------------------------------------------------------------------------
SELECT        | select() for columns, mutate() for expressions, summarise() for aggregates
FROM          | which data frame 
WHERE         | filter()
GROUP BY      | group_by()
HAVING        | filter() **after group_by()**
ORDER BY      | arrange()
LIMIT         | head()
  
**Challenge 1**
1. Can you tell me the difference in the order in which the following `R` and `SQL` code were written to manipulate data? For instance, in R, what command comes first? In contrast, in SQL, what command comes first?

- R example 

```r

data %>% # Data 
  select() %>% # Column
  filter() %>% # Row 
  group_by() %>% # Group by 
  summarise(n = n()) %>% # n() is one of the aggregate functions in r; it's count() used inside summarise() function 
  filter() %>% # Row 
  order_by() # Arrange 

```

- SQL example (in a SQL chunk, use `--` instead of `#` to comment) 

```sql 

SELECT column, aggregation (count())` -- Column

FROM data # Data 

WHERE condition -- Filter rows 

GROUP BY column -- Group by

HAVING condition -- Filter rows after group by  

ORDER BY column -- Arrange 

```

![SQL Zine by by [Julia Evans](https://jvns.ca/)](https://wizardzines.com/zines/sql/samples/from.png)

### Setup

Let's get to work. 

### Packages 

- `pacman::p_load()` reduces steps for installing and loading several packages simultaneously. 


```r
# pacman 
if (!require("pacman")) install.packages("pacman")
```

```
## Loading required package: pacman
```

```r
# The rest of pkgs 
pacman::p_load(
 
 tidyverse, # tidyverse packages 
 
 DBI, # using SQL queries
 
 RSQLite, # SQLite
 
 dbplyr, # use database with dplyr 
 
 glue, # glue to automate workflow 
 
 nycflights13 # toy data 
)
```

### NYC flights data 

- [The flight on-time performance data](https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236) from the Bureau of Transportation Statistics of the U.S. government. The data goes back to 1987, and its size is more than 20 gigabytes. For practice, we only use a small subset of the original data (flight data departing NYC in 2013) provided by RStudio.

![From RStudio.](https://d33wubrfki0l68.cloudfront.net/245292d1ea724f6c3fd8a92063dcd7bfb9758d02/5751b/diagrams/relational-nycflights.png)

### Workflow 

1. Create/connect to a database 

- Note that the server also can be your laptop (called [localhost](https://en.wikipedia.org/wiki/Localhost#:~:text=In%20computer%20networking%2C%20localhost%20is,via%20the%20loopback%20network%20interface.)).

- Short answer: To do so, you need interfaces between R and a database. We use [`RSQLite`](https://github.com/r-dbi/RSQLite) in this tutorial because it's easy to set up. 

- Long answer: The `DBI` package in R provides a client-side interface that allows `dplyr` to work with databases. DBI is automatically installed when you installed `dbplyr`. However, you need to install a specific backend engine (a tool for communication between R and a database management system) for the database (e.g., `RMariaDB`, `RPostgres`, `RSQLite`). In this workshop, we use SQLite because it is the easiest to get started with. I love PostgreSQL because it's open-source and also powerful to do [many amazing things](https://www.postgresql.org/docs/current/functions.html) (e.g., text mining, geospatial analysis). If you want to build a data warehouse, an analytical platform, consider using Spark (Hadoop).

2. Copy a table to the database 

- Option 1: You can create a table and insert rows manually. To do that, you also need to define the data schema (the database structure). 

- Table
    - Collection of rows 
    - Collection of columns (fields or attributes)
    - Each col has a type:
        - String: `VARCHAR(20)`
        - Integer: `INTEGER`
        - Floating-point: `FLOAT`, `DOUBLE`
        - Date/time: `DATE`, `TIME`, `DATETIME`
    - **Schema**: the structure of the database
        - The table name
        - The names and types of its columns
        - Various optional additional information 
            - [Constraints](https://www.w3schools.com/sql/sql_constraints.asp)
                - Syntax: `column datatype constraint`
                - Examples: `NOT NULL`, `UNIQUE`, `INDEX`
        
```sql

-- Create table 

CREATE TABLE students (
    id INT AUTO_INCREMENT,
    name VARCHAR(30),
    birth DATE,
    gpa FLOAT,
    grad INT,
    PRIMARY KEY(id));

-- Insert one additional row 

INSERT INTO students(name, birth, gpa, grad)
      VALUES ('Adam', '2000-08-04', 4.0, 2020);

```

- Option 2: Copy a file (object) to a table in a database using `copy_to`). We take this option as it's fast, and we would like to focus on querying in this workshop. 

3. Query the table 

- Main focus 

4. Pull the results of interests (**data**) using `collect()`

5. Disconnect the database 

#### Create a database 


```r
# Define a backend engine 

drv <- RSQLite::SQLite()

# Create an empty in-memory database 
con <- DBI::dbConnect(drv, 
                      dbname = ":memory:")

# Connect to an existing database 
#con <- DBI::dbConnect(RMariaDB::MariaDB(), 
 # host = "database.rstudio.com",
 # user = "hadley",
 # password = rstudioapi::askForPassword("Database password")
#)

dbListTables(con)
```

```
## character(0)
```

```r
# character(0) = NULL
```

- Note that `con` is empty at this stage.

#### Copy an object as a table to the database (push)


```r
# Copy objects to the data 
# copy_to() comes from dplyr
copy_to(dest = con, 
        df = flights)

copy_to(dest = con, 
        df = airports)

copy_to(dest = con,
        df = planes)

copy_to(dest = con, 
        df = weather)

# If you need, you can also select which columns you would like to copy:

# copy_to(dest = con, 
#          df = flights, 
#          name = "flights",
#          indexes = list(c("year", "tailnum", "dest")))
```



```r
# Show two tables in the database 

dbListTables(con)
```

```
## [1] "airports"     "flights"      "planes"       "sqlite_stat1" "sqlite_stat4"
## [6] "weather"
```

```r
# Show the columns/attributes/fields of a table 

dbListFields(con, "flights")
```

```
##  [1] "year"           "month"          "day"            "dep_time"      
##  [5] "sched_dep_time" "dep_delay"      "arr_time"       "sched_arr_time"
##  [9] "arr_delay"      "carrier"        "flight"         "tailnum"       
## [13] "origin"         "dest"           "air_time"       "distance"      
## [17] "hour"           "minute"         "time_hour"
```

```r
dbListFields(con, "weather")
```

```
##  [1] "origin"     "year"       "month"      "day"        "hour"      
##  [6] "temp"       "dewp"       "humid"      "wind_dir"   "wind_speed"
## [11] "wind_gust"  "precip"     "pressure"   "visib"      "time_hour"
```

#### Quick demonstrations:

- SELECT desired columns 
- FROM tables 

- Select all columns (*) from `flights` table and show the `first ten rows`
- Note that you can combine SQL and R commands thanks to `dbplyr`.

- Option 1 


```r
DBI::dbGetQuery(con, 
                "SELECT * FROM flights;") %>% # SQL
  head(10) # dplyr 
```

```
##    year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time
## 1  2013     1   1      517            515         2      830            819
## 2  2013     1   1      533            529         4      850            830
## 3  2013     1   1      542            540         2      923            850
## 4  2013     1   1      544            545        -1     1004           1022
## 5  2013     1   1      554            600        -6      812            837
## 6  2013     1   1      554            558        -4      740            728
## 7  2013     1   1      555            600        -5      913            854
## 8  2013     1   1      557            600        -3      709            723
## 9  2013     1   1      557            600        -3      838            846
## 10 2013     1   1      558            600        -2      753            745
##    arr_delay carrier flight tailnum origin dest air_time distance hour minute
## 1         11      UA   1545  N14228    EWR  IAH      227     1400    5     15
## 2         20      UA   1714  N24211    LGA  IAH      227     1416    5     29
## 3         33      AA   1141  N619AA    JFK  MIA      160     1089    5     40
## 4        -18      B6    725  N804JB    JFK  BQN      183     1576    5     45
## 5        -25      DL    461  N668DN    LGA  ATL      116      762    6      0
## 6         12      UA   1696  N39463    EWR  ORD      150      719    5     58
## 7         19      B6    507  N516JB    EWR  FLL      158     1065    6      0
## 8        -14      EV   5708  N829AS    LGA  IAD       53      229    6      0
## 9         -8      B6     79  N593JB    JFK  MCO      140      944    6      0
## 10         8      AA    301  N3ALAA    LGA  ORD      138      733    6      0
##     time_hour
## 1  1357034400
## 2  1357034400
## 3  1357034400
## 4  1357034400
## 5  1357038000
## 6  1357034400
## 7  1357038000
## 8  1357038000
## 9  1357038000
## 10 1357038000
```

- Option 2 (works faster)



- Option 3 (automating workflow)

  - When local variables are updated, the SQL query is also automatically updated. This approach is called [parameterized query](https://www.php.net/manual/en/pdo.prepared-statements.php) (or prepared statement).


```r
######################## PREPARATION ########################

# Local variables 
tbl <- "flights"
var <- "dep_delay"
num <- 10

# Glue SQL query string 
# Note that to indicate a numeric value, you don't need ``

sql_query <- glue_sql("
  SELECT {`var`}
  FROM {`tbl`}
  LIMIT {num} 
  ", .con = con)

######################## EXECUTION ########################

# Run the query 
dbGetQuery(con, sql_query)
```

```
##    dep_delay
## 1          2
## 2          4
## 3          2
## 4         -1
## 5         -6
## 6         -4
## 7         -5
## 8         -3
## 9         -3
## 10        -2
```

**Challenge 2** 
Can you rewrite the above code using `LIMIT` instead of `head(10)`? 

- You may notice that using only SQL code makes querying faster.

- Select `dep_delay` and `arr_delay` from flights table, show the first ten rows, then turn the result into a tibble.

**Challenge 3**
Could you remind me how to see the list of attributes of a table? Let's say you want to see the attributes of `flights` table. How can you do it?

- Collect the selected columns and filtered rows 


```r
df <- dbGetQuery(con, 
  "SELECT dep_delay, arr_delay FROM flights;") %>%
  head(10) %>%
  collect()
```
  
- Counting rows 

  - Count all (*)
  

```r
dbGetQuery(con, 
          "SELECT COUNT(*) 
           FROM flights;") 
```

```
##   COUNT(*)
## 1   336776
```
  

```r
dbGetQuery(con, 
           "SELECT COUNT(dep_delay)
           FROM flights;")
```

```
##   COUNT(dep_delay)
## 1           328521
```

  - Count distinct values 
  

```r
dbGetQuery(con, 
           "SELECT COUNT(DISTINCT dep_delay)
           FROM flights;")
```

```
##   COUNT(DISTINCT dep_delay)
## 1                       527
```

#### Tidy-way: dplyr -> SQL

Thanks to the `dbplyr` package you can use the `dplyr` syntax to query SQL. 

- Note that pipe (%) works.


```r
# tbl select tables
flights <- con %>% tbl("flights")
airports <- con %>% tbl("airports")
planes <- con %>% tbl("planes")
weather <- con %>% tbl("weather")
```

- `select` = `SELECT`


```r
flights %>% 
  select(contains("delay"))
```

```
## # Source:   lazy query [?? x 2]
## # Database: sqlite 3.37.0 [:memory:]
##    dep_delay arr_delay
##        <dbl>     <dbl>
##  1         2        11
##  2         4        20
##  3         2        33
##  4        -1       -18
##  5        -6       -25
##  6        -4        12
##  7        -5        19
##  8        -3       -14
##  9        -3        -8
## 10        -2         8
## # ... with more rows
```

**Challenge 4** 
Your turn: write the same code in SQL. Don't forget to add `connection` argument to your SQL code chunk.

- `mutate` = `SELECT` `AS`


```r
flights %>%
  select(distance, air_time) %>%  
  mutate(speed = distance / (air_time / 60)) 
```

```
## # Source:   lazy query [?? x 3]
## # Database: sqlite 3.37.0 [:memory:]
##    distance air_time speed
##       <dbl>    <dbl> <dbl>
##  1     1400      227  370.
##  2     1416      227  374.
##  3     1089      160  408.
##  4     1576      183  517.
##  5      762      116  394.
##  6      719      150  288.
##  7     1065      158  404.
##  8      229       53  259.
##  9      944      140  405.
## 10      733      138  319.
## # ... with more rows
```

**Challenge 5** 
Your turn: write the same code in SQL. (
Hint: `mutate(new_var = var 1 * var2` (R) = `SELECT var1 * var2 AS near_var` (SQL)

- `filter` = `WHERE` 


```r
flights %>% 
  filter(month == 1, day == 1) # filter(month ==1 & day == 1) Both work in the same way.
```

```
## # Source:   lazy query [?? x 19]
## # Database: sqlite 3.37.0 [:memory:]
##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
##    <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>
##  1  2013     1     1      517            515         2      830            819
##  2  2013     1     1      533            529         4      850            830
##  3  2013     1     1      542            540         2      923            850
##  4  2013     1     1      544            545        -1     1004           1022
##  5  2013     1     1      554            600        -6      812            837
##  6  2013     1     1      554            558        -4      740            728
##  7  2013     1     1      555            600        -5      913            854
##  8  2013     1     1      557            600        -3      709            723
##  9  2013     1     1      557            600        -3      838            846
## 10  2013     1     1      558            600        -2      753            745
## # ... with more rows, and 11 more variables: arr_delay <dbl>, carrier <chr>,
## #   flight <int>, tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>,
## #   distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dbl>
```

**Challenge 6** 
Your turn: write the same code in SQL (hint: `filter(condition1, condition2)` = `WHERE condition1 and condition2`)

**Additional tips**

Note that R and SQL operators are not exactly alike. R uses `!=` for `Not equal to`. SQL uses `<>` or `!=`. Furthermore, there are some cautions about using `NULL` (NA; unknown or missing): it should be `IS NULL` or `IS NOT NULL` not `=NULL` or `!=NULL` (this makes sense because NULL represents an absence of a value). 

Another pro-tip is [`LIKE` operator](https://www.w3schools.com/sql/sql_like.asp), used in a `WHERE` statement to find values based on string patterns.


```sql
SELECT DISTINCT(origin) -- Distinct values from origin column
FROM flights
WHERE origin LIKE 'J%'; -- Find any origin values that start with "J"
```


\begin{table}

\caption{(\#tab:unnamed-chunk-16)1 records}
\centering
\begin{tabular}[t]{l}
\hline
origin\\
\hline
JFK\\
\hline
\end{tabular}
\end{table}

`%` is one of the wildcards that you can use for string matching. `%` matches any number of characters. So, `J%` matches Jae, JFK, Joseph, etc. `_` is another useful wildcard and it matches exactly one character. So `J_` matches only JA, JE, etc. If wildcards are not enough, then you should consider using regular expressions.

- `arrange` = `ORDER BY`


```r
flights %>% 
  arrange(carrier, desc(arr_delay)) %>%
  show_query()
```

```
## <SQL>
## SELECT *
## FROM `flights`
## ORDER BY `carrier`, `arr_delay` DESC
```

**Challenge 7** 
Your turn: write the same code in SQL.
Hint: `arrange(var1, desc(var2)` (R) = `ORDER BY var1, var2 DESC` (SQL)

- `summarise` = `SELECT` `AS` and `group by` = `GROUP BY`


```r
flights %>%
  group_by(month, day) %>%
  summarise(delay = mean(dep_delay)) 
```

```
## Warning: Missing values are always removed in SQL.
## Use `mean(x, na.rm = TRUE)` to silence this warning
## This warning is displayed only once per session.
```

```
## `summarise()` has grouped output by 'month'. You can override using the `.groups` argument.
```

```
## # Source:   lazy query [?? x 3]
## # Database: sqlite 3.37.0 [:memory:]
## # Groups:   month
##    month   day delay
##    <int> <int> <dbl>
##  1     1     1 11.5 
##  2     1     2 13.9 
##  3     1     3 11.0 
##  4     1     4  8.95
##  5     1     5  5.73
##  6     1     6  7.15
##  7     1     7  5.42
##  8     1     8  2.55
##  9     1     9  2.28
## 10     1    10  2.84
## # ... with more rows
```

**Challenge 8** 
Your turn: write the same code in SQL (hint: in SQL the order should be `SELECT group_var1, group_var2, AVG(old_var) AS new_var` -> `FROM` -> `GROUP BY`)

- If you feel too much challenged, here's a help.


```r
flights %>%
  group_by(month, day) %>%
  summarise(delay = mean(dep_delay)) %>%
  show_query() # Show the SQL equivalent!
```

```
## `summarise()` has grouped output by 'month'. You can override using the `.groups` argument.
```

```
## <SQL>
## SELECT `month`, `day`, AVG(`dep_delay`) AS `delay`
## FROM `flights`
## GROUP BY `month`, `day`
```

- Joins 

- Using joins is more straightforward in R than it is in SQL.

- However, more flexible joins exist in SQL, and they are not available in R. 

  - Joins involving 3+ tables are not supported.
  - Some advanced joins available in SQL are not supported. 
  - For more information, check out [`tidyquery`](https://github.com/ianmcook/tidyquery/issues) to see the latest developments.

- SQL command 

`FROM one table LEFT JOIN another table ON condition = condition` (`ON` in SQL = `BY` in R)


```sql
SELECT *
FROM flights AS f
LEFT JOIN weather AS w 
ON f.year = w.year AND f.month = w.month
```


\begin{table}

\caption{(\#tab:unnamed-chunk-20)Displaying records 1 - 10}
\centering
\begin{tabular}[t]{r|r|r|r|r|r|r|r|r|l|r|l|l|l|r|r|r|r|r|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
year & month & day & dep\_time & sched\_dep\_time & dep\_delay & arr\_time & sched\_arr\_time & arr\_delay & carrier & flight & tailnum & origin & dest & air\_time & distance & hour & minute & time\_hour & origin & year & month & day & hour & temp & dewp & humid & wind\_dir & wind\_speed & wind\_gust & precip & pressure & visib & time\_hour\\
\hline
2013 & 1 & 1 & 517 & 515 & 2 & 830 & 819 & 11 & UA & 1545 & N14228 & EWR & IAH & 227 & 1400 & 5 & 15 & 1357034400 & EWR & 2013 & 1 & 1 & 1 & 39.02 & 26.06 & 59.37 & 270 & 10.35702 & NA & 0 & 1012.0 & 10 & 1357020000\\
\hline
2013 & 1 & 1 & 517 & 515 & 2 & 830 & 819 & 11 & UA & 1545 & N14228 & EWR & IAH & 227 & 1400 & 5 & 15 & 1357034400 & EWR & 2013 & 1 & 1 & 2 & 39.02 & 26.96 & 61.63 & 250 & 8.05546 & NA & 0 & 1012.3 & 10 & 1357023600\\
\hline
2013 & 1 & 1 & 517 & 515 & 2 & 830 & 819 & 11 & UA & 1545 & N14228 & EWR & IAH & 227 & 1400 & 5 & 15 & 1357034400 & EWR & 2013 & 1 & 1 & 3 & 39.02 & 28.04 & 64.43 & 240 & 11.50780 & NA & 0 & 1012.5 & 10 & 1357027200\\
\hline
2013 & 1 & 1 & 517 & 515 & 2 & 830 & 819 & 11 & UA & 1545 & N14228 & EWR & IAH & 227 & 1400 & 5 & 15 & 1357034400 & EWR & 2013 & 1 & 1 & 4 & 39.92 & 28.04 & 62.21 & 250 & 12.65858 & NA & 0 & 1012.2 & 10 & 1357030800\\
\hline
2013 & 1 & 1 & 517 & 515 & 2 & 830 & 819 & 11 & UA & 1545 & N14228 & EWR & IAH & 227 & 1400 & 5 & 15 & 1357034400 & EWR & 2013 & 1 & 1 & 5 & 39.02 & 28.04 & 64.43 & 260 & 12.65858 & NA & 0 & 1011.9 & 10 & 1357034400\\
\hline
2013 & 1 & 1 & 517 & 515 & 2 & 830 & 819 & 11 & UA & 1545 & N14228 & EWR & IAH & 227 & 1400 & 5 & 15 & 1357034400 & EWR & 2013 & 1 & 1 & 6 & 37.94 & 28.04 & 67.21 & 240 & 11.50780 & NA & 0 & 1012.4 & 10 & 1357038000\\
\hline
2013 & 1 & 1 & 517 & 515 & 2 & 830 & 819 & 11 & UA & 1545 & N14228 & EWR & IAH & 227 & 1400 & 5 & 15 & 1357034400 & EWR & 2013 & 1 & 1 & 7 & 39.02 & 28.04 & 64.43 & 240 & 14.96014 & NA & 0 & 1012.2 & 10 & 1357041600\\
\hline
2013 & 1 & 1 & 517 & 515 & 2 & 830 & 819 & 11 & UA & 1545 & N14228 & EWR & IAH & 227 & 1400 & 5 & 15 & 1357034400 & EWR & 2013 & 1 & 1 & 8 & 39.92 & 28.04 & 62.21 & 250 & 10.35702 & NA & 0 & 1012.2 & 10 & 1357045200\\
\hline
2013 & 1 & 1 & 517 & 515 & 2 & 830 & 819 & 11 & UA & 1545 & N14228 & EWR & IAH & 227 & 1400 & 5 & 15 & 1357034400 & EWR & 2013 & 1 & 1 & 9 & 39.92 & 28.04 & 62.21 & 260 & 14.96014 & NA & 0 & 1012.7 & 10 & 1357048800\\
\hline
2013 & 1 & 1 & 517 & 515 & 2 & 830 & 819 & 11 & UA & 1545 & N14228 & EWR & IAH & 227 & 1400 & 5 & 15 & 1357034400 & EWR & 2013 & 1 & 1 & 10 & 41.00 & 28.04 & 59.65 & 260 & 13.80936 & NA & 0 & 1012.4 & 10 & 1357052400\\
\hline
\end{tabular}
\end{table}

Can anyone explain why SQL query using `dplyr` then translated by `show_query()` looks so complex compared to the above? ([Hint](https://stackoverflow.com/questions/36808295/how-to-remove-duplicate-columns-from-join-in-sql))


```r
flights %>% 
  left_join(weather, by = c("year", "month")) %>%
  show_query()
```

```
## <SQL>
## SELECT `LHS`.`year` AS `year`, `LHS`.`month` AS `month`, `LHS`.`day` AS `day.x`, `dep_time`, `sched_dep_time`, `dep_delay`, `arr_time`, `sched_arr_time`, `arr_delay`, `carrier`, `flight`, `tailnum`, `LHS`.`origin` AS `origin.x`, `dest`, `air_time`, `distance`, `LHS`.`hour` AS `hour.x`, `minute`, `LHS`.`time_hour` AS `time_hour.x`, `RHS`.`origin` AS `origin.y`, `RHS`.`day` AS `day.y`, `RHS`.`hour` AS `hour.y`, `temp`, `dewp`, `humid`, `wind_dir`, `wind_speed`, `wind_gust`, `precip`, `pressure`, `visib`, `RHS`.`time_hour` AS `time_hour.y`
## FROM `flights` AS `LHS`
## LEFT JOIN `weather` AS `RHS`
## ON (`LHS`.`year` = `RHS`.`year` AND `LHS`.`month` = `RHS`.`month`)
```

#### Collect (pull)

* `collect()` is used to pull the data. Depending on the data size, it may take a long time to run.

- The following code won't work.

> Error in UseMethod("collect") : no applicable method for 'collect' applied to an object of class "c('LayerInstance', 'Layer', 'ggproto', 'gg')"


```r
origin_flights_plot <- flights %>%
  group_by(origin) %>%
  tally() %>%
  ggplot() +
  geom_col(aes(x = origin, y = n)) %>%
  collect()
```

- This works. 


```r
df <- flights %>%
  group_by(origin) %>%
  tally() %>%
  collect()

origin_flights_plot <- ggplot(df) +
  geom_col(aes(x = origin, y = n))

origin_flights_plot
```

![](08_big_data_files/figure-latex/unnamed-chunk-23-1.pdf)<!-- --> 

#### Disconnect 


```r
DBI::dbDisconnect(con)
```

### Things we didn't cover 

#### Subquery

Subquery = a query nested inside a query 

This is a hypothetical example inspired by [dofactory blog post](https://www.dofactory.com/sql/subquery).


```sql
SELECT names  -- Outer query 
FROM consultants
WHERE Id IN (SELECT ConsultingId
                FROM consulting_cases 
                WHERE category = 'r' AND category = 'sql'); -- Subquery 
```

#### Common table expression (WITH clauses)

This is just a hypothetical example inspired by [James LeDoux's blog post](https://jamesrledoux.com/code/sql-cte-common-table-expressions.


```sql
-- cases about R and SQL from dlab-database 
WITH r_sql_consulting_cases AS ( -- The name of the CTE expression 
  -- The CTE query 
  SELECT
    id 
  FROM 
    dlab 
  WHERE
    tags LIKE '%sql%'
  AND
    tags LIKE '%r%'
),
-- count the number of open cases about this consulting category 
-- The outer query 
SELECT status, COUNT(status) AS open_status_count
FROM dlab as d 
INNER JOIN r_sql_consulting_cases as r
  ON d.id = r.id 
WHERE status = 'open'; 
```

### References 

- [csv2db](https://github.com/csv2db/csv2db) - for loading large CSV files in to a database 
- R Studio, [Database using R](https://db.rstudio.com/)
- Ian Cook, ["Bridging the Gap between SQL and R"](https://github.com/ianmcook/rstudioconf2020/blob/master/bridging_the_gap_between_sql_and_r.pdf) rstudio::conf 2020 slides
  - [Video recording](https://www.youtube.com/watch?v=JwP5KdWSgqE&ab_channel=RStudio)
- Data Carpentry contributors, [SQL database and R](https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html), Data Carpentry, September 10, 2019.
- [Introduction to dbplyr](https://cran.r-project.org/web/packages/dbplyr/vignettes/dbplyr.html)
- Josh Erickson, [SQL in R](http://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/sql.html), STAT 701, University of Michigan
- [SQL zine](https://wizardzines.com/zines/sql/) by Julia Evans
- [q](http://harelba.github.io/q/) - a command-line tool that allows direct execution of SQL-like queries on CSVs/TSVs (and any other tabular text files) 

<!--chapter:end:08_big_data.Rmd-->

